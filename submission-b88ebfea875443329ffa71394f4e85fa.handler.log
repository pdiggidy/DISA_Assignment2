2025-03-21T23:02:16: Processing submission b88ebfea-8754-4332-9ffa-71394f4e85fa for group-2id70-17 ({'app': '0d91745c6311968f316e61f5d05cdf0cf63c40519854c7900c6a6f9c3a85be2e'})
2025-03-21T23:02:16: Creating submission environment ...
2025-03-21T23:02:21: Waiting for submission environment ...
2025-03-21T23:02:21: Awaiting app.kubernetes.io/name=hdfs
2025-03-21T23:03:30: Running on node: odc-09 odc-06 odc-08
2025-03-21T23:03:30: Awaiting app.kubernetes.io/name==spark
2025-03-21T23:03:31: Running on node: odc-09
2025-03-21T23:03:31: Attaching logs
2025-03-21T23:03:31: Attaching logger to infra: app.kubernetes.io/name=hdfs
2025-03-21T23:03:31: Attaching logger to infra: app.kubernetes.io/name==spark
2025-03-21T23:03:31: Begin uploading files
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:24.410114785Z 2025-03-21 23:03:24,409 INFO bzip2.Bzip2Factory: Successfully loaded & initialized native-bzip2 library system-native
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:24.415048747Z 2025-03-21 23:03:24,414 INFO zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:24.517424117Z 2025-03-21 23:03:24,517 INFO nativeio.NativeIO: The native code was built without PMDK support.
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:24.527136594Z Native library checking:
[pod/spark-master-0/spark-master] 2025-03-21T23:03:27.502813901Z Starting org.apache.spark.deploy.master.Master on spark-master-0.spark-master.submission-b88ebfea875443329ffa71394f4e85fa.svc.cluster.local
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:24.559799111Z hadoop:  true /opt/hadoop/lib/native/libhadoop.so.1.0.0
[pod/spark-master-0/spark-master] 2025-03-21T23:03:29.874529055Z Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties
[pod/spark-master-0/spark-master] 2025-03-21T23:03:29.901427839Z 25/03/21 23:03:29 INFO Master: Started daemon with process name: 8@spark-master-0
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:24.559810737Z zlib:    true /lib/x86_64-linux-gnu/libz.so.1
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:24.559815356Z zstd  :  true /lib/x86_64-linux-gnu/libzstd.so.1
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:24.559819536Z bzip2:   true /lib/x86_64-linux-gnu/libbz2.so.1
[pod/spark-master-0/spark-master] 2025-03-21T23:03:29.913101409Z 25/03/21 23:03:29 INFO SignalUtils: Registering signal handler for TERM
[pod/spark-master-0/spark-master] 2025-03-21T23:03:29.914555635Z 25/03/21 23:03:29 INFO SignalUtils: Registering signal handler for HUP
[pod/spark-master-0/spark-master] 2025-03-21T23:03:29.914620335Z 25/03/21 23:03:29 INFO SignalUtils: Registering signal handler for INT
[pod/spark-master-0/spark-master] 2025-03-21T23:03:30.518211720Z 25/03/21 23:03:30 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:24.559823200Z openssl: false EVP_CIPHER_CTX_block_size
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:24.559826837Z ISA-L:   true /lib/x86_64-linux-gnu/libisal.so.2
[pod/spark-master-0/spark-master] 2025-03-21T23:03:30.634910896Z 25/03/21 23:03:30 INFO SecurityManager: Changing view acls to: spark
[pod/spark-master-0/spark-master] 2025-03-21T23:03:30.635792990Z 25/03/21 23:03:30 INFO SecurityManager: Changing modify acls to: spark
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:24.559830579Z PMDK:    false The native code was built without PMDK support.
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:24.583915098Z HADOOP_CONF_DIR: /opt/hadoop/etc/hadoop
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:24.591982405Z HADOOP_LOG_DIR: /var/local/hadoop/logs
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:24.592017061Z /var/local/hadoop/name
[pod/spark-master-0/spark-master] 2025-03-21T23:03:30.636678479Z 25/03/21 23:03:30 INFO SecurityManager: Changing view acls groups to: 
[pod/spark-master-0/spark-master] 2025-03-21T23:03:30.637558850Z 25/03/21 23:03:30 INFO SecurityManager: Changing modify acls groups to: 
[pod/spark-master-0/spark-master] 2025-03-21T23:03:30.638301778Z 25/03/21 23:03:30 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(spark); groups with view permissions: Set(); users  with modify permissions: Set(spark); groups with modify permissions: Set()
[pod/spark-master-0/spark-master] 2025-03-21T23:03:31.132581380Z 25/03/21 23:03:31 INFO Utils: Successfully started service 'sparkMaster' on port 7077.
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:24.592025180Z Formatting name node
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:24.636625737Z WARNING: /var/local/hadoop/run does not exist. Creating.
[pod/spark-master-0/spark-master] 2025-03-21T23:03:31.155693523Z 25/03/21 23:03:31 INFO Master: Starting Spark master at spark://spark-master-0.spark-master.submission-b88ebfea875443329ffa71394f4e85fa.svc.cluster.local:7077
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:24.642127356Z WARNING: /var/local/hadoop/logs does not exist. Creating.
[pod/spark-master-0/spark-master] 2025-03-21T23:03:31.166344425Z 25/03/21 23:03:31 INFO Master: Running Spark version 3.3.4
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:25.684555308Z 2025-03-21 23:03:25,683 INFO namenode.NameNode: STARTUP_MSG: 
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:25.684613067Z /************************************************************
[pod/spark-master-0/spark-master] 2025-03-21T23:03:31.470319900Z 25/03/21 23:03:31 INFO Utils: Successfully started service 'MasterUI' on port 8080.
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:25.684618431Z STARTUP_MSG: Starting NameNode
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:25.684622924Z STARTUP_MSG:   host = hdfs-namenode-0/192.168.139.246
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:25.684627039Z STARTUP_MSG:   args = [-format, -nonInteractive, hdfs-k8s]
[pod/worker-1/spark-worker] 2025-03-21T23:02:43.730022069Z Starting org.apache.spark.deploy.worker.Worker on worker-1.worker.submission-b88ebfea875443329ffa71394f4e85fa.svc.cluster.local
[pod/worker-1/spark-worker] 2025-03-21T23:02:47.705535157Z Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:25.684631010Z STARTUP_MSG:   version = 3.3.6
[pod/worker-1/datanode] 2025-03-21T23:02:44.913057339Z 2025-03-21 23:02:44,911 INFO bzip2.Bzip2Factory: Successfully loaded & initialized native-bzip2 library system-native
[pod/worker-1/spark-worker] 2025-03-21T23:02:47.757753253Z 25/03/21 23:02:47 INFO Worker: Started daemon with process name: 8@worker-1
[pod/worker-1/datanode] 2025-03-21T23:02:44.921500236Z 2025-03-21 23:02:44,921 INFO zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
[pod/worker-1/datanode] 2025-03-21T23:02:45.050402230Z 2025-03-21 23:02:45,049 INFO nativeio.NativeIO: The native code was built without PMDK support.
[pod/worker-1/datanode] 2025-03-21T23:02:45.064752927Z Native library checking:
[pod/worker-1/spark-worker] 2025-03-21T23:02:47.782929631Z 25/03/21 23:02:47 INFO SignalUtils: Registering signal handler for TERM
[pod/worker-1/spark-worker] 2025-03-21T23:02:47.786143038Z 25/03/21 23:02:47 INFO SignalUtils: Registering signal handler for HUP
[pod/worker-1/spark-worker] 2025-03-21T23:02:47.786570807Z 25/03/21 23:02:47 INFO SignalUtils: Registering signal handler for INT
[pod/worker-1/datanode] 2025-03-21T23:02:45.069199332Z hadoop:  true /opt/hadoop/lib/native/libhadoop.so.1.0.0
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:25.684687117Z STARTUP_MSG:   classpath = /opt/hadoop/etc/hadoop:/opt/hadoop/share/hadoop/common/lib/netty-transport-native-kqueue-4.1.89.Final-osx-aarch_64.jar:/opt/hadoop/share/hadoop/common/lib/nimbus-jose-jwt-9.8.1.jar:/opt/hadoop/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/netty-codec-http-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop/share/hadoop/common/lib/netty-codec-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/jersey-core-1.19.4.jar:/opt/hadoop/share/hadoop/common/lib/jettison-1.5.4.jar:/opt/hadoop/share/hadoop/common/lib/jetty-xml-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/common/lib/curator-client-5.2.0.jar:/opt/hadoop/share/hadoop/common/lib/jul-to-slf4j-1.7.36.jar:/opt/hadoop/share/hadoop/common/lib/netty-transport-udt-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/hadoop/common/lib/netty-codec-http2-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/netty-handler-ssl-ocsp-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/jackson-annotations-2.12.7.jar:/opt/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop/share/hadoop/common/lib/netty-codec-redis-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/curator-recipes-5.2.0.jar:/opt/hadoop/share/hadoop/common/lib/avro-1.7.7.jar:/opt/hadoop/share/hadoop/common/lib/hadoop-auth-3.3.6.jar:/opt/hadoop/share/hadoop/common/lib/netty-codec-memcache-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/netty-transport-classes-kqueue-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/jetty-server-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/common/lib/netty-handler-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/guava-27.0-jre.jar:/opt/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/hadoop/common/lib/jetty-webapp-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/common/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/jetty-servlet-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/common/lib/commons-lang3-3.12.0.jar:/opt/hadoop/share/hadoop/common/lib/netty-resolver-dns-classes-macos-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/checker-qual-2.5.2.jar:/opt/hadoop/share/hadoop/common/lib/gson-2.9.0.jar:/opt/hadoop/share/hadoop/common/lib/netty-handler-proxy-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/hadoop/common/lib/j2objc-annotations-1.1.jar:/opt/hadoop/share/hadoop/common/lib/zookeeper-jute-3.6.3.jar:/opt/hadoop/share/hadoop/common/lib/jersey-servlet-1.19.4.jar:/opt/hadoop/share/hadoop/common/lib/netty-resolver-dns-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/re2j-1.1.jar:/opt/hadoop/share/hadoop/common/lib/jersey-json-1.20.jar:/opt/hadoop/share/hadoop/common/lib/jackson-databind-2.12.7.1.jar:/opt/hadoop/share/hadoop/common/lib/commons-io-2.8.0.jar:/opt/hadoop/share/hadoop/common/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/httpclient-4.5.13.jar:/opt/hadoop/share/hadoop/common/lib/netty-resolver-dns-native-macos-4.1.89.Final-osx-aarch_64.jar:/opt/hadoop/share/hadoop/common/lib/netty-transport-rxtx-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/hadoop/common/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/hadoop/common/lib/netty-resolver-dns-native-macos-4.1.89.Final-osx-x86_64.jar:/opt/hadoop/share/hadoop/common/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/hadoop/common/lib/commons-compress-1.21.jar:/opt/hadoop/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/jetty-util-ajax-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/common/lib/netty-transport-native-epoll-4.1.89.Final-linux-x86_64.jar:/opt/hadoop/share/hadoop/common/lib/jetty-io-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/common/lib/slf4j-api-1.7.36.jar:/opt/hadoop/share/hadoop/common/lib/netty-all-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/token-provider-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/hadoop/common/lib/netty-transport-native-epoll-4.1.89.Final-linux-aarch_64.jar:/opt/hadoop/share/hadoop/common/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/netty-common-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/failureaccess-1.0.jar:/opt/hadoop/share/hadoop/common/lib/jsr305-3.0.2.jar:/opt/hadoop/share/hadoop/common/lib/netty-transport-native-kqueue-4.1.89.Final-osx-x86_64.jar:/opt/hadoop/share/hadoop/common/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/hadoop/common/lib/netty-codec-socks-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/httpcore-4.4.13.jar:/opt/hadoop/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/hadoop/common/lib/animal-sniffer-annotations-1.17.jar:/opt/hadoop/share/hadoop/common/lib/netty-codec-haproxy-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/netty-resolver-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/slf4j-reload4j-1.7.36.jar:/opt/hadoop/share/hadoop/common/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop/share/hadoop/common/lib/stax2-api-4.2.1.jar:/opt/hadoop/share/hadoop/common/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/zookeeper-3.6.3.jar:/opt/hadoop/share/hadoop/common/lib/netty-codec-stomp-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/hadoop/common/lib/netty-transport-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/commons-codec-1.15.jar:/opt/hadoop/share/hadoop/common/lib/netty-codec-xml-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/netty-transport-native-unix-common-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/jetty-http-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/jersey-server-1.19.4.jar:/opt/hadoop/share/hadoop/common/lib/jetty-security-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/woodstox-core-5.4.0.jar:/opt/hadoop/share/hadoop/common/lib/commons-net-3.9.0.jar:/opt/hadoop/share/hadoop/common/lib/hadoop-annotations-3.3.6.jar:/opt/hadoop/share/hadoop/common/lib/netty-transport-classes-epoll-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/hadoop/common/lib/netty-transport-sctp-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/jsch-0.1.55.jar:/opt/hadoop/share/hadoop/common/lib/commons-text-1.10.0.jar:/opt/hadoop/share/hadoop/common/lib/netty-codec-dns-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/hadoop/common/lib/netty-codec-mqtt-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/reload4j-1.2.22.jar:/opt/hadoop/share/hadoop/common/lib/netty-buffer-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/jetty-util-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/common/lib/curator-framework-5.2.0.jar:/opt/hadoop/share/hadoop/common/lib/audience-annotations-0.5.0.jar:/opt/hadoop/share/hadoop/common/lib/jackson-core-2.12.7.jar:/opt/hadoop/share/hadoop/common/lib/commons-configuration2-2.8.0.jar:/opt/hadoop/share/hadoop/common/lib/netty-codec-smtp-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/opt/hadoop/share/hadoop/common/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/hadoop/common/hadoop-registry-3.3.6.jar:/opt/hadoop/share/hadoop/common/hadoop-kms-3.3.6.jar:/opt/hadoop/share/hadoop/common/hadoop-common-3.3.6.jar:/opt/hadoop/share/hadoop/common/hadoop-common-3.3.6-tests.jar:/opt/hadoop/share/hadoop/common/hadoop-nfs-3.3.6.jar:/opt/hadoop/share/hadoop/hdfs:/opt/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-classes-macos-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-transport-udt-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-codec-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/kotlin-stdlib-common-1.4.10.jar:/opt/hadoop/share/hadoop/hdfs/lib/jsch-0.1.55.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-configuration2-2.8.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/audience-annotations-0.5.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/hadoop/hdfs/lib/jetty-security-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/hdfs/lib/HikariCP-java7-2.4.12.jar:/opt/hadoop/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/jersey-server-1.19.4.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-transport-classes-kqueue-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/animal-sniffer-annotations-1.17.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-codec-1.15.jar:/opt/hadoop/share/hadoop/hdfs/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/reload4j-1.2.22.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-codec-dns-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-native-macos-4.1.89.Final-osx-x86_64.jar:/opt/hadoop/share/hadoop/hdfs/lib/httpclient-4.5.13.jar:/opt/hadoop/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-native-macos-4.1.89.Final-osx-aarch_64.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-transport-native-unix-common-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/paranamer-2.3.jar:/opt/hadoop/share/hadoop/hdfs/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/hadoop/hdfs/lib/okio-2.8.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/hadoop-auth-3.3.6.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-transport-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/jetty-server-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-transport-sctp-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/jetty-webapp-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/hdfs/lib/jetty-servlet-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-transport-native-kqueue-4.1.89.Final-osx-aarch_64.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-codec-http2-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-handler-proxy-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-codec-xml-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-codec-redis-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/httpcore-4.4.13.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-handler-ssl-ocsp-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/zookeeper-3.6.3.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-buffer-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop/share/hadoop/hdfs/lib/stax2-api-4.2.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/jetty-util-ajax-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-codec-http-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-codec-haproxy-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/woodstox-core-5.4.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/jetty-http-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/hdfs/lib/jersey-core-1.19.4.jar:/opt/hadoop/share/hadoop/hdfs/lib/curator-framework-5.2.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-codec-smtp-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/re2j-1.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/hadoop/hdfs/lib/okhttp-4.9.3.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-lang3-3.12.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-text-1.10.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/jersey-servlet-1.19.4.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-codec-memcache-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-transport-native-epoll-4.1.89.Final-linux-x86_64.jar:/opt/hadoop/share/hadoop/hdfs/lib/gson-2.9.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-resolver-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-net-3.9.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-codec-mqtt-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/jackson-core-2.12.7.jar:/opt/hadoop/share/hadoop/hdfs/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/hadoop/hdfs/lib/kotlin-stdlib-1.4.10.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-compress-1.21.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-transport-classes-epoll-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/hadoop/hdfs/lib/curator-client-5.2.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-io-2.8.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/jersey-json-1.20.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-all-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/guava-27.0-jre.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/avro-1.7.7.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/jackson-annotations-2.12.7.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-transport-rxtx-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-handler-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/checker-qual-2.5.2.jar:/opt/hadoop/share/hadoop/hdfs/lib/nimbus-jose-jwt-9.8.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-codec-stomp-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/hadoop-annotations-3.3.6.jar:/opt/hadoop/share/hadoop/hdfs/lib/jackson-databind-2.12.7.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/jetty-util-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-codec-socks-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-transport-native-kqueue-4.1.89.Final-osx-x86_64.jar:/opt/hadoop/share/hadoop/hdfs/lib/jettison-1.5.4.jar:/opt/hadoop/share/hadoop/hdfs/lib/zookeeper-jute-3.6.3.jar:/opt/hadoop/share/hadoop/hdfs/lib/failureaccess-1.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/jetty-io-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-transport-native-epoll-4.1.89.Final-linux-aarch_64.jar:/opt/hadoop/share/hadoop/hdfs/lib/jetty-xml-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.2.jar:/opt/hadoop/share/hadoop/hdfs/lib/j2objc-annotations-1.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-common-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/curator-recipes-5.2.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-3.10.6.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.3.6-tests.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.3.6.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.3.6-tests.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.3.6-tests.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.3.6.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.3.6.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.3.6.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-3.3.6.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.3.6.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.3.6-tests.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.3.6.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.3.6.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.3.6.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.3.6.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.3.6.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.3.6.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.3.6-tests.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.3.6.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.3.6.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.3.6.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.3.6.jar:/opt/hadoop/share/hadoop/yarn:/opt/hadoop/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.12.7.jar:/opt/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/opt/hadoop/share/hadoop/yarn/lib/fst-2.50.jar:/opt/hadoop/share/hadoop/yarn/lib/jersey-guice-1.19.4.jar:/opt/hadoop/share/hadoop/yarn/lib/jetty-plus-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/yarn/lib/javax.websocket-client-api-1.0.jar:/opt/hadoop/share/hadoop/yarn/lib/asm-tree-9.4.jar:/opt/hadoop/share/hadoop/yarn/lib/jetty-client-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/yarn/lib/javax-websocket-client-impl-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-base-2.12.7.jar:/opt/hadoop/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/opt/hadoop/share/hadoop/yarn/lib/bcpkix-jdk15on-1.68.jar:/opt/hadoop/share/hadoop/yarn/lib/javax.websocket-api-1.0.jar:/opt/hadoop/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/opt/hadoop/share/hadoop/yarn/lib/jetty-jndi-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/yarn/lib/websocket-servlet-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/yarn/lib/objenesis-2.6.jar:/opt/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop/share/hadoop/yarn/lib/json-io-2.5.1.jar:/opt/hadoop/share/hadoop/yarn/lib/websocket-server-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/opt/hadoop/share/hadoop/yarn/lib/bcprov-jdk15on-1.68.jar:/opt/hadoop/share/hadoop/yarn/lib/snakeyaml-2.0.jar:/opt/hadoop/share/hadoop/yarn/lib/websocket-api-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/yarn/lib/websocket-common-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/opt/hadoop/share/hadoop/yarn/lib/jersey-client-1.19.4.jar:/opt/hadoop/share/hadoop/yarn/lib/jetty-annotations-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/yarn/lib/jna-5.2.0.jar:/opt/hadoop/share/hadoop/yarn/lib/jakarta.xml.bind-api-2.3.2.jar:/opt/hadoop/share/hadoop/yarn/lib/guice-4.0.jar:/opt/hadoop/share/hadoop/yarn/lib/websocket-client-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/yarn/lib/asm-commons-9.4.jar:/opt/hadoop/share/hadoop/yarn/lib/jline-3.9.0.jar:/opt/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.12.7.jar:/opt/hadoop/share/hadoop/yarn/lib/java-util-1.9.0.jar:/opt/hadoop/share/hadoop/yarn/lib/javax-websocket-server-impl-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.3.6.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.3.6.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-common-3.3.6.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.3.6.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-router-3.3.6.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-client-3.3.6.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.3.6.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-services-api-3.3.6.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-3.3.6.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-3.3.6.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.3.6.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-registry-3.3.6.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-services-core-3.3.6.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-api-3.3.6.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-applications-mawo-core-3.3.6.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.3.6.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.3.6.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.3.6.jar
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:25.684817862Z STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r 1be78238728da9266a4f88195058f08fd012bf9c; compiled by 'ubuntu' on 2023-06-18T08:22Z
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:25.684820874Z STARTUP_MSG:   java = 11.0.26
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:25.684823522Z ************************************************************/
[pod/worker-1/spark-worker] 2025-03-21T23:02:48.843403840Z 25/03/21 23:02:48 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[pod/worker-1/spark-worker] 2025-03-21T23:02:49.054745151Z 25/03/21 23:02:49 INFO SecurityManager: Changing view acls to: spark
[pod/worker-0/datanode] 2025-03-21T23:02:59.708030395Z 2025-03-21 23:02:59,706 INFO bzip2.Bzip2Factory: Successfully loaded & initialized native-bzip2 library system-native
[pod/worker-0/datanode] 2025-03-21T23:02:59.715971954Z 2025-03-21 23:02:59,715 INFO zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
[pod/worker-0/spark-worker] 2025-03-21T23:03:01.838373161Z Starting org.apache.spark.deploy.worker.Worker on worker-0.worker.submission-b88ebfea875443329ffa71394f4e85fa.svc.cluster.local
[pod/worker-1/datanode] 2025-03-21T23:02:45.069620034Z zlib:    true /lib/x86_64-linux-gnu/libz.so.1
[pod/worker-1/spark-worker] 2025-03-21T23:02:49.055992052Z 25/03/21 23:02:49 INFO SecurityManager: Changing modify acls to: spark
[pod/worker-1/spark-worker] 2025-03-21T23:02:49.057305926Z 25/03/21 23:02:49 INFO SecurityManager: Changing view acls groups to: 
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:25.700731832Z 2025-03-21 23:03:25,700 INFO namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:25.901011879Z 2025-03-21 23:03:25,900 INFO namenode.NameNode: createNameNode [-format, -nonInteractive, hdfs-k8s]
[pod/worker-0/datanode] 2025-03-21T23:02:59.844252391Z 2025-03-21 23:02:59,843 INFO nativeio.NativeIO: The native code was built without PMDK support.
[pod/worker-0/datanode] 2025-03-21T23:02:59.857989054Z Native library checking:
[pod/worker-0/spark-worker] 2025-03-21T23:03:05.743146875Z Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties
[pod/worker-0/spark-worker] 2025-03-21T23:03:05.787739472Z 25/03/21 23:03:05 INFO Worker: Started daemon with process name: 8@worker-0
[pod/worker-1/datanode] 2025-03-21T23:02:45.070005881Z zstd  :  true /lib/x86_64-linux-gnu/libzstd.so.1
[pod/worker-1/datanode] 2025-03-21T23:02:45.070517824Z bzip2:   true /lib/x86_64-linux-gnu/libbz2.so.1
[pod/worker-1/datanode] 2025-03-21T23:02:45.070861760Z openssl: false EVP_CIPHER_CTX_block_size
[pod/worker-1/spark-worker] 2025-03-21T23:02:49.058617361Z 25/03/21 23:02:49 INFO SecurityManager: Changing modify acls groups to: 
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:26.676358074Z 2025-03-21 23:03:26,676 INFO namenode.NameNode: Formatting using clusterid: CID-d9b6df04-7661-475c-aa98-a572511d8eb0
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:26.730719928Z 2025-03-21 23:03:26,730 INFO namenode.FSEditLog: Edit logging is async:false
[pod/worker-0/datanode] 2025-03-21T23:02:59.862328094Z hadoop:  true /opt/hadoop/lib/native/libhadoop.so.1.0.0
[pod/worker-0/spark-worker] 2025-03-21T23:03:05.813894528Z 25/03/21 23:03:05 INFO SignalUtils: Registering signal handler for TERM
[pod/worker-1/datanode] 2025-03-21T23:02:45.071288242Z ISA-L:   true /lib/x86_64-linux-gnu/libisal.so.2
[pod/worker-1/datanode] 2025-03-21T23:02:45.071681627Z PMDK:    false The native code was built without PMDK support.
[pod/worker-1/datanode] 2025-03-21T23:02:45.126842610Z HADOOP_CONF_DIR: /opt/hadoop/etc/hadoop
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:26.787171480Z 2025-03-21 23:03:26,786 INFO namenode.FSNamesystem: KeyProvider: null
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:26.790178140Z 2025-03-21 23:03:26,790 INFO namenode.FSNamesystem: fsLock is fair: true
[pod/worker-0/datanode] 2025-03-21T23:02:59.862795649Z zlib:    true /lib/x86_64-linux-gnu/libz.so.1
[pod/worker-0/datanode] 2025-03-21T23:02:59.863200983Z zstd  :  true /lib/x86_64-linux-gnu/libzstd.so.1
[pod/worker-0/datanode] 2025-03-21T23:02:59.863924529Z bzip2:   true /lib/x86_64-linux-gnu/libbz2.so.1
[pod/worker-0/spark-worker] 2025-03-21T23:03:05.817198179Z 25/03/21 23:03:05 INFO SignalUtils: Registering signal handler for HUP
[pod/worker-0/spark-worker] 2025-03-21T23:03:05.817563318Z 25/03/21 23:03:05 INFO SignalUtils: Registering signal handler for INT
[pod/worker-1/datanode] 2025-03-21T23:02:45.126911865Z HADOOP_LOG_DIR: /var/local/hadoop/logs
[pod/worker-1/spark-worker] 2025-03-21T23:02:49.060037476Z 25/03/21 23:02:49 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(spark); groups with view permissions: Set(); users  with modify permissions: Set(spark); groups with modify permissions: Set()
[pod/worker-1/spark-worker] 2025-03-21T23:02:50.041735625Z 25/03/21 23:02:50 INFO Utils: Successfully started service 'sparkWorker' on port 7078.
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:26.790376844Z 2025-03-21 23:03:26,790 INFO namenode.FSNamesystem: Detailed lock hold time metrics enabled: false
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:26.826530455Z 2025-03-21 23:03:26,826 INFO namenode.FSNamesystem: fsOwner                = hadoop (auth:SIMPLE)
[pod/worker-0/datanode] 2025-03-21T23:02:59.864345146Z openssl: false EVP_CIPHER_CTX_block_size
[pod/worker-0/spark-worker] 2025-03-21T23:03:06.801083783Z 25/03/21 23:03:06 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[pod/worker-1/datanode] 2025-03-21T23:02:45.241096387Z WARNING: /var/local/hadoop/run does not exist. Creating.
[pod/worker-1/spark-worker] 2025-03-21T23:02:50.046129018Z 25/03/21 23:02:50 INFO Worker: Worker decommissioning not enabled.
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:26.826565125Z 2025-03-21 23:03:26,826 INFO namenode.FSNamesystem: supergroup             = supergroup
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:26.826594552Z 2025-03-21 23:03:26,826 INFO namenode.FSNamesystem: isPermissionEnabled    = false
[pod/worker-0/datanode] 2025-03-21T23:02:59.864786089Z ISA-L:   true /lib/x86_64-linux-gnu/libisal.so.2
[pod/worker-0/datanode] 2025-03-21T23:02:59.865228356Z PMDK:    false The native code was built without PMDK support.
[pod/worker-0/datanode] 2025-03-21T23:02:59.931679707Z HADOOP_CONF_DIR: /opt/hadoop/etc/hadoop
[pod/worker-0/spark-worker] 2025-03-21T23:03:06.914864488Z 25/03/21 23:03:06 INFO SecurityManager: Changing view acls to: spark
[pod/worker-0/spark-worker] 2025-03-21T23:03:06.915884801Z 25/03/21 23:03:06 INFO SecurityManager: Changing modify acls to: spark
[pod/worker-0/spark-worker] 2025-03-21T23:03:06.917325437Z 25/03/21 23:03:06 INFO SecurityManager: Changing view acls groups to: 
[pod/worker-1/datanode] 2025-03-21T23:02:45.252663458Z WARNING: /var/local/hadoop/logs does not exist. Creating.
[pod/worker-1/datanode] 2025-03-21T23:02:46.859759889Z 2025-03-21 23:02:46,857 INFO datanode.DataNode: STARTUP_MSG: 
[pod/worker-1/spark-worker] 2025-03-21T23:02:50.658759668Z 25/03/21 23:02:50 INFO Worker: Starting Spark worker worker-1.worker.submission-b88ebfea875443329ffa71394f4e85fa.svc.cluster.local:7078 with 40 cores, 300.0 GiB RAM
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:26.826629992Z 2025-03-21 23:03:26,826 INFO namenode.FSNamesystem: isStoragePolicyEnabled = true
[pod/worker-0/datanode] 2025-03-21T23:02:59.931715397Z HADOOP_LOG_DIR: /var/local/hadoop/logs
[pod/worker-0/spark-worker] 2025-03-21T23:03:06.918732111Z 25/03/21 23:03:06 INFO SecurityManager: Changing modify acls groups to: 
[pod/worker-0/spark-worker] 2025-03-21T23:03:06.920145600Z 25/03/21 23:03:06 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(spark); groups with view permissions: Set(); users  with modify permissions: Set(spark); groups with modify permissions: Set()
[pod/worker-1/spark-worker] 2025-03-21T23:02:50.676181521Z 25/03/21 23:02:50 INFO Worker: Running Spark version 3.3.4
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:26.826876036Z 2025-03-21 23:03:26,826 INFO namenode.FSNamesystem: HA Enabled: false
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:26.899998973Z 2025-03-21 23:03:26,899 INFO common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:27.103589505Z 2025-03-21 23:03:27,103 INFO blockmanagement.DatanodeManager: dfs.block.invalidate.limit : configured=1000, counted=60, effected=1000
[pod/worker-0/datanode] 2025-03-21T23:03:00.045442921Z WARNING: /var/local/hadoop/run does not exist. Creating.
[pod/worker-0/spark-worker] 2025-03-21T23:03:07.750039457Z 25/03/21 23:03:07 INFO Utils: Successfully started service 'sparkWorker' on port 7078.
[pod/worker-0/spark-worker] 2025-03-21T23:03:07.754856541Z 25/03/21 23:03:07 INFO Worker: Worker decommissioning not enabled.
[pod/worker-0/spark-worker] 2025-03-21T23:03:08.316495857Z 25/03/21 23:03:08 INFO Worker: Starting Spark worker worker-0.worker.submission-b88ebfea875443329ffa71394f4e85fa.svc.cluster.local:7078 with 40 cores, 300.0 GiB RAM
[pod/worker-0/spark-worker] 2025-03-21T23:03:08.339019521Z 25/03/21 23:03:08 INFO Worker: Running Spark version 3.3.4
[pod/worker-1/datanode] 2025-03-21T23:02:46.859828479Z /************************************************************
[pod/worker-1/datanode] 2025-03-21T23:02:46.859836719Z STARTUP_MSG: Starting DataNode
[pod/worker-1/spark-worker] 2025-03-21T23:02:50.677454853Z 25/03/21 23:02:50 INFO Worker: Spark home: /opt/spark
[pod/worker-1/spark-worker] 2025-03-21T23:02:50.732275303Z 25/03/21 23:02:50 INFO ResourceUtils: ==============================================================
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:27.103673675Z 2025-03-21 23:03:27,103 INFO blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=false
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:27.108079934Z 2025-03-21 23:03:27,107 INFO blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
[pod/worker-0/datanode] 2025-03-21T23:03:00.057564360Z WARNING: /var/local/hadoop/logs does not exist. Creating.
[pod/worker-0/datanode] 2025-03-21T23:03:01.774767024Z 2025-03-21 23:03:01,772 INFO datanode.DataNode: STARTUP_MSG: 
[pod/worker-0/datanode] 2025-03-21T23:03:01.774819534Z /************************************************************
[pod/worker-0/spark-worker] 2025-03-21T23:03:08.340686299Z 25/03/21 23:03:08 INFO Worker: Spark home: /opt/spark
[pod/worker-1/datanode] 2025-03-21T23:02:46.859843666Z STARTUP_MSG:   host = worker-1/192.168.172.208
[pod/worker-1/spark-worker] 2025-03-21T23:02:50.733310784Z 25/03/21 23:02:50 INFO ResourceUtils: No custom resources configured for spark.worker.
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:27.108458051Z 2025-03-21 23:03:27,108 INFO blockmanagement.BlockManager: The block deletion will start around 2025 Mar 21 23:03:27
[pod/worker-0/datanode] 2025-03-21T23:03:01.774826964Z STARTUP_MSG: Starting DataNode
[pod/worker-0/datanode] 2025-03-21T23:03:01.774833079Z STARTUP_MSG:   host = worker-0/192.168.84.177
[pod/worker-0/datanode] 2025-03-21T23:03:01.774839059Z STARTUP_MSG:   args = []
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:27.110182765Z 2025-03-21 23:03:27,110 INFO util.GSet: Computing capacity for map BlocksMap
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:27.110204651Z 2025-03-21 23:03:27,110 INFO util.GSet: VM type       = 64-bit
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:27.111635160Z 2025-03-21 23:03:27,111 INFO util.GSet: 2.0% max memory 1 GB = 20.5 MB
[pod/worker-0/datanode] 2025-03-21T23:03:01.774844492Z STARTUP_MSG:   version = 3.3.6
[pod/worker-0/spark-worker] 2025-03-21T23:03:08.392810845Z 25/03/21 23:03:08 INFO ResourceUtils: ==============================================================
[pod/worker-0/spark-worker] 2025-03-21T23:03:08.393888076Z 25/03/21 23:03:08 INFO ResourceUtils: No custom resources configured for spark.worker.
[pod/worker-0/spark-worker] 2025-03-21T23:03:08.394945849Z 25/03/21 23:03:08 INFO ResourceUtils: ==============================================================
[pod/worker-1/datanode] 2025-03-21T23:02:46.859849791Z STARTUP_MSG:   args = []
[pod/worker-1/spark-worker] 2025-03-21T23:02:50.734351542Z 25/03/21 23:02:50 INFO ResourceUtils: ==============================================================
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:27.111653749Z 2025-03-21 23:03:27,111 INFO util.GSet: capacity      = 2^21 = 2097152 entries
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:27.126807303Z 2025-03-21 23:03:27,126 INFO blockmanagement.BlockManager: Storage policy satisfier is disabled
[pod/worker-0/spark-worker] 2025-03-21T23:03:08.805647413Z 25/03/21 23:03:08 INFO Utils: Successfully started service 'WorkerUI' on port 8081.
[pod/worker-1/datanode] 2025-03-21T23:02:46.859856364Z STARTUP_MSG:   version = 3.3.6
[pod/worker-1/spark-worker] 2025-03-21T23:02:51.146582915Z 25/03/21 23:02:51 INFO Utils: Successfully started service 'WorkerUI' on port 8081.
[pod/worker-1/spark-worker] 2025-03-21T23:02:51.243988393Z 25/03/21 23:02:51 INFO WorkerWebUI: Bound WorkerWebUI to 0.0.0.0, and started at http://worker-1.worker.submission-b88ebfea875443329ffa71394f4e85fa.svc.cluster.local:8081
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:27.126857013Z 2025-03-21 23:03:27,126 INFO blockmanagement.BlockManager: dfs.block.access.token.enable = false
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:27.133995509Z 2025-03-21 23:03:27,133 INFO blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.threshold-pct = 0.999
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:27.134029652Z 2025-03-21 23:03:27,133 INFO blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.min.datanodes = 0
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:27.134066200Z 2025-03-21 23:03:27,133 INFO blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.extension = 30000
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:27.135298558Z 2025-03-21 23:03:27,135 INFO blockmanagement.BlockManager: defaultReplication         = 3
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:27.135329666Z 2025-03-21 23:03:27,135 INFO blockmanagement.BlockManager: maxReplication             = 512
[pod/worker-1/spark-worker] 2025-03-21T23:02:51.250498617Z 25/03/21 23:02:51 INFO Worker: Connecting to master spark-master.submission-b88ebfea875443329ffa71394f4e85fa.svc.cluster.local:7077...
[pod/worker-1/spark-worker] 2025-03-21T23:02:51.425716785Z 25/03/21 23:02:51 WARN Worker: Failed to connect to master spark-master.submission-b88ebfea875443329ffa71394f4e85fa.svc.cluster.local:7077
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:27.135347401Z 2025-03-21 23:03:27,135 INFO blockmanagement.BlockManager: minReplication             = 1
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:27.135419789Z 2025-03-21 23:03:27,135 INFO blockmanagement.BlockManager: maxReplicationStreams      = 2
[pod/worker-1/spark-worker] 2025-03-21T23:02:51.425754531Z org.apache.spark.SparkException: Exception thrown in awaitResult: 
[pod/worker-1/spark-worker] 2025-03-21T23:02:51.425760170Z 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[pod/worker-0/spark-worker] 2025-03-21T23:03:08.912609786Z 25/03/21 23:03:08 INFO WorkerWebUI: Bound WorkerWebUI to 0.0.0.0, and started at http://worker-0.worker.submission-b88ebfea875443329ffa71394f4e85fa.svc.cluster.local:8081
[pod/worker-0/spark-worker] 2025-03-21T23:03:08.918870556Z 25/03/21 23:03:08 INFO Worker: Connecting to master spark-master.submission-b88ebfea875443329ffa71394f4e85fa.svc.cluster.local:7077...
[pod/worker-1/spark-worker] 2025-03-21T23:02:51.425764838Z 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[pod/worker-1/spark-worker] 2025-03-21T23:02:51.425769547Z 	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:27.135480521Z 2025-03-21 23:03:27,135 INFO blockmanagement.BlockManager: redundancyRecheckInterval  = 3000ms
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:27.135529620Z 2025-03-21 23:03:27,135 INFO blockmanagement.BlockManager: encryptDataTransfer        = false
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:27.135578428Z 2025-03-21 23:03:27,135 INFO blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:27.179057941Z 2025-03-21 23:03:27,178 INFO namenode.FSDirectory: GLOBAL serial map: bits=29 maxEntries=536870911
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:27.179125790Z 2025-03-21 23:03:27,178 INFO namenode.FSDirectory: USER serial map: bits=24 maxEntries=16777215
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:27.179129854Z 2025-03-21 23:03:27,178 INFO namenode.FSDirectory: GROUP serial map: bits=24 maxEntries=16777215
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:27.179144233Z 2025-03-21 23:03:27,178 INFO namenode.FSDirectory: XATTR serial map: bits=24 maxEntries=16777215
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:27.194052402Z 2025-03-21 23:03:27,193 INFO util.GSet: Computing capacity for map INodeMap
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:27.194099229Z 2025-03-21 23:03:27,193 INFO util.GSet: VM type       = 64-bit
[pod/worker-0/datanode] 2025-03-21T23:03:01.774957196Z STARTUP_MSG:   classpath = /opt/hadoop/etc/hadoop:/opt/hadoop/share/hadoop/common/lib/jettison-1.5.4.jar:/opt/hadoop/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/hadoop/common/lib/curator-framework-5.2.0.jar:/opt/hadoop/share/hadoop/common/lib/jetty-security-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/common/lib/jackson-databind-2.12.7.1.jar:/opt/hadoop/share/hadoop/common/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/hadoop/common/lib/curator-recipes-5.2.0.jar:/opt/hadoop/share/hadoop/common/lib/netty-transport-classes-epoll-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/commons-net-3.9.0.jar:/opt/hadoop/share/hadoop/common/lib/jsr305-3.0.2.jar:/opt/hadoop/share/hadoop/common/lib/audience-annotations-0.5.0.jar:/opt/hadoop/share/hadoop/common/lib/netty-codec-stomp-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/netty-codec-mqtt-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/animal-sniffer-annotations-1.17.jar:/opt/hadoop/share/hadoop/common/lib/guava-27.0-jre.jar:/opt/hadoop/share/hadoop/common/lib/netty-codec-socks-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/jetty-util-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/netty-common-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/jersey-server-1.19.4.jar:/opt/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop/share/hadoop/common/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/hadoop/common/lib/netty-codec-smtp-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/hadoop/common/lib/avro-1.7.7.jar:/opt/hadoop/share/hadoop/common/lib/jetty-io-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/common/lib/netty-transport-sctp-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/hadoop/common/lib/nimbus-jose-jwt-9.8.1.jar:/opt/hadoop/share/hadoop/common/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/jackson-core-2.12.7.jar:/opt/hadoop/share/hadoop/common/lib/commons-codec-1.15.jar:/opt/hadoop/share/hadoop/common/lib/failureaccess-1.0.jar:/opt/hadoop/share/hadoop/common/lib/gson-2.9.0.jar:/opt/hadoop/share/hadoop/common/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/hadoop/common/lib/commons-compress-1.21.jar:/opt/hadoop/share/hadoop/common/lib/netty-resolver-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/hadoop/common/lib/netty-codec-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/hadoop/common/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/netty-transport-native-unix-common-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/woodstox-core-5.4.0.jar:/opt/hadoop/share/hadoop/common/lib/commons-text-1.10.0.jar:/opt/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop/share/hadoop/common/lib/jersey-servlet-1.19.4.jar:/opt/hadoop/share/hadoop/common/lib/netty-codec-haproxy-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/netty-transport-native-epoll-4.1.89.Final-linux-aarch_64.jar:/opt/hadoop/share/hadoop/common/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/hadoop/common/lib/jetty-http-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/common/lib/jetty-util-ajax-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/common/lib/netty-transport-native-kqueue-4.1.89.Final-osx-aarch_64.jar:/opt/hadoop/share/hadoop/common/lib/httpclient-4.5.13.jar:/opt/hadoop/share/hadoop/common/lib/curator-client-5.2.0.jar:/opt/hadoop/share/hadoop/common/lib/netty-transport-native-epoll-4.1.89.Final-linux-x86_64.jar:/opt/hadoop/share/hadoop/common/lib/jetty-servlet-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/common/lib/httpcore-4.4.13.jar:/opt/hadoop/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/netty-codec-http2-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/hadoop/common/lib/netty-codec-redis-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/slf4j-reload4j-1.7.36.jar:/opt/hadoop/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/netty-handler-ssl-ocsp-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/hadoop/common/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/netty-handler-proxy-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/netty-codec-xml-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/netty-resolver-dns-native-macos-4.1.89.Final-osx-aarch_64.jar:/opt/hadoop/share/hadoop/common/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/hadoop/common/lib/netty-resolver-dns-classes-macos-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/re2j-1.1.jar:/opt/hadoop/share/hadoop/common/lib/commons-lang3-3.12.0.jar:/opt/hadoop/share/hadoop/common/lib/netty-transport-classes-kqueue-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/netty-buffer-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/netty-transport-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/hadoop/common/lib/netty-transport-rxtx-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/zookeeper-3.6.3.jar:/opt/hadoop/share/hadoop/common/lib/jul-to-slf4j-1.7.36.jar:/opt/hadoop/share/hadoop/common/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/hadoop/common/lib/checker-qual-2.5.2.jar:/opt/hadoop/share/hadoop/common/lib/stax2-api-4.2.1.jar:/opt/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop/share/hadoop/common/lib/hadoop-annotations-3.3.6.jar:/opt/hadoop/share/hadoop/common/lib/netty-handler-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/netty-codec-dns-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/netty-codec-http-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/commons-io-2.8.0.jar:/opt/hadoop/share/hadoop/common/lib/jersey-json-1.20.jar:/opt/hadoop/share/hadoop/common/lib/netty-all-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/netty-codec-memcache-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/zookeeper-jute-3.6.3.jar:/opt/hadoop/share/hadoop/common/lib/jackson-annotations-2.12.7.jar:/opt/hadoop/share/hadoop/common/lib/jetty-xml-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/common/lib/netty-resolver-dns-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/token-provider-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/netty-resolver-dns-native-macos-4.1.89.Final-osx-x86_64.jar:/opt/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/hadoop/common/lib/slf4j-api-1.7.36.jar:/opt/hadoop/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/opt/hadoop/share/hadoop/common/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/hadoop/common/lib/j2objc-annotations-1.1.jar:/opt/hadoop/share/hadoop/common/lib/jersey-core-1.19.4.jar:/opt/hadoop/share/hadoop/common/lib/jetty-server-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/netty-transport-udt-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/commons-configuration2-2.8.0.jar:/opt/hadoop/share/hadoop/common/lib/jetty-webapp-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop/share/hadoop/common/lib/netty-transport-native-kqueue-4.1.89.Final-osx-x86_64.jar:/opt/hadoop/share/hadoop/common/lib/jsch-0.1.55.jar:/opt/hadoop/share/hadoop/common/lib/reload4j-1.2.22.jar:/opt/hadoop/share/hadoop/common/lib/hadoop-auth-3.3.6.jar:/opt/hadoop/share/hadoop/common/hadoop-nfs-3.3.6.jar:/opt/hadoop/share/hadoop/common/hadoop-registry-3.3.6.jar:/opt/hadoop/share/hadoop/common/hadoop-common-3.3.6.jar:/opt/hadoop/share/hadoop/common/hadoop-common-3.3.6-tests.jar:/opt/hadoop/share/hadoop/common/hadoop-kms-3.3.6.jar:/opt/hadoop/share/hadoop/hdfs:/opt/hadoop/share/hadoop/hdfs/lib/checker-qual-2.5.2.jar:/opt/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-resolver-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-handler-ssl-ocsp-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/hadoop-annotations-3.3.6.jar:/opt/hadoop/share/hadoop/hdfs/lib/guava-27.0-jre.jar:/opt/hadoop/share/hadoop/hdfs/lib/gson-2.9.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-transport-native-epoll-4.1.89.Final-linux-x86_64.jar:/opt/hadoop/share/hadoop/hdfs/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/audience-annotations-0.5.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-handler-proxy-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/zookeeper-jute-3.6.3.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-compress-1.21.jar:/opt/hadoop/share/hadoop/hdfs/lib/httpclient-4.5.13.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/hadoop/hdfs/lib/jetty-http-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-3.10.6.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/re2j-1.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/jettison-1.5.4.jar:/opt/hadoop/share/hadoop/hdfs/lib/jetty-util-ajax-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/hdfs/lib/okhttp-4.9.3.jar:/opt/hadoop/share/hadoop/hdfs/lib/jersey-servlet-1.19.4.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-transport-native-kqueue-4.1.89.Final-osx-x86_64.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/curator-client-5.2.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-transport-udt-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/jetty-security-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/hdfs/lib/jackson-databind-2.12.7.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/hadoop/hdfs/lib/jetty-servlet-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop/share/hadoop/hdfs/lib/jersey-core-1.19.4.jar:/opt/hadoop/share/hadoop/hdfs/lib/kotlin-stdlib-1.4.10.jar:/opt/hadoop/share/hadoop/hdfs/lib/curator-recipes-5.2.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-codec-http2-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/hadoop-auth-3.3.6.jar:/opt/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.2.jar:/opt/hadoop/share/hadoop/hdfs/lib/jetty-server-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/paranamer-2.3.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-transport-sctp-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-codec-redis-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/jetty-webapp-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-lang3-3.12.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/animal-sniffer-annotations-1.17.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-transport-classes-kqueue-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-codec-http-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-common-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/jetty-util-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/hdfs/lib/avro-1.7.7.jar:/opt/hadoop/share/hadoop/hdfs/lib/nimbus-jose-jwt-9.8.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-transport-native-unix-common-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/jetty-io-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-text-1.10.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-transport-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-transport-native-epoll-4.1.89.Final-linux-aarch_64.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-io-2.8.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/jersey-json-1.20.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-transport-classes-epoll-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-codec-smtp-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-all-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/jsch-0.1.55.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-codec-xml-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/woodstox-core-5.4.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/HikariCP-java7-2.4.12.jar:/opt/hadoop/share/hadoop/hdfs/lib/j2objc-annotations-1.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-native-macos-4.1.89.Final-osx-x86_64.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/kotlin-stdlib-common-1.4.10.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/reload4j-1.2.22.jar:/opt/hadoop/share/hadoop/hdfs/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/opt/hadoop/share/hadoop/hdfs/lib/jackson-core-2.12.7.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-codec-mqtt-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-classes-macos-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-codec-memcache-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-net-3.9.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-configuration2-2.8.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-codec-haproxy-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-handler-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-native-macos-4.1.89.Final-osx-aarch_64.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-transport-native-kqueue-4.1.89.Final-osx-aarch_64.jar:/opt/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-transport-rxtx-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-codec-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/hadoop/hdfs/lib/jackson-annotations-2.12.7.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-codec-stomp-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/hadoop/hdfs/lib/httpcore-4.4.13.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-codec-socks-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/jersey-server-1.19.4.jar:/opt/hadoop/share/hadoop/hdfs/lib/curator-framework-5.2.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/zookeeper-3.6.3.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/hadoop/hdfs/lib/jetty-xml-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/stax2-api-4.2.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-codec-dns-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-codec-1.15.jar:/opt/hadoop/share/hadoop/hdfs/lib/okio-2.8.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-buffer-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/failureaccess-1.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.3.6-tests.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.3.6-tests.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.3.6.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.3.6.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.3.6.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-3.3.6.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.3.6-tests.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.3.6.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.3.6.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.3.6-tests.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.3.6.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.3.6.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.3.6.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.3.6.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.3.6.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.3.6.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.3.6.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.3.6.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.3.6.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.3.6.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.3.6-tests.jar:/opt/hadoop/share/hadoop/yarn:/opt/hadoop/share/hadoop/yarn/lib/asm-commons-9.4.jar:/opt/hadoop/share/hadoop/yarn/lib/java-util-1.9.0.jar:/opt/hadoop/share/hadoop/yarn/lib/snakeyaml-2.0.jar:/opt/hadoop/share/hadoop/yarn/lib/websocket-server-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/opt/hadoop/share/hadoop/yarn/lib/jetty-jndi-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/yarn/lib/websocket-api-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/yarn/lib/jetty-plus-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/yarn/lib/asm-tree-9.4.jar:/opt/hadoop/share/hadoop/yarn/lib/websocket-servlet-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/yarn/lib/jersey-client-1.19.4.jar:/opt/hadoop/share/hadoop/yarn/lib/jline-3.9.0.jar:/opt/hadoop/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/opt/hadoop/share/hadoop/yarn/lib/javax-websocket-client-impl-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/opt/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-base-2.12.7.jar:/opt/hadoop/share/hadoop/yarn/lib/websocket-client-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/yarn/lib/javax.websocket-api-1.0.jar:/opt/hadoop/share/hadoop/yarn/lib/javax-websocket-server-impl-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/yarn/lib/jersey-guice-1.19.4.jar:/opt/hadoop/share/hadoop/yarn/lib/jetty-annotations-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/yarn/lib/websocket-common-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/yarn/lib/bcpkix-jdk15on-1.68.jar:/opt/hadoop/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/opt/hadoop/share/hadoop/yarn/lib/objenesis-2.6.jar:/opt/hadoop/share/hadoop/yarn/lib/json-io-2.5.1.jar:/opt/hadoop/share/hadoop/yarn/lib/guice-4.0.jar:/opt/hadoop/share/hadoop/yarn/lib/bcprov-jdk15on-1.68.jar:/opt/hadoop/share/hadoop/yarn/lib/jakarta.xml.bind-api-2.3.2.jar:/opt/hadoop/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.12.7.jar:/opt/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.12.7.jar:/opt/hadoop/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/opt/hadoop/share/hadoop/yarn/lib/jna-5.2.0.jar:/opt/hadoop/share/hadoop/yarn/lib/fst-2.50.jar:/opt/hadoop/share/hadoop/yarn/lib/javax.websocket-client-api-1.0.jar:/opt/hadoop/share/hadoop/yarn/lib/jetty-client-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-services-core-3.3.6.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.3.6.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.3.6.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-3.3.6.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.3.6.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.3.6.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.3.6.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-client-3.3.6.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-api-3.3.6.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-common-3.3.6.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-3.3.6.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-services-api-3.3.6.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-router-3.3.6.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-applications-mawo-core-3.3.6.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.3.6.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.3.6.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.3.6.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-registry-3.3.6.jar
[pod/worker-0/datanode] 2025-03-21T23:03:01.775111257Z STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r 1be78238728da9266a4f88195058f08fd012bf9c; compiled by 'ubuntu' on 2023-06-18T08:22Z
[pod/worker-0/datanode] 2025-03-21T23:03:01.775119254Z STARTUP_MSG:   java = 11.0.26
[pod/worker-0/datanode] 2025-03-21T23:03:01.775124757Z ************************************************************/
[pod/worker-0/datanode] 2025-03-21T23:03:01.795927280Z 2025-03-21 23:03:01,795 INFO datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
[pod/worker-0/datanode] 2025-03-21T23:03:02.800220699Z 2025-03-21 23:03:02,799 INFO checker.ThrottledAsyncChecker: Scheduling a check for [DISK]file:/var/local/hadoop/data
[pod/worker-0/datanode] 2025-03-21T23:03:03.134843916Z 2025-03-21 23:03:03,134 INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
[pod/worker-0/datanode] 2025-03-21T23:03:03.414722739Z 2025-03-21 23:03:03,413 INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
[pod/worker-0/datanode] 2025-03-21T23:03:03.414782394Z 2025-03-21 23:03:03,414 INFO impl.MetricsSystemImpl: DataNode metrics system started
[pod/worker-0/datanode] 2025-03-21T23:03:04.012399598Z 2025-03-21 23:03:04,012 INFO common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
[pod/worker-0/datanode] 2025-03-21T23:03:04.049005586Z 2025-03-21 23:03:04,048 INFO datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
[pod/worker-0/datanode] 2025-03-21T23:03:04.062289507Z 2025-03-21 23:03:04,061 INFO datanode.DataNode: Configured hostname is worker-0.worker.submission-b88ebfea875443329ffa71394f4e85fa.svc.cluster.local
[pod/worker-0/datanode] 2025-03-21T23:03:04.063296895Z 2025-03-21 23:03:04,063 INFO common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
[pod/worker-0/datanode] 2025-03-21T23:03:04.073787036Z 2025-03-21 23:03:04,073 INFO datanode.DataNode: Starting DataNode with maxLockedMemory = 0
[pod/worker-1/datanode] 2025-03-21T23:02:46.859985851Z STARTUP_MSG:   classpath = /opt/hadoop/etc/hadoop:/opt/hadoop/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/hadoop/common/lib/netty-codec-stomp-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/netty-resolver-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/hadoop/common/lib/commons-configuration2-2.8.0.jar:/opt/hadoop/share/hadoop/common/lib/netty-resolver-dns-native-macos-4.1.89.Final-osx-aarch_64.jar:/opt/hadoop/share/hadoop/common/lib/netty-codec-memcache-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/jetty-webapp-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/common/lib/jsch-0.1.55.jar:/opt/hadoop/share/hadoop/common/lib/jetty-server-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/common/lib/jettison-1.5.4.jar:/opt/hadoop/share/hadoop/common/lib/jetty-http-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/common/lib/netty-codec-http-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/opt/hadoop/share/hadoop/common/lib/netty-transport-classes-kqueue-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/netty-transport-udt-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/reload4j-1.2.22.jar:/opt/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/hadoop/common/lib/httpclient-4.5.13.jar:/opt/hadoop/share/hadoop/common/lib/netty-codec-dns-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/hadoop/common/lib/jul-to-slf4j-1.7.36.jar:/opt/hadoop/share/hadoop/common/lib/netty-handler-ssl-ocsp-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/hadoop/common/lib/netty-codec-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/netty-codec-socks-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/guava-27.0-jre.jar:/opt/hadoop/share/hadoop/common/lib/hadoop-auth-3.3.6.jar:/opt/hadoop/share/hadoop/common/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/hadoop/common/lib/httpcore-4.4.13.jar:/opt/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/hadoop/common/lib/jersey-server-1.19.4.jar:/opt/hadoop/share/hadoop/common/lib/netty-common-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop/share/hadoop/common/lib/jetty-util-ajax-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/common/lib/netty-transport-classes-epoll-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/hadoop/common/lib/jackson-annotations-2.12.7.jar:/opt/hadoop/share/hadoop/common/lib/slf4j-reload4j-1.7.36.jar:/opt/hadoop/share/hadoop/common/lib/netty-transport-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/commons-codec-1.15.jar:/opt/hadoop/share/hadoop/common/lib/jetty-io-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/common/lib/netty-transport-native-kqueue-4.1.89.Final-osx-x86_64.jar:/opt/hadoop/share/hadoop/common/lib/netty-handler-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/netty-codec-xml-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/jetty-security-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/common/lib/netty-transport-native-epoll-4.1.89.Final-linux-x86_64.jar:/opt/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop/share/hadoop/common/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/netty-handler-proxy-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/jackson-databind-2.12.7.1.jar:/opt/hadoop/share/hadoop/common/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/hadoop/common/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/jetty-xml-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/common/lib/animal-sniffer-annotations-1.17.jar:/opt/hadoop/share/hadoop/common/lib/curator-framework-5.2.0.jar:/opt/hadoop/share/hadoop/common/lib/stax2-api-4.2.1.jar:/opt/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop/share/hadoop/common/lib/netty-transport-native-epoll-4.1.89.Final-linux-aarch_64.jar:/opt/hadoop/share/hadoop/common/lib/zookeeper-3.6.3.jar:/opt/hadoop/share/hadoop/common/lib/jetty-util-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/common/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/hadoop/common/lib/netty-transport-rxtx-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/hadoop/common/lib/netty-codec-redis-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/slf4j-api-1.7.36.jar:/opt/hadoop/share/hadoop/common/lib/netty-codec-http2-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/audience-annotations-0.5.0.jar:/opt/hadoop/share/hadoop/common/lib/commons-compress-1.21.jar:/opt/hadoop/share/hadoop/common/lib/token-provider-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/jetty-servlet-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/netty-resolver-dns-native-macos-4.1.89.Final-osx-x86_64.jar:/opt/hadoop/share/hadoop/common/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/hadoop/common/lib/jersey-servlet-1.19.4.jar:/opt/hadoop/share/hadoop/common/lib/checker-qual-2.5.2.jar:/opt/hadoop/share/hadoop/common/lib/commons-net-3.9.0.jar:/opt/hadoop/share/hadoop/common/lib/gson-2.9.0.jar:/opt/hadoop/share/hadoop/common/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/commons-io-2.8.0.jar:/opt/hadoop/share/hadoop/common/lib/jersey-json-1.20.jar:/opt/hadoop/share/hadoop/common/lib/netty-codec-haproxy-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/netty-resolver-dns-classes-macos-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/jsr305-3.0.2.jar:/opt/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/hadoop/common/lib/zookeeper-jute-3.6.3.jar:/opt/hadoop/share/hadoop/common/lib/netty-resolver-dns-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/curator-recipes-5.2.0.jar:/opt/hadoop/share/hadoop/common/lib/avro-1.7.7.jar:/opt/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop/share/hadoop/common/lib/commons-lang3-3.12.0.jar:/opt/hadoop/share/hadoop/common/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/jackson-core-2.12.7.jar:/opt/hadoop/share/hadoop/common/lib/netty-all-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/netty-buffer-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/netty-codec-smtp-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/hadoop/common/lib/curator-client-5.2.0.jar:/opt/hadoop/share/hadoop/common/lib/hadoop-annotations-3.3.6.jar:/opt/hadoop/share/hadoop/common/lib/woodstox-core-5.4.0.jar:/opt/hadoop/share/hadoop/common/lib/nimbus-jose-jwt-9.8.1.jar:/opt/hadoop/share/hadoop/common/lib/failureaccess-1.0.jar:/opt/hadoop/share/hadoop/common/lib/jersey-core-1.19.4.jar:/opt/hadoop/share/hadoop/common/lib/j2objc-annotations-1.1.jar:/opt/hadoop/share/hadoop/common/lib/netty-codec-mqtt-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/netty-transport-native-kqueue-4.1.89.Final-osx-aarch_64.jar:/opt/hadoop/share/hadoop/common/lib/netty-transport-sctp-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/hadoop/common/lib/re2j-1.1.jar:/opt/hadoop/share/hadoop/common/lib/netty-transport-native-unix-common-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/commons-text-1.10.0.jar:/opt/hadoop/share/hadoop/common/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/hadoop/common/hadoop-registry-3.3.6.jar:/opt/hadoop/share/hadoop/common/hadoop-nfs-3.3.6.jar:/opt/hadoop/share/hadoop/common/hadoop-common-3.3.6-tests.jar:/opt/hadoop/share/hadoop/common/hadoop-common-3.3.6.jar:/opt/hadoop/share/hadoop/common/hadoop-kms-3.3.6.jar:/opt/hadoop/share/hadoop/hdfs:/opt/hadoop/share/hadoop/hdfs/lib/guava-27.0-jre.jar:/opt/hadoop/share/hadoop/hdfs/lib/httpclient-4.5.13.jar:/opt/hadoop/share/hadoop/hdfs/lib/jetty-servlet-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/hdfs/lib/checker-qual-2.5.2.jar:/opt/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-codec-xml-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/jsch-0.1.55.jar:/opt/hadoop/share/hadoop/hdfs/lib/curator-framework-5.2.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-native-macos-4.1.89.Final-osx-x86_64.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-transport-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-codec-redis-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/hadoop/hdfs/lib/jackson-databind-2.12.7.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-codec-http2-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/hadoop/hdfs/lib/jettison-1.5.4.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-3.10.6.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/jetty-io-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/hdfs/lib/gson-2.9.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.2.jar:/opt/hadoop/share/hadoop/hdfs/lib/HikariCP-java7-2.4.12.jar:/opt/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-common-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-codec-smtp-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/jetty-xml-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-handler-ssl-ocsp-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/kotlin-stdlib-common-1.4.10.jar:/opt/hadoop/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/jersey-core-1.19.4.jar:/opt/hadoop/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-configuration2-2.8.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/avro-1.7.7.jar:/opt/hadoop/share/hadoop/hdfs/lib/re2j-1.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/okhttp-4.9.3.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-codec-dns-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-transport-sctp-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-handler-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-codec-haproxy-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-classes-macos-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/hadoop-annotations-3.3.6.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-codec-mqtt-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/hadoop/hdfs/lib/jersey-server-1.19.4.jar:/opt/hadoop/share/hadoop/hdfs/lib/jackson-annotations-2.12.7.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-transport-native-kqueue-4.1.89.Final-osx-aarch_64.jar:/opt/hadoop/share/hadoop/hdfs/lib/hadoop-auth-3.3.6.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-transport-native-kqueue-4.1.89.Final-osx-x86_64.jar:/opt/hadoop/share/hadoop/hdfs/lib/jetty-server-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/hdfs/lib/paranamer-2.3.jar:/opt/hadoop/share/hadoop/hdfs/lib/httpcore-4.4.13.jar:/opt/hadoop/share/hadoop/hdfs/lib/zookeeper-jute-3.6.3.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-compress-1.21.jar:/opt/hadoop/share/hadoop/hdfs/lib/jetty-webapp-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-codec-memcache-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-codec-stomp-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/jetty-util-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-native-macos-4.1.89.Final-osx-aarch_64.jar:/opt/hadoop/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-net-3.9.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/jetty-util-ajax-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/hdfs/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-buffer-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/jersey-servlet-1.19.4.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-codec-socks-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-codec-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/audience-annotations-0.5.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/stax2-api-4.2.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-transport-native-unix-common-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-codec-http-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-handler-proxy-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/zookeeper-3.6.3.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-all-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/kotlin-stdlib-1.4.10.jar:/opt/hadoop/share/hadoop/hdfs/lib/curator-recipes-5.2.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/jetty-http-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/animal-sniffer-annotations-1.17.jar:/opt/hadoop/share/hadoop/hdfs/lib/okio-2.8.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-transport-classes-epoll-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/jackson-core-2.12.7.jar:/opt/hadoop/share/hadoop/hdfs/lib/curator-client-5.2.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/failureaccess-1.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-transport-native-epoll-4.1.89.Final-linux-x86_64.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-transport-classes-kqueue-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/jetty-security-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-transport-rxtx-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-transport-native-epoll-4.1.89.Final-linux-aarch_64.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/nimbus-jose-jwt-9.8.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-text-1.10.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-transport-udt-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-resolver-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-codec-1.15.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-lang3-3.12.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/reload4j-1.2.22.jar:/opt/hadoop/share/hadoop/hdfs/lib/woodstox-core-5.4.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/jersey-json-1.20.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-io-2.8.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/j2objc-annotations-1.1.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.3.6-tests.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.3.6-tests.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.3.6.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-3.3.6.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.3.6.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.3.6-tests.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.3.6.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.3.6.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.3.6-tests.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.3.6.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.3.6.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.3.6.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.3.6.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.3.6-tests.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.3.6.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.3.6.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.3.6.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.3.6.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.3.6.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.3.6.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.3.6.jar:/opt/hadoop/share/hadoop/yarn:/opt/hadoop/share/hadoop/yarn/lib/bcpkix-jdk15on-1.68.jar:/opt/hadoop/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/opt/hadoop/share/hadoop/yarn/lib/jetty-annotations-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/yarn/lib/jna-5.2.0.jar:/opt/hadoop/share/hadoop/yarn/lib/bcprov-jdk15on-1.68.jar:/opt/hadoop/share/hadoop/yarn/lib/java-util-1.9.0.jar:/opt/hadoop/share/hadoop/yarn/lib/guice-4.0.jar:/opt/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.12.7.jar:/opt/hadoop/share/hadoop/yarn/lib/javax-websocket-client-impl-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/yarn/lib/snakeyaml-2.0.jar:/opt/hadoop/share/hadoop/yarn/lib/asm-commons-9.4.jar:/opt/hadoop/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/opt/hadoop/share/hadoop/yarn/lib/websocket-server-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-base-2.12.7.jar:/opt/hadoop/share/hadoop/yarn/lib/javax.websocket-client-api-1.0.jar:/opt/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop/share/hadoop/yarn/lib/jersey-guice-1.19.4.jar:/opt/hadoop/share/hadoop/yarn/lib/jakarta.xml.bind-api-2.3.2.jar:/opt/hadoop/share/hadoop/yarn/lib/websocket-servlet-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/yarn/lib/websocket-common-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/yarn/lib/javax.websocket-api-1.0.jar:/opt/hadoop/share/hadoop/yarn/lib/jersey-client-1.19.4.jar:/opt/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop/share/hadoop/yarn/lib/fst-2.50.jar:/opt/hadoop/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.12.7.jar:/opt/hadoop/share/hadoop/yarn/lib/jetty-jndi-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/yarn/lib/jetty-plus-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/yarn/lib/json-io-2.5.1.jar:/opt/hadoop/share/hadoop/yarn/lib/objenesis-2.6.jar:/opt/hadoop/share/hadoop/yarn/lib/asm-tree-9.4.jar:/opt/hadoop/share/hadoop/yarn/lib/websocket-api-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/opt/hadoop/share/hadoop/yarn/lib/jline-3.9.0.jar:/opt/hadoop/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/opt/hadoop/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/opt/hadoop/share/hadoop/yarn/lib/websocket-client-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/yarn/lib/javax-websocket-server-impl-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/yarn/lib/jetty-client-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.3.6.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.3.6.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-router-3.3.6.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.3.6.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.3.6.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-api-3.3.6.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.3.6.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.3.6.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-registry-3.3.6.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.3.6.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-applications-mawo-core-3.3.6.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-services-core-3.3.6.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-client-3.3.6.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.3.6.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-common-3.3.6.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-services-api-3.3.6.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-3.3.6.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-3.3.6.jar
[pod/worker-1/datanode] 2025-03-21T23:02:46.860157261Z STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r 1be78238728da9266a4f88195058f08fd012bf9c; compiled by 'ubuntu' on 2023-06-18T08:22Z
[pod/worker-1/datanode] 2025-03-21T23:02:46.860164071Z STARTUP_MSG:   java = 11.0.26
[pod/worker-1/datanode] 2025-03-21T23:02:46.860170045Z ************************************************************/
[pod/worker-1/datanode] 2025-03-21T23:02:46.881797217Z 2025-03-21 23:02:46,881 INFO datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
[pod/worker-1/datanode] 2025-03-21T23:02:47.887147530Z 2025-03-21 23:02:47,886 INFO checker.ThrottledAsyncChecker: Scheduling a check for [DISK]file:/var/local/hadoop/data
[pod/worker-1/datanode] 2025-03-21T23:02:48.218460038Z 2025-03-21 23:02:48,217 INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
[pod/worker-1/datanode] 2025-03-21T23:02:48.502461452Z 2025-03-21 23:02:48,501 INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
[pod/worker-1/datanode] 2025-03-21T23:02:48.502527676Z 2025-03-21 23:02:48,502 INFO impl.MetricsSystemImpl: DataNode metrics system started
[pod/worker-1/datanode] 2025-03-21T23:02:49.087984877Z 2025-03-21 23:02:49,087 INFO common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
[pod/worker-1/datanode] 2025-03-21T23:02:49.126184516Z 2025-03-21 23:02:49,125 INFO datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
[pod/worker-0/spark-worker] 2025-03-21T23:03:09.098794128Z 25/03/21 23:03:09 WARN Worker: Failed to connect to master spark-master.submission-b88ebfea875443329ffa71394f4e85fa.svc.cluster.local:7077
[pod/worker-0/spark-worker] 2025-03-21T23:03:09.098873524Z org.apache.spark.SparkException: Exception thrown in awaitResult: 
[pod/worker-0/spark-worker] 2025-03-21T23:03:09.098884638Z 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[pod/worker-0/spark-worker] 2025-03-21T23:03:09.098895200Z 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[pod/worker-0/spark-worker] 2025-03-21T23:03:09.108259512Z 	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[pod/worker-0/spark-worker] 2025-03-21T23:03:09.108288843Z 	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[pod/worker-0/spark-worker] 2025-03-21T23:03:09.108299262Z 	at org.apache.spark.deploy.worker.Worker$$anon$1.run(Worker.scala:313)
[pod/worker-0/spark-worker] 2025-03-21T23:03:09.108308564Z 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[pod/worker-0/spark-worker] 2025-03-21T23:03:09.108361920Z 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[pod/worker-0/spark-worker] 2025-03-21T23:03:09.108369866Z 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[pod/worker-0/spark-worker] 2025-03-21T23:03:09.108375824Z 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[pod/worker-0/spark-worker] 2025-03-21T23:03:09.108382193Z 	at java.base/java.lang.Thread.run(Thread.java:829)
[pod/worker-0/spark-worker] 2025-03-21T23:03:09.108389494Z Caused by: java.io.IOException: Failed to connect to spark-master.submission-b88ebfea875443329ffa71394f4e85fa.svc.cluster.local:7077
[pod/worker-0/spark-worker] 2025-03-21T23:03:09.108396026Z 	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:298)
[pod/worker-0/spark-worker] 2025-03-21T23:03:09.108402145Z 	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:218)
[pod/worker-0/spark-worker] 2025-03-21T23:03:09.108408163Z 	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:230)
[pod/worker-1/datanode] 2025-03-21T23:02:49.139615219Z 2025-03-21 23:02:49,139 INFO datanode.DataNode: Configured hostname is worker-1.worker.submission-b88ebfea875443329ffa71394f4e85fa.svc.cluster.local
[pod/worker-1/datanode] 2025-03-21T23:02:49.140628186Z 2025-03-21 23:02:49,140 INFO common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
[pod/worker-1/datanode] 2025-03-21T23:02:49.151656218Z 2025-03-21 23:02:49,151 INFO datanode.DataNode: Starting DataNode with maxLockedMemory = 0
[pod/worker-1/datanode] 2025-03-21T23:02:49.201561043Z 2025-03-21 23:02:49,201 INFO datanode.DataNode: Opened streaming server at /0.0.0.0:9866
[pod/worker-1/datanode] 2025-03-21T23:02:49.204613048Z 2025-03-21 23:02:49,204 INFO datanode.DataNode: Balancing bandwidth is 104857600 bytes/s
[pod/worker-1/datanode] 2025-03-21T23:02:49.204645447Z 2025-03-21 23:02:49,204 INFO datanode.DataNode: Number threads for balancing is 100
[pod/worker-1/datanode] 2025-03-21T23:02:49.312588295Z 2025-03-21 23:02:49,311 INFO util.log: Logging initialized @4031ms to org.eclipse.jetty.util.log.Slf4jLog
[pod/worker-1/spark-worker] 2025-03-21T23:02:51.425773795Z 	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[pod/worker-1/spark-worker] 2025-03-21T23:02:51.425778072Z 	at org.apache.spark.deploy.worker.Worker$$anon$1.run(Worker.scala:313)
[pod/worker-1/spark-worker] 2025-03-21T23:02:51.425782960Z 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[pod/worker-1/spark-worker] 2025-03-21T23:02:51.425814186Z 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[pod/worker-1/spark-worker] 2025-03-21T23:02:51.425818041Z 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[pod/worker-1/spark-worker] 2025-03-21T23:02:51.425820903Z 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[pod/worker-1/spark-worker] 2025-03-21T23:02:51.425823973Z 	at java.base/java.lang.Thread.run(Thread.java:829)
[pod/worker-1/spark-worker] 2025-03-21T23:02:51.425826701Z Caused by: java.io.IOException: Failed to connect to spark-master.submission-b88ebfea875443329ffa71394f4e85fa.svc.cluster.local:7077
[pod/worker-1/spark-worker] 2025-03-21T23:02:51.425829860Z 	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:298)
[pod/worker-1/spark-worker] 2025-03-21T23:02:51.425839775Z 	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:218)
[pod/worker-1/spark-worker] 2025-03-21T23:02:51.425843144Z 	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:230)
[pod/worker-1/spark-worker] 2025-03-21T23:02:51.425846570Z 	at org.apache.spark.rpc.netty.NettyRpcEnv.createClient(NettyRpcEnv.scala:204)
[pod/worker-1/spark-worker] 2025-03-21T23:02:51.425849283Z 	at org.apache.spark.rpc.netty.Outbox$$anon$1.call(Outbox.scala:202)
[pod/worker-1/spark-worker] 2025-03-21T23:02:51.425859016Z 	at org.apache.spark.rpc.netty.Outbox$$anon$1.call(Outbox.scala:198)
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:27.194191049Z 2025-03-21 23:03:27,194 INFO util.GSet: 1.0% max memory 1 GB = 10.2 MB
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:27.194221204Z 2025-03-21 23:03:27,194 INFO util.GSet: capacity      = 2^20 = 1048576 entries
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:27.198267103Z 2025-03-21 23:03:27,198 INFO namenode.FSDirectory: ACLs enabled? true
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:27.198282610Z 2025-03-21 23:03:27,198 INFO namenode.FSDirectory: POSIX ACL inheritance enabled? true
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:27.198318486Z 2025-03-21 23:03:27,198 INFO namenode.FSDirectory: XAttrs enabled? true
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:27.198586572Z 2025-03-21 23:03:27,198 INFO namenode.NameNode: Caching file names occurring more than 10 times
[pod/worker-0/datanode] 2025-03-21T23:03:04.120951368Z 2025-03-21 23:03:04,120 INFO datanode.DataNode: Opened streaming server at /0.0.0.0:9866
[pod/worker-0/datanode] 2025-03-21T23:03:04.124488478Z 2025-03-21 23:03:04,124 INFO datanode.DataNode: Balancing bandwidth is 104857600 bytes/s
[pod/worker-0/datanode] 2025-03-21T23:03:04.124551782Z 2025-03-21 23:03:04,124 INFO datanode.DataNode: Number threads for balancing is 100
[pod/worker-0/datanode] 2025-03-21T23:03:04.232006486Z 2025-03-21 23:03:04,231 INFO util.log: Logging initialized @4146ms to org.eclipse.jetty.util.log.Slf4jLog
[pod/worker-0/datanode] 2025-03-21T23:03:04.486338693Z 2025-03-21 23:03:04,485 WARN server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /var/local/hadoop/hadoop-http-auth-signature-secret
[pod/worker-0/datanode] 2025-03-21T23:03:04.503286385Z 2025-03-21 23:03:04,503 INFO http.HttpRequestLog: Http request log for http.requests.datanode is not defined
[pod/worker-0/datanode] 2025-03-21T23:03:04.518778959Z 2025-03-21 23:03:04,518 INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
[pod/worker-0/spark-worker] 2025-03-21T23:03:09.108414655Z 	at org.apache.spark.rpc.netty.NettyRpcEnv.createClient(NettyRpcEnv.scala:204)
[pod/worker-0/spark-worker] 2025-03-21T23:03:09.108420309Z 	at org.apache.spark.rpc.netty.Outbox$$anon$1.call(Outbox.scala:202)
[pod/worker-0/spark-worker] 2025-03-21T23:03:09.108425926Z 	at org.apache.spark.rpc.netty.Outbox$$anon$1.call(Outbox.scala:198)
[pod/worker-0/spark-worker] 2025-03-21T23:03:09.108431750Z 	... 4 more
[pod/worker-0/spark-worker] 2025-03-21T23:03:09.108438586Z Caused by: java.net.UnknownHostException: spark-master.submission-b88ebfea875443329ffa71394f4e85fa.svc.cluster.local
[pod/worker-0/spark-worker] 2025-03-21T23:03:09.108444223Z 	at java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:797)
[pod/worker-0/spark-worker] 2025-03-21T23:03:09.108450024Z 	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)
[pod/worker-0/spark-worker] 2025-03-21T23:03:09.108455708Z 	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1386)
[pod/worker-1/datanode] 2025-03-21T23:02:49.572539412Z 2025-03-21 23:02:49,572 WARN server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /var/local/hadoop/hadoop-http-auth-signature-secret
[pod/worker-1/datanode] 2025-03-21T23:02:49.588840543Z 2025-03-21 23:02:49,588 INFO http.HttpRequestLog: Http request log for http.requests.datanode is not defined
[pod/worker-1/datanode] 2025-03-21T23:02:49.604224212Z 2025-03-21 23:02:49,603 INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
[pod/worker-1/spark-worker] 2025-03-21T23:02:51.425862130Z 	... 4 more
[pod/worker-1/spark-worker] 2025-03-21T23:02:51.425866596Z Caused by: java.net.UnknownHostException: spark-master.submission-b88ebfea875443329ffa71394f4e85fa.svc.cluster.local
[pod/worker-1/spark-worker] 2025-03-21T23:02:51.425869119Z 	at java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:797)
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:27.204397897Z 2025-03-21 23:03:27,204 INFO snapshot.SnapshotManager: Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
[pod/worker-0/datanode] 2025-03-21T23:03:04.523887471Z 2025-03-21 23:03:04,523 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
[pod/worker-0/spark-worker] 2025-03-21T23:03:09.108461342Z 	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1307)
[pod/worker-0/spark-worker] 2025-03-21T23:03:09.108466902Z 	at java.base/java.net.InetAddress.getByName(InetAddress.java:1257)
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:27.206436664Z 2025-03-21 23:03:27,206 INFO snapshot.SnapshotManager: SkipList is disabled
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:27.211063612Z 2025-03-21 23:03:27,210 INFO util.GSet: Computing capacity for map cachedBlocks
[pod/worker-0/datanode] 2025-03-21T23:03:04.524019162Z 2025-03-21 23:03:04,523 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
[pod/worker-0/datanode] 2025-03-21T23:03:04.524176082Z 2025-03-21 23:03:04,524 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
[pod/worker-0/datanode] 2025-03-21T23:03:04.604225303Z 2025-03-21 23:03:04,603 INFO http.HttpServer2: Jetty bound to port 42113
[pod/worker-0/spark-worker] 2025-03-21T23:03:09.108472489Z 	at io.netty.util.internal.SocketUtils$8.run(SocketUtils.java:156)
[pod/worker-0/spark-worker] 2025-03-21T23:03:09.108478029Z 	at io.netty.util.internal.SocketUtils$8.run(SocketUtils.java:153)
[pod/worker-1/datanode] 2025-03-21T23:02:49.609271319Z 2025-03-21 23:02:49,608 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
[pod/worker-1/datanode] 2025-03-21T23:02:49.609363760Z 2025-03-21 23:02:49,609 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
[pod/worker-1/spark-worker] 2025-03-21T23:02:51.425871876Z 	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:27.211080101Z 2025-03-21 23:03:27,210 INFO util.GSet: VM type       = 64-bit
[pod/worker-0/datanode] 2025-03-21T23:03:04.606965487Z 2025-03-21 23:03:04,606 INFO server.Server: jetty-9.4.51.v20230217; built: 2023-02-17T08:19:37.309Z; git: b45c405e4544384de066f814ed42ae3dceacdd49; jvm 11.0.26+4-post-Ubuntu-1ubuntu122.04
[pod/worker-0/datanode] 2025-03-21T23:03:04.659936737Z 2025-03-21 23:03:04,659 INFO server.session: DefaultSessionIdManager workerName=node0
[pod/worker-0/spark-worker] 2025-03-21T23:03:09.108483669Z 	at java.base/java.security.AccessController.doPrivileged(Native Method)
[pod/worker-0/spark-worker] 2025-03-21T23:03:09.108489273Z 	at io.netty.util.internal.SocketUtils.addressByName(SocketUtils.java:153)
[pod/worker-1/datanode] 2025-03-21T23:02:49.609540112Z 2025-03-21 23:02:49,609 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
[pod/worker-1/spark-worker] 2025-03-21T23:02:51.425874562Z 	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1386)
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:27.211292802Z 2025-03-21 23:03:27,211 INFO util.GSet: 0.25% max memory 1 GB = 2.6 MB
[pod/worker-0/datanode] 2025-03-21T23:03:04.660045401Z 2025-03-21 23:03:04,659 INFO server.session: No SessionScavenger set, using defaults
[pod/worker-1/datanode] 2025-03-21T23:02:49.691214299Z 2025-03-21 23:02:49,690 INFO http.HttpServer2: Jetty bound to port 38259
[pod/worker-1/spark-worker] 2025-03-21T23:02:51.425877038Z 	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1307)
[pod/worker-1/spark-worker] 2025-03-21T23:02:51.425879867Z 	at java.base/java.net.InetAddress.getByName(InetAddress.java:1257)
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:27.211340402Z 2025-03-21 23:03:27,211 INFO util.GSet: capacity      = 2^18 = 262144 entries
[pod/worker-0/datanode] 2025-03-21T23:03:04.664202473Z 2025-03-21 23:03:04,663 INFO server.session: node0 Scavenging every 600000ms
[pod/worker-0/datanode] 2025-03-21T23:03:04.697642124Z 2025-03-21 23:03:04,697 INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@2ca47471{logs,/logs,file:///var/local/hadoop/logs/,AVAILABLE}
[pod/worker-0/datanode] 2025-03-21T23:03:04.699575352Z 2025-03-21 23:03:04,699 INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@2f3c6ac4{static,/static,file:///opt/hadoop/share/hadoop/hdfs/webapps/static/,AVAILABLE}
[pod/worker-0/datanode] 2025-03-21T23:03:05.006136100Z 2025-03-21 23:03:05,005 INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@1a78dacd{datanode,/,file:///opt/hadoop/share/hadoop/hdfs/webapps/datanode/,AVAILABLE}{file:/opt/hadoop/share/hadoop/hdfs/webapps/datanode}
[pod/worker-0/spark-worker] 2025-03-21T23:03:09.108495020Z 	at io.netty.resolver.DefaultNameResolver.doResolve(DefaultNameResolver.java:41)
[pod/worker-0/spark-worker] 2025-03-21T23:03:09.108545462Z 	at io.netty.resolver.SimpleNameResolver.resolve(SimpleNameResolver.java:61)
[pod/worker-1/spark-worker] 2025-03-21T23:02:51.425882531Z 	at io.netty.util.internal.SocketUtils$8.run(SocketUtils.java:156)
[pod/worker-1/spark-worker] 2025-03-21T23:02:51.425899078Z 	at io.netty.util.internal.SocketUtils$8.run(SocketUtils.java:153)
[pod/worker-0/datanode] 2025-03-21T23:03:05.027624940Z 2025-03-21 23:03:05,027 INFO server.AbstractConnector: Started ServerConnector@5528a42c{HTTP/1.1, (http/1.1)}{localhost:42113}
[pod/worker-1/datanode] 2025-03-21T23:02:49.693711698Z 2025-03-21 23:02:49,693 INFO server.Server: jetty-9.4.51.v20230217; built: 2023-02-17T08:19:37.309Z; git: b45c405e4544384de066f814ed42ae3dceacdd49; jvm 11.0.26+4-post-Ubuntu-1ubuntu122.04
[pod/worker-1/datanode] 2025-03-21T23:02:49.746066863Z 2025-03-21 23:02:49,745 INFO server.session: DefaultSessionIdManager workerName=node0
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:27.221859650Z 2025-03-21 23:03:27,221 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
[pod/worker-0/datanode] 2025-03-21T23:03:05.027898084Z 2025-03-21 23:03:05,027 INFO server.Server: Started @4943ms
[pod/worker-0/datanode] 2025-03-21T23:03:05.258600384Z 2025-03-21 23:03:05,258 WARN web.DatanodeHttpServer: Got null for restCsrfPreventionFilter - will not do any filtering.
[pod/worker-0/spark-worker] 2025-03-21T23:03:09.108560111Z 	at io.netty.resolver.SimpleNameResolver.resolve(SimpleNameResolver.java:53)
[pod/worker-1/datanode] 2025-03-21T23:02:49.746155632Z 2025-03-21 23:02:49,745 INFO server.session: No SessionScavenger set, using defaults
[pod/worker-1/datanode] 2025-03-21T23:02:49.749761670Z 2025-03-21 23:02:49,749 INFO server.session: node0 Scavenging every 600000ms
[pod/worker-1/spark-worker] 2025-03-21T23:02:51.425902740Z 	at java.base/java.security.AccessController.doPrivileged(Native Method)
[pod/worker-1/spark-worker] 2025-03-21T23:02:51.425905730Z 	at io.netty.util.internal.SocketUtils.addressByName(SocketUtils.java:153)
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:27.221902372Z 2025-03-21 23:03:27,221 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
[pod/worker-0/datanode] 2025-03-21T23:03:05.467357803Z 2025-03-21 23:03:05,466 INFO web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:9864
[pod/worker-0/datanode] 2025-03-21T23:03:05.483641053Z 2025-03-21 23:03:05,481 INFO util.JvmPauseMonitor: Starting JVM pause monitor
[pod/worker-0/datanode] 2025-03-21T23:03:05.484418563Z 2025-03-21 23:03:05,483 INFO datanode.DataNode: dnUserName = hadoop
[pod/worker-0/spark-worker] 2025-03-21T23:03:09.108566524Z 	at io.netty.resolver.InetSocketAddressResolver.doResolve(InetSocketAddressResolver.java:55)
[pod/worker-0/spark-worker] 2025-03-21T23:03:09.108572227Z 	at io.netty.resolver.InetSocketAddressResolver.doResolve(InetSocketAddressResolver.java:31)
[pod/worker-0/spark-worker] 2025-03-21T23:03:09.108577871Z 	at io.netty.resolver.AbstractAddressResolver.resolve(AbstractAddressResolver.java:106)
[pod/worker-1/datanode] 2025-03-21T23:02:49.784997290Z 2025-03-21 23:02:49,784 INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@13006998{logs,/logs,file:///var/local/hadoop/logs/,AVAILABLE}
[pod/worker-1/spark-worker] 2025-03-21T23:02:51.425908461Z 	at io.netty.resolver.DefaultNameResolver.doResolve(DefaultNameResolver.java:41)
[pod/worker-1/spark-worker] 2025-03-21T23:02:51.425912070Z 	at io.netty.resolver.SimpleNameResolver.resolve(SimpleNameResolver.java:61)
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:27.221916093Z 2025-03-21 23:03:27,221 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
[pod/worker-0/datanode] 2025-03-21T23:03:05.484737059Z 2025-03-21 23:03:05,484 INFO datanode.DataNode: supergroup = supergroup
[pod/worker-0/datanode] 2025-03-21T23:03:05.597903136Z 2025-03-21 23:03:05,597 INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
[pod/worker-0/spark-worker] 2025-03-21T23:03:09.108583445Z 	at io.netty.bootstrap.Bootstrap.doResolveAndConnect0(Bootstrap.java:206)
[pod/worker-0/spark-worker] 2025-03-21T23:03:09.108590318Z 	at io.netty.bootstrap.Bootstrap.access$000(Bootstrap.java:46)
[pod/worker-1/datanode] 2025-03-21T23:02:49.786957931Z 2025-03-21 23:02:49,786 INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@10027fc9{static,/static,file:///opt/hadoop/share/hadoop/hdfs/webapps/static/,AVAILABLE}
[pod/worker-1/datanode] 2025-03-21T23:02:50.090193058Z 2025-03-21 23:02:50,089 INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@238ad8c{datanode,/,file:///opt/hadoop/share/hadoop/hdfs/webapps/datanode/,AVAILABLE}{file:/opt/hadoop/share/hadoop/hdfs/webapps/datanode}
[pod/worker-1/spark-worker] 2025-03-21T23:02:51.425917851Z 	at io.netty.resolver.SimpleNameResolver.resolve(SimpleNameResolver.java:53)
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:27.228637836Z 2025-03-21 23:03:27,228 INFO namenode.FSNamesystem: Retry cache on namenode is enabled
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:27.228669261Z 2025-03-21 23:03:27,228 INFO namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
[pod/worker-0/datanode] 2025-03-21T23:03:05.644133101Z 2025-03-21 23:03:05,643 INFO ipc.Server: Listener at 0.0.0.0:9867
[pod/worker-0/spark-worker] 2025-03-21T23:03:09.108595948Z 	at io.netty.bootstrap.Bootstrap$1.operationComplete(Bootstrap.java:180)
[pod/worker-1/datanode] 2025-03-21T23:02:50.111082615Z 2025-03-21 23:02:50,110 INFO server.AbstractConnector: Started ServerConnector@372b0d86{HTTP/1.1, (http/1.1)}{localhost:38259}
[pod/worker-1/spark-worker] 2025-03-21T23:02:51.425921126Z 	at io.netty.resolver.InetSocketAddressResolver.doResolve(InetSocketAddressResolver.java:55)
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:27.230925676Z 2025-03-21 23:03:27,230 INFO util.GSet: Computing capacity for map NameNodeRetryCache
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:27.230946746Z 2025-03-21 23:03:27,230 INFO util.GSet: VM type       = 64-bit
[pod/worker-0/spark-worker] 2025-03-21T23:03:09.108601472Z 	at io.netty.bootstrap.Bootstrap$1.operationComplete(Bootstrap.java:166)
[pod/worker-0/spark-worker] 2025-03-21T23:03:09.108607149Z 	at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:578)
[pod/worker-1/datanode] 2025-03-21T23:02:50.111309797Z 2025-03-21 23:02:50,111 INFO server.Server: Started @4830ms
[pod/worker-1/spark-worker] 2025-03-21T23:02:51.425924473Z 	at io.netty.resolver.InetSocketAddressResolver.doResolve(InetSocketAddressResolver.java:31)
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:27.231202226Z 2025-03-21 23:03:27,231 INFO util.GSet: 0.029999999329447746% max memory 1 GB = 314.6 KB
[pod/worker-0/datanode] 2025-03-21T23:03:05.647424052Z 2025-03-21 23:03:05,646 INFO ipc.Server: Starting Socket Reader #1 for port 9867
[pod/worker-0/datanode] 2025-03-21T23:03:06.117431941Z 2025-03-21 23:03:06,117 INFO datanode.DataNode: Opened IPC server at /0.0.0.0:9867
[pod/worker-0/datanode] 2025-03-21T23:03:06.194230782Z 2025-03-21 23:03:06,193 INFO datanode.DataNode: Refresh request received for nameservices: null
[pod/worker-0/spark-worker] 2025-03-21T23:03:09.108612732Z 	at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:552)
[pod/worker-0/spark-worker] 2025-03-21T23:03:09.108632540Z 	at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:491)
[pod/worker-1/datanode] 2025-03-21T23:02:50.341800860Z 2025-03-21 23:02:50,341 WARN web.DatanodeHttpServer: Got null for restCsrfPreventionFilter - will not do any filtering.
[pod/worker-1/spark-worker] 2025-03-21T23:02:51.425927056Z 	at io.netty.resolver.AbstractAddressResolver.resolve(AbstractAddressResolver.java:106)
[pod/worker-1/spark-worker] 2025-03-21T23:02:51.425929698Z 	at io.netty.bootstrap.Bootstrap.doResolveAndConnect0(Bootstrap.java:206)
[pod/worker-1/spark-worker] 2025-03-21T23:02:51.425933241Z 	at io.netty.bootstrap.Bootstrap.access$000(Bootstrap.java:46)
[pod/worker-1/spark-worker] 2025-03-21T23:02:51.425936789Z 	at io.netty.bootstrap.Bootstrap$1.operationComplete(Bootstrap.java:180)
[pod/worker-0/datanode] 2025-03-21T23:03:06.217470516Z 2025-03-21 23:03:06,217 WARN hdfs.DFSUtilClient: Namenode for null remains unresolved for ID null. Check your hdfs-site.xml file to ensure namenodes are configured properly.
[pod/worker-0/spark-worker] 2025-03-21T23:03:09.108639247Z 	at io.netty.util.concurrent.DefaultPromise.setValue0(DefaultPromise.java:616)
[pod/worker-0/spark-worker] 2025-03-21T23:03:09.108644947Z 	at io.netty.util.concurrent.DefaultPromise.setSuccess0(DefaultPromise.java:605)
[pod/worker-1/datanode] 2025-03-21T23:02:50.551125891Z 2025-03-21 23:02:50,550 INFO web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:9864
[pod/worker-1/datanode] 2025-03-21T23:02:50.567182013Z 2025-03-21 23:02:50,565 INFO util.JvmPauseMonitor: Starting JVM pause monitor
[pod/worker-1/spark-worker] 2025-03-21T23:02:51.425939389Z 	at io.netty.bootstrap.Bootstrap$1.operationComplete(Bootstrap.java:166)
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:27.231217059Z 2025-03-21 23:03:27,231 INFO util.GSet: capacity      = 2^15 = 32768 entries
[pod/worker-0/datanode] 2025-03-21T23:03:06.221094742Z 2025-03-21 23:03:06,220 INFO datanode.DataNode: Starting BPOfferServices for nameservices: <default>
[pod/worker-0/datanode] 2025-03-21T23:03:06.246433437Z 2025-03-21 23:03:06,245 INFO datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to hdfs-namenode:8020 starting to offer service
[pod/worker-0/datanode] 2025-03-21T23:03:06.262230306Z 2025-03-21 23:03:06,261 INFO ipc.Server: IPC Server Responder: starting
[pod/worker-0/spark-worker] 2025-03-21T23:03:09.108650611Z 	at io.netty.util.concurrent.DefaultPromise.trySuccess(DefaultPromise.java:104)
[pod/worker-0/spark-worker] 2025-03-21T23:03:09.108657097Z 	at io.netty.channel.DefaultChannelPromise.trySuccess(DefaultChannelPromise.java:84)
[pod/worker-1/spark-worker] 2025-03-21T23:02:51.425942257Z 	at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:578)
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:27.266141759Z 2025-03-21 23:03:27,265 INFO namenode.FSImage: Allocated new BlockPoolId: BP-1789806720-192.168.139.246-1742598207255
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:27.348125852Z 2025-03-21 23:03:27,347 INFO common.Storage: Storage directory /var/local/hadoop/name has been successfully formatted.
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:27.386486894Z 2025-03-21 23:03:27,385 INFO namenode.FSImageFormatProtobuf: Saving image file /var/local/hadoop/name/current/fsimage.ckpt_0000000000000000000 using no compression
[pod/worker-0/datanode] 2025-03-21T23:03:06.262673244Z 2025-03-21 23:03:06,261 INFO ipc.Server: IPC Server listener on 9867: starting
[pod/worker-1/datanode] 2025-03-21T23:02:50.567939182Z 2025-03-21 23:02:50,567 INFO datanode.DataNode: dnUserName = hadoop
[pod/worker-1/spark-worker] 2025-03-21T23:02:51.425944945Z 	at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:552)
[pod/worker-0/datanode] 2025-03-21T23:03:07.434214831Z 2025-03-21 23:03:07,433 INFO ipc.Client: Retrying connect to server: hdfs-namenode:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[pod/worker-0/spark-worker] 2025-03-21T23:03:09.108662961Z 	at io.netty.channel.AbstractChannel$AbstractUnsafe.safeSetSuccess(AbstractChannel.java:990)
[pod/worker-1/datanode] 2025-03-21T23:02:50.567975808Z 2025-03-21 23:02:50,567 INFO datanode.DataNode: supergroup = supergroup
[pod/worker-1/datanode] 2025-03-21T23:02:50.678217860Z 2025-03-21 23:02:50,677 INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
[pod/worker-1/datanode] 2025-03-21T23:02:50.722170834Z 2025-03-21 23:02:50,721 INFO ipc.Server: Listener at 0.0.0.0:9867
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:27.517741350Z 2025-03-21 23:03:27,517 INFO namenode.FSImageFormatProtobuf: Image file /var/local/hadoop/name/current/fsimage.ckpt_0000000000000000000 of size 401 bytes saved in 0 seconds .
[pod/worker-1/datanode] 2025-03-21T23:02:50.725074014Z 2025-03-21 23:02:50,724 INFO ipc.Server: Starting Socket Reader #1 for port 9867
[pod/worker-1/spark-worker] 2025-03-21T23:02:51.425955498Z 	at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:491)
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:27.579379744Z 2025-03-21 23:03:27,579 INFO namenode.NNStorageRetentionManager: Going to retain 1 images with txid >= 0
[pod/worker-0/datanode] 2025-03-21T23:03:08.435960778Z 2025-03-21 23:03:08,435 INFO ipc.Client: Retrying connect to server: hdfs-namenode:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[pod/worker-0/datanode] 2025-03-21T23:03:09.437024592Z 2025-03-21 23:03:09,436 INFO ipc.Client: Retrying connect to server: hdfs-namenode:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[pod/worker-0/spark-worker] 2025-03-21T23:03:09.108668788Z 	at io.netty.channel.AbstractChannel$AbstractUnsafe.register0(AbstractChannel.java:516)
[pod/worker-0/spark-worker] 2025-03-21T23:03:09.108674285Z 	at io.netty.channel.AbstractChannel$AbstractUnsafe.access$200(AbstractChannel.java:429)
[pod/worker-1/datanode] 2025-03-21T23:02:51.252282689Z 2025-03-21 23:02:51,251 INFO datanode.DataNode: Opened IPC server at /0.0.0.0:9867
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:27.619452192Z 2025-03-21 23:03:27,619 INFO namenode.FSNamesystem: Stopping services started for active state
[pod/worker-0/spark-worker] 2025-03-21T23:03:09.108719508Z 	at io.netty.channel.AbstractChannel$AbstractUnsafe$1.run(AbstractChannel.java:486)
[pod/worker-0/spark-worker] 2025-03-21T23:03:09.108727240Z 	at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:164)
[pod/worker-0/spark-worker] 2025-03-21T23:03:09.108732894Z 	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:469)
[pod/worker-1/spark-worker] 2025-03-21T23:02:51.425958783Z 	at io.netty.util.concurrent.DefaultPromise.setValue0(DefaultPromise.java:616)
[pod/worker-0/datanode] 2025-03-21T23:03:10.437888859Z 2025-03-21 23:03:10,437 INFO ipc.Client: Retrying connect to server: hdfs-namenode:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[pod/worker-0/datanode] 2025-03-21T23:03:11.438424871Z 2025-03-21 23:03:11,438 INFO ipc.Client: Retrying connect to server: hdfs-namenode:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[pod/worker-0/datanode] 2025-03-21T23:03:12.438908525Z 2025-03-21 23:03:12,438 INFO ipc.Client: Retrying connect to server: hdfs-namenode:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[pod/worker-1/spark-worker] 2025-03-21T23:02:51.425961535Z 	at io.netty.util.concurrent.DefaultPromise.setSuccess0(DefaultPromise.java:605)
[pod/worker-1/datanode] 2025-03-21T23:02:51.334245922Z 2025-03-21 23:02:51,333 INFO datanode.DataNode: Refresh request received for nameservices: null
[pod/worker-1/datanode] 2025-03-21T23:02:51.358328344Z 2025-03-21 23:02:51,357 WARN hdfs.DFSUtilClient: Namenode for null remains unresolved for ID null. Check your hdfs-site.xml file to ensure namenodes are configured properly.
[pod/worker-1/datanode] 2025-03-21T23:02:51.361580425Z 2025-03-21 23:02:51,361 INFO datanode.DataNode: Starting BPOfferServices for nameservices: <default>
[pod/worker-1/datanode] 2025-03-21T23:02:51.385547610Z 2025-03-21 23:02:51,384 INFO datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to hdfs-namenode:8020 starting to offer service
[pod/worker-1/spark-worker] 2025-03-21T23:02:51.425964178Z 	at io.netty.util.concurrent.DefaultPromise.trySuccess(DefaultPromise.java:104)
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:27.619830772Z 2025-03-21 23:03:27,619 INFO namenode.FSNamesystem: Stopping services started for standby state
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:27.628678953Z 2025-03-21 23:03:27,628 INFO namenode.FSImage: FSImageSaver clean checkpoint: txid=0 when meet shutdown.
[pod/worker-0/datanode] 2025-03-21T23:03:13.440195852Z 2025-03-21 23:03:13,439 INFO ipc.Client: Retrying connect to server: hdfs-namenode:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[pod/worker-0/spark-worker] 2025-03-21T23:03:09.108739139Z 	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:503)
[pod/worker-0/spark-worker] 2025-03-21T23:03:09.108744696Z 	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:986)
[pod/worker-1/datanode] 2025-03-21T23:02:51.399831729Z 2025-03-21 23:02:51,399 INFO ipc.Server: IPC Server Responder: starting
[pod/worker-1/spark-worker] 2025-03-21T23:02:51.425967077Z 	at io.netty.channel.DefaultChannelPromise.trySuccess(DefaultChannelPromise.java:84)
[pod/worker-1/spark-worker] 2025-03-21T23:02:51.425969967Z 	at io.netty.channel.AbstractChannel$AbstractUnsafe.safeSetSuccess(AbstractChannel.java:990)
[pod/worker-1/spark-worker] 2025-03-21T23:02:51.425972672Z 	at io.netty.channel.AbstractChannel$AbstractUnsafe.register0(AbstractChannel.java:516)
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:27.630476452Z 2025-03-21 23:03:27,630 INFO namenode.NameNode: SHUTDOWN_MSG: 
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:27.630491741Z /************************************************************
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:27.630495920Z SHUTDOWN_MSG: Shutting down NameNode at hdfs-namenode-0/192.168.139.246
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:27.630499098Z ************************************************************/
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:27.690277236Z Formatted name node
[pod/worker-0/datanode] 2025-03-21T23:03:14.441019463Z 2025-03-21 23:03:14,440 INFO ipc.Client: Retrying connect to server: hdfs-namenode:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[pod/worker-0/datanode] 2025-03-21T23:03:15.441600301Z 2025-03-21 23:03:15,441 INFO ipc.Client: Retrying connect to server: hdfs-namenode:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[pod/worker-0/spark-worker] 2025-03-21T23:03:09.108750557Z 	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
[pod/worker-0/spark-worker] 2025-03-21T23:03:09.108756598Z 	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
[pod/worker-1/datanode] 2025-03-21T23:02:51.400859923Z 2025-03-21 23:02:51,400 INFO ipc.Server: IPC Server listener on 9867: starting
[pod/worker-1/datanode] 2025-03-21T23:02:52.577111422Z 2025-03-21 23:02:52,576 INFO ipc.Client: Retrying connect to server: hdfs-namenode:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[pod/worker-1/spark-worker] 2025-03-21T23:02:51.425975483Z 	at io.netty.channel.AbstractChannel$AbstractUnsafe.access$200(AbstractChannel.java:429)
[pod/worker-1/spark-worker] 2025-03-21T23:02:51.425996194Z 	at io.netty.channel.AbstractChannel$AbstractUnsafe$1.run(AbstractChannel.java:486)
[pod/worker-0/datanode] 2025-03-21T23:03:16.442248086Z 2025-03-21 23:03:16,441 INFO ipc.Client: Retrying connect to server: hdfs-namenode:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[pod/worker-0/spark-worker] 2025-03-21T23:03:09.108762279Z 	... 1 more
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:28.743021693Z 2025-03-21 23:03:28,742 INFO namenode.NameNode: STARTUP_MSG: 
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:28.743068432Z /************************************************************
[pod/worker-1/spark-worker] 2025-03-21T23:02:51.425999819Z 	at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:164)
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:28.743072942Z STARTUP_MSG: Starting NameNode
[pod/worker-0/datanode] 2025-03-21T23:03:16.457253153Z 2025-03-21 23:03:16,457 WARN datanode.DataNode: Problem connecting to server: hdfs-namenode:8020
[pod/worker-0/spark-worker] 2025-03-21T23:03:15.936605613Z 25/03/21 23:03:15 INFO Worker: Retrying connection to master (attempt # 1)
[pod/worker-0/spark-worker] 2025-03-21T23:03:15.938286720Z 25/03/21 23:03:15 INFO Worker: Connecting to master spark-master.submission-b88ebfea875443329ffa71394f4e85fa.svc.cluster.local:7077...
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:28.743075651Z STARTUP_MSG:   host = hdfs-namenode-0/192.168.139.246
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:28.743078655Z STARTUP_MSG:   args = []
[pod/worker-0/datanode] 2025-03-21T23:03:22.461287209Z 2025-03-21 23:03:22,460 INFO ipc.Client: Retrying connect to server: hdfs-namenode:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[pod/worker-0/datanode] 2025-03-21T23:03:23.462105240Z 2025-03-21 23:03:23,461 INFO ipc.Client: Retrying connect to server: hdfs-namenode:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[pod/worker-0/spark-worker] 2025-03-21T23:03:15.954672258Z 25/03/21 23:03:15 WARN Worker: Failed to connect to master spark-master.submission-b88ebfea875443329ffa71394f4e85fa.svc.cluster.local:7077
[pod/worker-1/datanode] 2025-03-21T23:02:53.578498824Z 2025-03-21 23:02:53,577 INFO ipc.Client: Retrying connect to server: hdfs-namenode:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[pod/worker-1/spark-worker] 2025-03-21T23:02:51.426002759Z 	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:469)
[pod/worker-1/spark-worker] 2025-03-21T23:02:51.426005893Z 	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:503)
[pod/worker-1/spark-worker] 2025-03-21T23:02:51.426009269Z 	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:986)
[pod/worker-0/datanode] 2025-03-21T23:03:24.462793780Z 2025-03-21 23:03:24,462 INFO ipc.Client: Retrying connect to server: hdfs-namenode:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[pod/worker-0/spark-worker] 2025-03-21T23:03:15.954719095Z org.apache.spark.SparkException: Exception thrown in awaitResult: 
[pod/worker-0/spark-worker] 2025-03-21T23:03:15.954739046Z 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[pod/worker-1/datanode] 2025-03-21T23:02:54.579106303Z 2025-03-21 23:02:54,578 INFO ipc.Client: Retrying connect to server: hdfs-namenode:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[pod/worker-1/datanode] 2025-03-21T23:02:55.579645380Z 2025-03-21 23:02:55,579 INFO ipc.Client: Retrying connect to server: hdfs-namenode:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[pod/worker-1/spark-worker] 2025-03-21T23:02:51.426012133Z 	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:28.743081260Z STARTUP_MSG:   version = 3.3.6
[pod/worker-0/datanode] 2025-03-21T23:03:25.464678084Z 2025-03-21 23:03:25,464 INFO ipc.Client: Retrying connect to server: hdfs-namenode:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[pod/worker-1/datanode] 2025-03-21T23:02:56.580116351Z 2025-03-21 23:02:56,579 INFO ipc.Client: Retrying connect to server: hdfs-namenode:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[pod/worker-1/datanode] 2025-03-21T23:02:57.580687853Z 2025-03-21 23:02:57,580 INFO ipc.Client: Retrying connect to server: hdfs-namenode:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[pod/worker-0/datanode] 2025-03-21T23:03:26.465371262Z 2025-03-21 23:03:26,464 INFO ipc.Client: Retrying connect to server: hdfs-namenode:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[pod/worker-0/spark-worker] 2025-03-21T23:03:15.954754444Z 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[pod/worker-0/spark-worker] 2025-03-21T23:03:15.954770289Z 	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[pod/worker-1/datanode] 2025-03-21T23:02:58.581975597Z 2025-03-21 23:02:58,581 INFO ipc.Client: Retrying connect to server: hdfs-namenode:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[pod/worker-0/datanode] 2025-03-21T23:03:26.468112969Z 2025-03-21 23:03:26,467 WARN ipc.Client: Address change detected. Old: hdfs-namenode:8020 New: hdfs-namenode/192.168.139.246:8020
[pod/worker-0/spark-worker] 2025-03-21T23:03:15.954786545Z 	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[pod/worker-1/datanode] 2025-03-21T23:02:59.582522271Z 2025-03-21 23:02:59,582 INFO ipc.Client: Retrying connect to server: hdfs-namenode:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[pod/worker-1/spark-worker] 2025-03-21T23:02:51.426017432Z 	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
[pod/worker-1/spark-worker] 2025-03-21T23:02:51.426020520Z 	... 1 more
[pod/worker-0/spark-worker] 2025-03-21T23:03:15.954803934Z 	at org.apache.spark.deploy.worker.Worker$$anon$1.run(Worker.scala:313)
[pod/worker-1/spark-worker] 2025-03-21T23:03:02.271112198Z 25/03/21 23:03:02 INFO Worker: Retrying connection to master (attempt # 1)
[pod/worker-1/spark-worker] 2025-03-21T23:03:02.273006291Z 25/03/21 23:03:02 INFO Worker: Connecting to master spark-master.submission-b88ebfea875443329ffa71394f4e85fa.svc.cluster.local:7077...
[pod/worker-0/datanode] 2025-03-21T23:03:27.469017736Z 2025-03-21 23:03:27,468 INFO ipc.Client: Retrying connect to server: hdfs-namenode/192.168.139.246:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[pod/worker-0/datanode] 2025-03-21T23:03:28.482445126Z 2025-03-21 23:03:28,481 INFO ipc.Client: Retrying connect to server: hdfs-namenode/192.168.139.246:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[pod/worker-0/spark-worker] 2025-03-21T23:03:15.954818940Z 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[pod/worker-1/datanode] 2025-03-21T23:03:00.583044755Z 2025-03-21 23:03:00,582 INFO ipc.Client: Retrying connect to server: hdfs-namenode:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[pod/worker-1/spark-worker] 2025-03-21T23:03:02.295460168Z 25/03/21 23:03:02 WARN Worker: Failed to connect to master spark-master.submission-b88ebfea875443329ffa71394f4e85fa.svc.cluster.local:7077
[pod/worker-1/spark-worker] 2025-03-21T23:03:02.295503931Z org.apache.spark.SparkException: Exception thrown in awaitResult: 
[pod/worker-1/spark-worker] 2025-03-21T23:03:02.295522122Z 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[pod/worker-0/datanode] 2025-03-21T23:03:29.484189688Z 2025-03-21 23:03:29,483 INFO ipc.Client: Retrying connect to server: hdfs-namenode/192.168.139.246:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[pod/worker-0/datanode] 2025-03-21T23:03:30.485710888Z 2025-03-21 23:03:30,485 INFO ipc.Client: Retrying connect to server: hdfs-namenode/192.168.139.246:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[pod/worker-0/datanode] 2025-03-21T23:03:31.487470321Z 2025-03-21 23:03:31,486 INFO ipc.Client: Retrying connect to server: hdfs-namenode/192.168.139.246:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[pod/worker-0/spark-worker] 2025-03-21T23:03:15.954835106Z 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[pod/worker-0/spark-worker] 2025-03-21T23:03:15.954850978Z 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[pod/worker-0/spark-worker] 2025-03-21T23:03:15.954865269Z 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[pod/worker-1/datanode] 2025-03-21T23:03:01.583645911Z 2025-03-21 23:03:01,583 INFO ipc.Client: Retrying connect to server: hdfs-namenode:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[pod/worker-1/datanode] 2025-03-21T23:03:01.593715622Z 2025-03-21 23:03:01,593 WARN datanode.DataNode: Problem connecting to server: hdfs-namenode:8020
[pod/worker-1/datanode] 2025-03-21T23:03:07.597133801Z 2025-03-21 23:03:07,596 INFO ipc.Client: Retrying connect to server: hdfs-namenode:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[pod/worker-1/datanode] 2025-03-21T23:03:08.597618402Z 2025-03-21 23:03:08,597 INFO ipc.Client: Retrying connect to server: hdfs-namenode:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:28.743126436Z STARTUP_MSG:   classpath = /opt/hadoop/etc/hadoop:/opt/hadoop/share/hadoop/common/lib/netty-transport-native-kqueue-4.1.89.Final-osx-aarch_64.jar:/opt/hadoop/share/hadoop/common/lib/nimbus-jose-jwt-9.8.1.jar:/opt/hadoop/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/netty-codec-http-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop/share/hadoop/common/lib/netty-codec-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/jersey-core-1.19.4.jar:/opt/hadoop/share/hadoop/common/lib/jettison-1.5.4.jar:/opt/hadoop/share/hadoop/common/lib/jetty-xml-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/common/lib/curator-client-5.2.0.jar:/opt/hadoop/share/hadoop/common/lib/jul-to-slf4j-1.7.36.jar:/opt/hadoop/share/hadoop/common/lib/netty-transport-udt-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/hadoop/common/lib/netty-codec-http2-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/netty-handler-ssl-ocsp-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/jackson-annotations-2.12.7.jar:/opt/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop/share/hadoop/common/lib/netty-codec-redis-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/curator-recipes-5.2.0.jar:/opt/hadoop/share/hadoop/common/lib/avro-1.7.7.jar:/opt/hadoop/share/hadoop/common/lib/hadoop-auth-3.3.6.jar:/opt/hadoop/share/hadoop/common/lib/netty-codec-memcache-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/netty-transport-classes-kqueue-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/jetty-server-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/common/lib/netty-handler-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/guava-27.0-jre.jar:/opt/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/hadoop/common/lib/jetty-webapp-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/common/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/jetty-servlet-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/common/lib/commons-lang3-3.12.0.jar:/opt/hadoop/share/hadoop/common/lib/netty-resolver-dns-classes-macos-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/checker-qual-2.5.2.jar:/opt/hadoop/share/hadoop/common/lib/gson-2.9.0.jar:/opt/hadoop/share/hadoop/common/lib/netty-handler-proxy-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/hadoop/common/lib/j2objc-annotations-1.1.jar:/opt/hadoop/share/hadoop/common/lib/zookeeper-jute-3.6.3.jar:/opt/hadoop/share/hadoop/common/lib/jersey-servlet-1.19.4.jar:/opt/hadoop/share/hadoop/common/lib/netty-resolver-dns-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/re2j-1.1.jar:/opt/hadoop/share/hadoop/common/lib/jersey-json-1.20.jar:/opt/hadoop/share/hadoop/common/lib/jackson-databind-2.12.7.1.jar:/opt/hadoop/share/hadoop/common/lib/commons-io-2.8.0.jar:/opt/hadoop/share/hadoop/common/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/httpclient-4.5.13.jar:/opt/hadoop/share/hadoop/common/lib/netty-resolver-dns-native-macos-4.1.89.Final-osx-aarch_64.jar:/opt/hadoop/share/hadoop/common/lib/netty-transport-rxtx-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/hadoop/common/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/hadoop/common/lib/netty-resolver-dns-native-macos-4.1.89.Final-osx-x86_64.jar:/opt/hadoop/share/hadoop/common/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/hadoop/common/lib/commons-compress-1.21.jar:/opt/hadoop/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/jetty-util-ajax-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/common/lib/netty-transport-native-epoll-4.1.89.Final-linux-x86_64.jar:/opt/hadoop/share/hadoop/common/lib/jetty-io-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/common/lib/slf4j-api-1.7.36.jar:/opt/hadoop/share/hadoop/common/lib/netty-all-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/token-provider-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/hadoop/common/lib/netty-transport-native-epoll-4.1.89.Final-linux-aarch_64.jar:/opt/hadoop/share/hadoop/common/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/netty-common-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/failureaccess-1.0.jar:/opt/hadoop/share/hadoop/common/lib/jsr305-3.0.2.jar:/opt/hadoop/share/hadoop/common/lib/netty-transport-native-kqueue-4.1.89.Final-osx-x86_64.jar:/opt/hadoop/share/hadoop/common/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/hadoop/common/lib/netty-codec-socks-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/httpcore-4.4.13.jar:/opt/hadoop/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/hadoop/common/lib/animal-sniffer-annotations-1.17.jar:/opt/hadoop/share/hadoop/common/lib/netty-codec-haproxy-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/netty-resolver-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/slf4j-reload4j-1.7.36.jar:/opt/hadoop/share/hadoop/common/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop/share/hadoop/common/lib/stax2-api-4.2.1.jar:/opt/hadoop/share/hadoop/common/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/zookeeper-3.6.3.jar:/opt/hadoop/share/hadoop/common/lib/netty-codec-stomp-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/hadoop/common/lib/netty-transport-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/commons-codec-1.15.jar:/opt/hadoop/share/hadoop/common/lib/netty-codec-xml-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/netty-transport-native-unix-common-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/jetty-http-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/jersey-server-1.19.4.jar:/opt/hadoop/share/hadoop/common/lib/jetty-security-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/woodstox-core-5.4.0.jar:/opt/hadoop/share/hadoop/common/lib/commons-net-3.9.0.jar:/opt/hadoop/share/hadoop/common/lib/hadoop-annotations-3.3.6.jar:/opt/hadoop/share/hadoop/common/lib/netty-transport-classes-epoll-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/hadoop/common/lib/netty-transport-sctp-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/jsch-0.1.55.jar:/opt/hadoop/share/hadoop/common/lib/commons-text-1.10.0.jar:/opt/hadoop/share/hadoop/common/lib/netty-codec-dns-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/hadoop/common/lib/netty-codec-mqtt-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/reload4j-1.2.22.jar:/opt/hadoop/share/hadoop/common/lib/netty-buffer-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/jetty-util-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/common/lib/curator-framework-5.2.0.jar:/opt/hadoop/share/hadoop/common/lib/audience-annotations-0.5.0.jar:/opt/hadoop/share/hadoop/common/lib/jackson-core-2.12.7.jar:/opt/hadoop/share/hadoop/common/lib/commons-configuration2-2.8.0.jar:/opt/hadoop/share/hadoop/common/lib/netty-codec-smtp-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/opt/hadoop/share/hadoop/common/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/hadoop/common/hadoop-registry-3.3.6.jar:/opt/hadoop/share/hadoop/common/hadoop-kms-3.3.6.jar:/opt/hadoop/share/hadoop/common/hadoop-common-3.3.6.jar:/opt/hadoop/share/hadoop/common/hadoop-common-3.3.6-tests.jar:/opt/hadoop/share/hadoop/common/hadoop-nfs-3.3.6.jar:/opt/hadoop/share/hadoop/hdfs:/opt/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-classes-macos-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-transport-udt-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-codec-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/kotlin-stdlib-common-1.4.10.jar:/opt/hadoop/share/hadoop/hdfs/lib/jsch-0.1.55.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-configuration2-2.8.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/audience-annotations-0.5.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/hadoop/hdfs/lib/jetty-security-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/hdfs/lib/HikariCP-java7-2.4.12.jar:/opt/hadoop/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/jersey-server-1.19.4.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-transport-classes-kqueue-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/animal-sniffer-annotations-1.17.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-codec-1.15.jar:/opt/hadoop/share/hadoop/hdfs/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/reload4j-1.2.22.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-codec-dns-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-native-macos-4.1.89.Final-osx-x86_64.jar:/opt/hadoop/share/hadoop/hdfs/lib/httpclient-4.5.13.jar:/opt/hadoop/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-native-macos-4.1.89.Final-osx-aarch_64.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-transport-native-unix-common-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/paranamer-2.3.jar:/opt/hadoop/share/hadoop/hdfs/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/hadoop/hdfs/lib/okio-2.8.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/hadoop-auth-3.3.6.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-transport-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/jetty-server-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-transport-sctp-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/jetty-webapp-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/hdfs/lib/jetty-servlet-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-transport-native-kqueue-4.1.89.Final-osx-aarch_64.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-codec-http2-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-handler-proxy-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-codec-xml-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-codec-redis-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/httpcore-4.4.13.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-handler-ssl-ocsp-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/zookeeper-3.6.3.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-buffer-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop/share/hadoop/hdfs/lib/stax2-api-4.2.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/jetty-util-ajax-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-codec-http-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-codec-haproxy-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/woodstox-core-5.4.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/jetty-http-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/hdfs/lib/jersey-core-1.19.4.jar:/opt/hadoop/share/hadoop/hdfs/lib/curator-framework-5.2.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-codec-smtp-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/re2j-1.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/hadoop/hdfs/lib/okhttp-4.9.3.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-lang3-3.12.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-text-1.10.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/jersey-servlet-1.19.4.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-codec-memcache-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-transport-native-epoll-4.1.89.Final-linux-x86_64.jar:/opt/hadoop/share/hadoop/hdfs/lib/gson-2.9.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-resolver-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-net-3.9.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-codec-mqtt-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/jackson-core-2.12.7.jar:/opt/hadoop/share/hadoop/hdfs/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/hadoop/hdfs/lib/kotlin-stdlib-1.4.10.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-compress-1.21.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-transport-classes-epoll-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/hadoop/hdfs/lib/curator-client-5.2.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-io-2.8.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/jersey-json-1.20.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-all-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/guava-27.0-jre.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/avro-1.7.7.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/jackson-annotations-2.12.7.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-transport-rxtx-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-handler-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/checker-qual-2.5.2.jar:/opt/hadoop/share/hadoop/hdfs/lib/nimbus-jose-jwt-9.8.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-codec-stomp-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/hadoop-annotations-3.3.6.jar:/opt/hadoop/share/hadoop/hdfs/lib/jackson-databind-2.12.7.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/jetty-util-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-codec-socks-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-transport-native-kqueue-4.1.89.Final-osx-x86_64.jar:/opt/hadoop/share/hadoop/hdfs/lib/jettison-1.5.4.jar:/opt/hadoop/share/hadoop/hdfs/lib/zookeeper-jute-3.6.3.jar:/opt/hadoop/share/hadoop/hdfs/lib/failureaccess-1.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/jetty-io-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-transport-native-epoll-4.1.89.Final-linux-aarch_64.jar:/opt/hadoop/share/hadoop/hdfs/lib/jetty-xml-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.2.jar:/opt/hadoop/share/hadoop/hdfs/lib/j2objc-annotations-1.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-common-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/curator-recipes-5.2.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-3.10.6.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.3.6-tests.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.3.6.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.3.6-tests.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.3.6-tests.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.3.6.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.3.6.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.3.6.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-3.3.6.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.3.6.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.3.6-tests.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.3.6.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.3.6.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.3.6.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.3.6.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.3.6.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.3.6.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.3.6-tests.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.3.6.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.3.6.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.3.6.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.3.6.jar:/opt/hadoop/share/hadoop/yarn:/opt/hadoop/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.12.7.jar:/opt/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/opt/hadoop/share/hadoop/yarn/lib/fst-2.50.jar:/opt/hadoop/share/hadoop/yarn/lib/jersey-guice-1.19.4.jar:/opt/hadoop/share/hadoop/yarn/lib/jetty-plus-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/yarn/lib/javax.websocket-client-api-1.0.jar:/opt/hadoop/share/hadoop/yarn/lib/asm-tree-9.4.jar:/opt/hadoop/share/hadoop/yarn/lib/jetty-client-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/yarn/lib/javax-websocket-client-impl-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-base-2.12.7.jar:/opt/hadoop/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/opt/hadoop/share/hadoop/yarn/lib/bcpkix-jdk15on-1.68.jar:/opt/hadoop/share/hadoop/yarn/lib/javax.websocket-api-1.0.jar:/opt/hadoop/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/opt/hadoop/share/hadoop/yarn/lib/jetty-jndi-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/yarn/lib/websocket-servlet-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/yarn/lib/objenesis-2.6.jar:/opt/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop/share/hadoop/yarn/lib/json-io-2.5.1.jar:/opt/hadoop/share/hadoop/yarn/lib/websocket-server-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/opt/hadoop/share/hadoop/yarn/lib/bcprov-jdk15on-1.68.jar:/opt/hadoop/share/hadoop/yarn/lib/snakeyaml-2.0.jar:/opt/hadoop/share/hadoop/yarn/lib/websocket-api-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/yarn/lib/websocket-common-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/opt/hadoop/share/hadoop/yarn/lib/jersey-client-1.19.4.jar:/opt/hadoop/share/hadoop/yarn/lib/jetty-annotations-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/yarn/lib/jna-5.2.0.jar:/opt/hadoop/share/hadoop/yarn/lib/jakarta.xml.bind-api-2.3.2.jar:/opt/hadoop/share/hadoop/yarn/lib/guice-4.0.jar:/opt/hadoop/share/hadoop/yarn/lib/websocket-client-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/yarn/lib/asm-commons-9.4.jar:/opt/hadoop/share/hadoop/yarn/lib/jline-3.9.0.jar:/opt/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.12.7.jar:/opt/hadoop/share/hadoop/yarn/lib/java-util-1.9.0.jar:/opt/hadoop/share/hadoop/yarn/lib/javax-websocket-server-impl-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.3.6.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.3.6.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-common-3.3.6.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.3.6.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-router-3.3.6.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-client-3.3.6.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.3.6.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-services-api-3.3.6.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-3.3.6.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-3.3.6.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.3.6.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-registry-3.3.6.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-services-core-3.3.6.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-api-3.3.6.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-applications-mawo-core-3.3.6.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.3.6.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.3.6.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.3.6.jar
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:28.743199413Z STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r 1be78238728da9266a4f88195058f08fd012bf9c; compiled by 'ubuntu' on 2023-06-18T08:22Z
[pod/worker-1/spark-worker] 2025-03-21T23:03:02.295537356Z 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[pod/worker-1/spark-worker] 2025-03-21T23:03:02.295552212Z 	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[pod/worker-0/spark-worker] 2025-03-21T23:03:15.954890437Z 	at java.base/java.lang.Thread.run(Thread.java:829)
[pod/worker-0/spark-worker] 2025-03-21T23:03:15.954917025Z Caused by: java.io.IOException: Failed to connect to spark-master.submission-b88ebfea875443329ffa71394f4e85fa.svc.cluster.local:7077
[pod/worker-1/datanode] 2025-03-21T23:03:09.598249291Z 2025-03-21 23:03:09,597 INFO ipc.Client: Retrying connect to server: hdfs-namenode:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[pod/worker-1/datanode] 2025-03-21T23:03:10.599799265Z 2025-03-21 23:03:10,599 INFO ipc.Client: Retrying connect to server: hdfs-namenode:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[pod/worker-1/spark-worker] 2025-03-21T23:03:02.295566453Z 	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[pod/worker-1/spark-worker] 2025-03-21T23:03:02.295582041Z 	at org.apache.spark.deploy.worker.Worker$$anon$1.run(Worker.scala:313)
[pod/worker-1/spark-worker] 2025-03-21T23:03:02.295595674Z 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:28.743202668Z STARTUP_MSG:   java = 11.0.26
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:28.743205459Z ************************************************************/
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:28.752044271Z 2025-03-21 23:03:28,751 INFO namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:28.928558043Z 2025-03-21 23:03:28,928 INFO namenode.NameNode: createNameNode []
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:29.139034022Z 2025-03-21 23:03:29,138 INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:29.363553121Z 2025-03-21 23:03:29,363 INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
[pod/worker-0/spark-worker] 2025-03-21T23:03:15.954936683Z 	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:298)
[pod/worker-0/spark-worker] 2025-03-21T23:03:15.954953009Z 	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:218)
[pod/worker-0/spark-worker] 2025-03-21T23:03:15.955006589Z 	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:230)
[pod/worker-0/spark-worker] 2025-03-21T23:03:15.955019323Z 	at org.apache.spark.rpc.netty.NettyRpcEnv.createClient(NettyRpcEnv.scala:204)
[pod/worker-0/spark-worker] 2025-03-21T23:03:15.955044341Z 	at org.apache.spark.rpc.netty.Outbox$$anon$1.call(Outbox.scala:202)
[pod/worker-1/datanode] 2025-03-21T23:03:11.600540173Z 2025-03-21 23:03:11,600 INFO ipc.Client: Retrying connect to server: hdfs-namenode:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[pod/worker-1/datanode] 2025-03-21T23:03:12.608073089Z 2025-03-21 23:03:12,607 INFO ipc.Client: Retrying connect to server: hdfs-namenode:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[pod/worker-0/spark-worker] 2025-03-21T23:03:15.955052651Z 	at org.apache.spark.rpc.netty.Outbox$$anon$1.call(Outbox.scala:198)
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:29.363602307Z 2025-03-21 23:03:29,363 INFO impl.MetricsSystemImpl: NameNode metrics system started
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:29.382419085Z 2025-03-21 23:03:29,382 INFO namenode.NameNodeUtils: fs.defaultFS is hdfs://hdfs-namenode:8020
[pod/worker-1/spark-worker] 2025-03-21T23:03:02.295608288Z 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[pod/worker-1/spark-worker] 2025-03-21T23:03:02.295622563Z 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[pod/worker-1/spark-worker] 2025-03-21T23:03:02.295639247Z 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[pod/worker-0/spark-worker] 2025-03-21T23:03:15.955061666Z 	... 4 more
[pod/worker-0/spark-worker] 2025-03-21T23:03:15.955071246Z Caused by: java.net.UnknownHostException: spark-master.submission-b88ebfea875443329ffa71394f4e85fa.svc.cluster.local
[pod/worker-0/spark-worker] 2025-03-21T23:03:15.955079847Z 	at java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:797)
[pod/worker-1/datanode] 2025-03-21T23:03:13.608698909Z 2025-03-21 23:03:13,608 INFO ipc.Client: Retrying connect to server: hdfs-namenode:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[pod/worker-1/datanode] 2025-03-21T23:03:14.609604379Z 2025-03-21 23:03:14,608 INFO ipc.Client: Retrying connect to server: hdfs-namenode:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[pod/worker-1/datanode] 2025-03-21T23:03:15.610224658Z 2025-03-21 23:03:15,609 INFO ipc.Client: Retrying connect to server: hdfs-namenode:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[pod/worker-1/spark-worker] 2025-03-21T23:03:02.295652816Z 	at java.base/java.lang.Thread.run(Thread.java:829)
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:29.382498778Z 2025-03-21 23:03:29,382 INFO namenode.NameNode: Clients should use hdfs-namenode:8020 to access this namenode/service.
[pod/worker-1/datanode] 2025-03-21T23:03:16.610748840Z 2025-03-21 23:03:16,610 INFO ipc.Client: Retrying connect to server: hdfs-namenode:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[pod/worker-1/datanode] 2025-03-21T23:03:16.611737946Z 2025-03-21 23:03:16,611 WARN datanode.DataNode: Problem connecting to server: hdfs-namenode:8020
[pod/worker-1/datanode] 2025-03-21T23:03:22.622615104Z 2025-03-21 23:03:22,622 INFO ipc.Client: Retrying connect to server: hdfs-namenode:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[pod/worker-1/spark-worker] 2025-03-21T23:03:02.295665263Z Caused by: java.io.IOException: Failed to connect to spark-master.submission-b88ebfea875443329ffa71394f4e85fa.svc.cluster.local:7077
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:29.665174047Z 2025-03-21 23:03:29,664 INFO util.JvmPauseMonitor: Starting JVM pause monitor
[pod/worker-0/spark-worker] 2025-03-21T23:03:15.955088651Z 	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)
[pod/worker-0/spark-worker] 2025-03-21T23:03:15.955096791Z 	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1386)
[pod/worker-1/datanode] 2025-03-21T23:03:23.623303455Z 2025-03-21 23:03:23,622 INFO ipc.Client: Retrying connect to server: hdfs-namenode:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[pod/worker-1/datanode] 2025-03-21T23:03:24.623958552Z 2025-03-21 23:03:24,623 INFO ipc.Client: Retrying connect to server: hdfs-namenode:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[pod/worker-1/datanode] 2025-03-21T23:03:25.624693077Z 2025-03-21 23:03:25,624 INFO ipc.Client: Retrying connect to server: hdfs-namenode:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[pod/worker-1/spark-worker] 2025-03-21T23:03:02.295685576Z 	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:298)
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:29.702005377Z 2025-03-21 23:03:29,701 INFO hdfs.DFSUtil: Filter initializers set : org.apache.hadoop.http.lib.StaticUserWebFilter,org.apache.hadoop.hdfs.web.AuthFilterInitializer
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:29.709792451Z 2025-03-21 23:03:29,709 INFO hdfs.DFSUtil: Starting Web-server for hdfs at: http://0.0.0.0:50070
[pod/worker-0/spark-worker] 2025-03-21T23:03:15.955104757Z 	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1307)
[pod/worker-0/spark-worker] 2025-03-21T23:03:15.955114391Z 	at java.base/java.net.InetAddress.getByName(InetAddress.java:1257)
[pod/worker-0/spark-worker] 2025-03-21T23:03:15.955123239Z 	at io.netty.util.internal.SocketUtils$8.run(SocketUtils.java:156)
[pod/worker-1/datanode] 2025-03-21T23:03:26.625330898Z 2025-03-21 23:03:26,624 INFO ipc.Client: Retrying connect to server: hdfs-namenode:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[pod/worker-1/spark-worker] 2025-03-21T23:03:02.295700248Z 	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:218)
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:29.731744026Z 2025-03-21 23:03:29,731 INFO util.log: Logging initialized @1973ms to org.eclipse.jetty.util.log.Slf4jLog
[pod/worker-0/spark-worker] 2025-03-21T23:03:15.955132013Z 	at io.netty.util.internal.SocketUtils$8.run(SocketUtils.java:153)
[pod/worker-0/spark-worker] 2025-03-21T23:03:15.955154274Z 	at java.base/java.security.AccessController.doPrivileged(Native Method)
[pod/worker-0/spark-worker] 2025-03-21T23:03:15.955172405Z 	at io.netty.util.internal.SocketUtils.addressByName(SocketUtils.java:153)
[pod/worker-1/datanode] 2025-03-21T23:03:27.626290024Z 2025-03-21 23:03:27,625 INFO ipc.Client: Retrying connect to server: hdfs-namenode:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[pod/worker-1/datanode] 2025-03-21T23:03:28.626987121Z 2025-03-21 23:03:28,626 INFO ipc.Client: Retrying connect to server: hdfs-namenode:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[pod/worker-1/spark-worker] 2025-03-21T23:03:02.295767892Z 	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:230)
[pod/worker-1/spark-worker] 2025-03-21T23:03:02.295779510Z 	at org.apache.spark.rpc.netty.NettyRpcEnv.createClient(NettyRpcEnv.scala:204)
[pod/worker-1/spark-worker] 2025-03-21T23:03:02.295788459Z 	at org.apache.spark.rpc.netty.Outbox$$anon$1.call(Outbox.scala:202)
[pod/worker-1/spark-worker] 2025-03-21T23:03:02.295798213Z 	at org.apache.spark.rpc.netty.Outbox$$anon$1.call(Outbox.scala:198)
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:29.877334689Z 2025-03-21 23:03:29,877 WARN server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /var/local/hadoop/hadoop-http-auth-signature-secret
[pod/worker-1/datanode] 2025-03-21T23:03:29.627542045Z 2025-03-21 23:03:29,627 INFO ipc.Client: Retrying connect to server: hdfs-namenode:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[pod/worker-1/spark-worker] 2025-03-21T23:03:02.295806964Z 	... 4 more
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:29.907924158Z 2025-03-21 23:03:29,907 INFO http.HttpRequestLog: Http request log for http.requests.namenode is not defined
[pod/worker-0/spark-worker] 2025-03-21T23:03:15.955181527Z 	at io.netty.resolver.DefaultNameResolver.doResolve(DefaultNameResolver.java:41)
[pod/worker-0/spark-worker] 2025-03-21T23:03:15.955190936Z 	at io.netty.resolver.SimpleNameResolver.resolve(SimpleNameResolver.java:61)
[pod/worker-1/spark-worker] 2025-03-21T23:03:02.295815748Z Caused by: java.net.UnknownHostException: spark-master.submission-b88ebfea875443329ffa71394f4e85fa.svc.cluster.local
[pod/worker-1/spark-worker] 2025-03-21T23:03:02.295823658Z 	at java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:797)
[pod/worker-1/spark-worker] 2025-03-21T23:03:02.295832449Z 	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)
[pod/worker-1/spark-worker] 2025-03-21T23:03:02.295842440Z 	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1386)
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:29.921916611Z 2025-03-21 23:03:29,921 INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:29.926066146Z 2025-03-21 23:03:29,925 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
[pod/worker-0/spark-worker] 2025-03-21T23:03:15.955214828Z 	at io.netty.resolver.SimpleNameResolver.resolve(SimpleNameResolver.java:53)
[pod/worker-0/spark-worker] 2025-03-21T23:03:15.955224250Z 	at io.netty.resolver.InetSocketAddressResolver.doResolve(InetSocketAddressResolver.java:55)
[pod/worker-0/spark-worker] 2025-03-21T23:03:15.955237813Z 	at io.netty.resolver.InetSocketAddressResolver.doResolve(InetSocketAddressResolver.java:31)
[pod/worker-1/spark-worker] 2025-03-21T23:03:02.295851505Z 	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1307)
[pod/worker-1/datanode] 2025-03-21T23:03:30.628096746Z 2025-03-21 23:03:30,627 INFO ipc.Client: Retrying connect to server: hdfs-namenode:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[pod/worker-0/spark-worker] 2025-03-21T23:03:15.955246277Z 	at io.netty.resolver.AbstractAddressResolver.resolve(AbstractAddressResolver.java:106)
[pod/worker-0/spark-worker] 2025-03-21T23:03:15.955270870Z 	at io.netty.bootstrap.Bootstrap.doResolveAndConnect0(Bootstrap.java:206)
[pod/worker-0/spark-worker] 2025-03-21T23:03:15.955278739Z 	at io.netty.bootstrap.Bootstrap.access$000(Bootstrap.java:46)
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:29.926156842Z 2025-03-21 23:03:29,926 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:29.926306960Z 2025-03-21 23:03:29,926 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
[pod/worker-0/spark-worker] 2025-03-21T23:03:15.955288506Z 	at io.netty.bootstrap.Bootstrap$1.operationComplete(Bootstrap.java:180)
[pod/worker-0/spark-worker] 2025-03-21T23:03:15.955296940Z 	at io.netty.bootstrap.Bootstrap$1.operationComplete(Bootstrap.java:166)
[pod/worker-0/spark-worker] 2025-03-21T23:03:15.955305574Z 	at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:578)
[pod/worker-0/spark-worker] 2025-03-21T23:03:15.955315231Z 	at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:552)
[pod/worker-1/spark-worker] 2025-03-21T23:03:02.295861867Z 	at java.base/java.net.InetAddress.getByName(InetAddress.java:1257)
[pod/worker-1/spark-worker] 2025-03-21T23:03:02.295869088Z 	at io.netty.util.internal.SocketUtils$8.run(SocketUtils.java:156)
[pod/worker-1/spark-worker] 2025-03-21T23:03:02.295874742Z 	at io.netty.util.internal.SocketUtils$8.run(SocketUtils.java:153)
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:29.931892933Z 2025-03-21 23:03:29,931 INFO http.HttpServer2: Added filter AuthFilter (class=org.apache.hadoop.hdfs.web.AuthFilter) to context hdfs
[pod/worker-0/spark-worker] 2025-03-21T23:03:15.955323658Z 	at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:491)
[pod/worker-0/spark-worker] 2025-03-21T23:03:15.955333295Z 	at io.netty.util.concurrent.DefaultPromise.setValue0(DefaultPromise.java:616)
[pod/worker-1/spark-worker] 2025-03-21T23:03:02.295879958Z 	at java.base/java.security.AccessController.doPrivileged(Native Method)
[pod/worker-1/spark-worker] 2025-03-21T23:03:02.295908417Z 	at io.netty.util.internal.SocketUtils.addressByName(SocketUtils.java:153)
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:29.931927467Z 2025-03-21 23:03:29,931 INFO http.HttpServer2: Added filter AuthFilter (class=org.apache.hadoop.hdfs.web.AuthFilter) to context static
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:29.932006435Z 2025-03-21 23:03:29,931 INFO http.HttpServer2: Added filter AuthFilter (class=org.apache.hadoop.hdfs.web.AuthFilter) to context logs
[pod/worker-1/spark-worker] 2025-03-21T23:03:02.295924148Z 	at io.netty.resolver.DefaultNameResolver.doResolve(DefaultNameResolver.java:41)
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:29.985804569Z 2025-03-21 23:03:29,985 INFO http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
[pod/worker-0/spark-worker] 2025-03-21T23:03:15.955343804Z 	at io.netty.util.concurrent.DefaultPromise.setSuccess0(DefaultPromise.java:605)
[pod/worker-0/spark-worker] 2025-03-21T23:03:15.955352756Z 	at io.netty.util.concurrent.DefaultPromise.trySuccess(DefaultPromise.java:104)
[pod/worker-0/spark-worker] 2025-03-21T23:03:15.955362302Z 	at io.netty.channel.DefaultChannelPromise.trySuccess(DefaultChannelPromise.java:84)
[pod/worker-0/spark-worker] 2025-03-21T23:03:15.955372103Z 	at io.netty.channel.AbstractChannel$AbstractUnsafe.safeSetSuccess(AbstractChannel.java:990)
[pod/worker-1/spark-worker] 2025-03-21T23:03:02.295930227Z 	at io.netty.resolver.SimpleNameResolver.resolve(SimpleNameResolver.java:61)
[pod/worker-1/spark-worker] 2025-03-21T23:03:02.295935733Z 	at io.netty.resolver.SimpleNameResolver.resolve(SimpleNameResolver.java:53)
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:30.001002160Z 2025-03-21 23:03:30,000 INFO http.HttpServer2: Jetty bound to port 50070
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:30.002262912Z 2025-03-21 23:03:30,002 INFO server.Server: jetty-9.4.51.v20230217; built: 2023-02-17T08:19:37.309Z; git: b45c405e4544384de066f814ed42ae3dceacdd49; jvm 11.0.26+4-post-Ubuntu-1ubuntu122.04
[pod/worker-0/spark-worker] 2025-03-21T23:03:15.955381041Z 	at io.netty.channel.AbstractChannel$AbstractUnsafe.register0(AbstractChannel.java:516)
[pod/worker-0/spark-worker] 2025-03-21T23:03:15.955390039Z 	at io.netty.channel.AbstractChannel$AbstractUnsafe.access$200(AbstractChannel.java:429)
[pod/worker-0/spark-worker] 2025-03-21T23:03:15.955470562Z 	at io.netty.channel.AbstractChannel$AbstractUnsafe$1.run(AbstractChannel.java:486)
[pod/worker-1/spark-worker] 2025-03-21T23:03:02.295941601Z 	at io.netty.resolver.InetSocketAddressResolver.doResolve(InetSocketAddressResolver.java:55)
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:30.037122492Z 2025-03-21 23:03:30,036 INFO server.session: DefaultSessionIdManager workerName=node0
[pod/worker-0/spark-worker] 2025-03-21T23:03:15.955484652Z 	at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:164)
[pod/worker-0/spark-worker] 2025-03-21T23:03:15.955496484Z 	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:469)
[pod/worker-1/spark-worker] 2025-03-21T23:03:02.295947194Z 	at io.netty.resolver.InetSocketAddressResolver.doResolve(InetSocketAddressResolver.java:31)
[pod/worker-1/spark-worker] 2025-03-21T23:03:02.295952851Z 	at io.netty.resolver.AbstractAddressResolver.resolve(AbstractAddressResolver.java:106)
[pod/worker-1/spark-worker] 2025-03-21T23:03:02.295958492Z 	at io.netty.bootstrap.Bootstrap.doResolveAndConnect0(Bootstrap.java:206)
[pod/worker-1/spark-worker] 2025-03-21T23:03:02.295963952Z 	at io.netty.bootstrap.Bootstrap.access$000(Bootstrap.java:46)
[pod/worker-0/spark-worker] 2025-03-21T23:03:15.955548955Z 	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:503)
[pod/worker-0/spark-worker] 2025-03-21T23:03:15.955563751Z 	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:986)
[pod/worker-0/spark-worker] 2025-03-21T23:03:15.955573916Z 	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
[pod/worker-1/spark-worker] 2025-03-21T23:03:02.295969535Z 	at io.netty.bootstrap.Bootstrap$1.operationComplete(Bootstrap.java:180)
[pod/worker-1/spark-worker] 2025-03-21T23:03:02.295975162Z 	at io.netty.bootstrap.Bootstrap$1.operationComplete(Bootstrap.java:166)
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:30.037158265Z 2025-03-21 23:03:30,036 INFO server.session: No SessionScavenger set, using defaults
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:30.039378332Z 2025-03-21 23:03:30,039 INFO server.session: node0 Scavenging every 600000ms
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:30.068316571Z 2025-03-21 23:03:30,068 WARN server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /var/local/hadoop/hadoop-http-auth-signature-secret
[pod/worker-1/spark-worker] 2025-03-21T23:03:02.295980916Z 	at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:578)
[pod/worker-1/spark-worker] 2025-03-21T23:03:02.295986627Z 	at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:552)
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:30.086112790Z 2025-03-21 23:03:30,071 INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@20a8a64e{logs,/logs,file:///var/local/hadoop/logs/,AVAILABLE}
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:30.086164145Z 2025-03-21 23:03:30,072 INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@34997338{static,/static,file:///opt/hadoop/share/hadoop/hdfs/webapps/static/,AVAILABLE}
[pod/worker-0/spark-worker] 2025-03-21T23:03:15.955583138Z 	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
[pod/worker-1/spark-worker] 2025-03-21T23:03:02.295992053Z 	at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:491)
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:30.225302369Z 2025-03-21 23:03:30,225 INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@56102e1c{hdfs,/,file:///opt/hadoop/share/hadoop/hdfs/webapps/hdfs/,AVAILABLE}{file:/opt/hadoop/share/hadoop/hdfs/webapps/hdfs}
[pod/worker-0/spark-worker] 2025-03-21T23:03:15.955598829Z 	... 1 more
[pod/worker-0/spark-worker] 2025-03-21T23:03:22.919651828Z 25/03/21 23:03:22 INFO Worker: Retrying connection to master (attempt # 2)
[pod/worker-0/spark-worker] 2025-03-21T23:03:22.920383757Z 25/03/21 23:03:22 INFO Worker: Connecting to master spark-master.submission-b88ebfea875443329ffa71394f4e85fa.svc.cluster.local:7077...
[pod/worker-0/spark-worker] 2025-03-21T23:03:22.942610300Z 25/03/21 23:03:22 WARN Worker: Failed to connect to master spark-master.submission-b88ebfea875443329ffa71394f4e85fa.svc.cluster.local:7077
[pod/worker-1/spark-worker] 2025-03-21T23:03:02.295997383Z 	at io.netty.util.concurrent.DefaultPromise.setValue0(DefaultPromise.java:616)
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:30.236109053Z 2025-03-21 23:03:30,235 INFO server.AbstractConnector: Started ServerConnector@3b956878{HTTP/1.1, (http/1.1)}{0.0.0.0:50070}
[pod/worker-0/spark-worker] 2025-03-21T23:03:22.942657779Z org.apache.spark.SparkException: Exception thrown in awaitResult: 
[pod/worker-1/spark-worker] 2025-03-21T23:03:02.296002703Z 	at io.netty.util.concurrent.DefaultPromise.setSuccess0(DefaultPromise.java:605)
[pod/worker-1/spark-worker] 2025-03-21T23:03:02.296008122Z 	at io.netty.util.concurrent.DefaultPromise.trySuccess(DefaultPromise.java:104)
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:30.236159538Z 2025-03-21 23:03:30,236 INFO server.Server: Started @2477ms
[pod/worker-0/spark-worker] 2025-03-21T23:03:22.942676591Z 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[pod/worker-0/spark-worker] 2025-03-21T23:03:22.942692580Z 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[pod/worker-0/spark-worker] 2025-03-21T23:03:22.942709554Z 	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[pod/worker-0/spark-worker] 2025-03-21T23:03:22.942723999Z 	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:30.537216208Z 2025-03-21 23:03:30,536 WARN namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
[pod/worker-0/spark-worker] 2025-03-21T23:03:22.942741081Z 	at org.apache.spark.deploy.worker.Worker$$anon$1.run(Worker.scala:313)
[pod/worker-1/spark-worker] 2025-03-21T23:03:02.296013612Z 	at io.netty.channel.DefaultChannelPromise.trySuccess(DefaultChannelPromise.java:84)
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:30.537258176Z 2025-03-21 23:03:30,537 WARN namenode.FSNamesystem: Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
[pod/worker-0/spark-worker] 2025-03-21T23:03:22.942756278Z 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[pod/worker-1/spark-worker] 2025-03-21T23:03:02.296018979Z 	at io.netty.channel.AbstractChannel$AbstractUnsafe.safeSetSuccess(AbstractChannel.java:990)
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:30.613738216Z 2025-03-21 23:03:30,613 INFO namenode.FSEditLog: Edit logging is async:false
[pod/worker-0/spark-worker] 2025-03-21T23:03:22.942771037Z 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[pod/worker-0/spark-worker] 2025-03-21T23:03:22.942785362Z 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[pod/worker-1/spark-worker] 2025-03-21T23:03:02.296024415Z 	at io.netty.channel.AbstractChannel$AbstractUnsafe.register0(AbstractChannel.java:516)
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:30.655594417Z 2025-03-21 23:03:30,655 INFO namenode.FSNamesystem: KeyProvider: null
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:30.658301123Z 2025-03-21 23:03:30,658 INFO namenode.FSNamesystem: fsLock is fair: true
[pod/worker-1/spark-worker] 2025-03-21T23:03:02.296046612Z 	at io.netty.channel.AbstractChannel$AbstractUnsafe.access$200(AbstractChannel.java:429)
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:30.658451190Z 2025-03-21 23:03:30,658 INFO namenode.FSNamesystem: Detailed lock hold time metrics enabled: false
[pod/worker-0/spark-worker] 2025-03-21T23:03:22.942799272Z 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[pod/worker-0/spark-worker] 2025-03-21T23:03:22.942813777Z 	at java.base/java.lang.Thread.run(Thread.java:829)
[pod/worker-1/spark-worker] 2025-03-21T23:03:02.296079529Z 	at io.netty.channel.AbstractChannel$AbstractUnsafe$1.run(AbstractChannel.java:486)
[pod/worker-1/spark-worker] 2025-03-21T23:03:02.296087649Z 	at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:164)
[pod/worker-1/spark-worker] 2025-03-21T23:03:02.296097042Z 	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:469)
[pod/worker-1/spark-worker] 2025-03-21T23:03:02.296105546Z 	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:503)
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:30.685882180Z 2025-03-21 23:03:30,685 INFO namenode.FSNamesystem: fsOwner                = hadoop (auth:SIMPLE)
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:30.685928619Z 2025-03-21 23:03:30,685 INFO namenode.FSNamesystem: supergroup             = supergroup
[pod/worker-0/spark-worker] 2025-03-21T23:03:22.942827357Z Caused by: java.io.IOException: Failed to connect to spark-master.submission-b88ebfea875443329ffa71394f4e85fa.svc.cluster.local:7077
[pod/worker-0/spark-worker] 2025-03-21T23:03:22.942847155Z 	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:298)
[pod/worker-1/spark-worker] 2025-03-21T23:03:02.296123583Z 	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:986)
[pod/worker-1/spark-worker] 2025-03-21T23:03:02.296131275Z 	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:30.685941710Z 2025-03-21 23:03:30,685 INFO namenode.FSNamesystem: isPermissionEnabled    = false
[pod/worker-0/spark-worker] 2025-03-21T23:03:22.942862061Z 	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:218)
[pod/worker-0/spark-worker] 2025-03-21T23:03:22.942876098Z 	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:230)
[pod/worker-0/spark-worker] 2025-03-21T23:03:22.942891509Z 	at org.apache.spark.rpc.netty.NettyRpcEnv.createClient(NettyRpcEnv.scala:204)
[pod/worker-0/spark-worker] 2025-03-21T23:03:22.942905253Z 	at org.apache.spark.rpc.netty.Outbox$$anon$1.call(Outbox.scala:202)
[pod/worker-1/spark-worker] 2025-03-21T23:03:02.296137192Z 	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:30.685947475Z 2025-03-21 23:03:30,685 INFO namenode.FSNamesystem: isStoragePolicyEnabled = true
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:30.685974437Z 2025-03-21 23:03:30,685 INFO namenode.FSNamesystem: HA Enabled: false
[pod/worker-0/spark-worker] 2025-03-21T23:03:22.942925151Z 	at org.apache.spark.rpc.netty.Outbox$$anon$1.call(Outbox.scala:198)
[pod/worker-1/spark-worker] 2025-03-21T23:03:02.296142592Z 	... 1 more
[pod/worker-0/spark-worker] 2025-03-21T23:03:22.942939325Z 	... 4 more
[pod/worker-0/spark-worker] 2025-03-21T23:03:22.942953262Z Caused by: java.net.UnknownHostException: spark-master.submission-b88ebfea875443329ffa71394f4e85fa.svc.cluster.local
[pod/worker-1/spark-worker] 2025-03-21T23:03:13.250737351Z 25/03/21 23:03:13 INFO Worker: Retrying connection to master (attempt # 2)
[pod/worker-0/spark-worker] 2025-03-21T23:03:22.942965916Z 	at java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:797)
[pod/worker-0/spark-worker] 2025-03-21T23:03:22.942981080Z 	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)
[pod/worker-0/spark-worker] 2025-03-21T23:03:22.943034262Z 	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1386)
[pod/worker-0/spark-worker] 2025-03-21T23:03:22.943045312Z 	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1307)
[pod/worker-0/spark-worker] 2025-03-21T23:03:22.943053302Z 	at java.base/java.net.InetAddress.getByName(InetAddress.java:1257)
[pod/worker-1/spark-worker] 2025-03-21T23:03:13.251121476Z 25/03/21 23:03:13 INFO Worker: Connecting to master spark-master.submission-b88ebfea875443329ffa71394f4e85fa.svc.cluster.local:7077...
[pod/worker-1/spark-worker] 2025-03-21T23:03:13.270044731Z 25/03/21 23:03:13 WARN Worker: Failed to connect to master spark-master.submission-b88ebfea875443329ffa71394f4e85fa.svc.cluster.local:7077
[pod/worker-1/spark-worker] 2025-03-21T23:03:13.270082011Z org.apache.spark.SparkException: Exception thrown in awaitResult: 
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:30.728151790Z 2025-03-21 23:03:30,727 INFO common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:30.905665042Z 2025-03-21 23:03:30,905 INFO blockmanagement.DatanodeManager: dfs.block.invalidate.limit : configured=1000, counted=60, effected=1000
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:30.905712584Z 2025-03-21 23:03:30,905 INFO blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=false
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:30.910629264Z 2025-03-21 23:03:30,910 INFO blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
[pod/worker-1/spark-worker] 2025-03-21T23:03:13.270092834Z 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[pod/worker-0/spark-worker] 2025-03-21T23:03:22.943062507Z 	at io.netty.util.internal.SocketUtils$8.run(SocketUtils.java:156)
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:30.911002389Z 2025-03-21 23:03:30,910 INFO blockmanagement.BlockManager: The block deletion will start around 2025 Mar 21 23:03:30
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:30.912949470Z 2025-03-21 23:03:30,912 INFO util.GSet: Computing capacity for map BlocksMap
[pod/worker-1/spark-worker] 2025-03-21T23:03:13.270105946Z 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[pod/worker-0/spark-worker] 2025-03-21T23:03:22.943079201Z 	at io.netty.util.internal.SocketUtils$8.run(SocketUtils.java:153)
[pod/worker-0/spark-worker] 2025-03-21T23:03:22.943086826Z 	at java.base/java.security.AccessController.doPrivileged(Native Method)
[pod/worker-0/spark-worker] 2025-03-21T23:03:22.943096527Z 	at io.netty.util.internal.SocketUtils.addressByName(SocketUtils.java:153)
[pod/worker-0/spark-worker] 2025-03-21T23:03:22.943110454Z 	at io.netty.resolver.DefaultNameResolver.doResolve(DefaultNameResolver.java:41)
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:30.912964661Z 2025-03-21 23:03:30,912 INFO util.GSet: VM type       = 64-bit
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:30.914430908Z 2025-03-21 23:03:30,914 INFO util.GSet: 2.0% max memory 1 GB = 20.5 MB
[pod/worker-1/spark-worker] 2025-03-21T23:03:13.270123592Z 	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[pod/worker-0/spark-worker] 2025-03-21T23:03:22.943123549Z 	at io.netty.resolver.SimpleNameResolver.resolve(SimpleNameResolver.java:61)
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:30.914446654Z 2025-03-21 23:03:30,914 INFO util.GSet: capacity      = 2^21 = 2097152 entries
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:30.929660132Z 2025-03-21 23:03:30,929 INFO blockmanagement.BlockManager: Storage policy satisfier is disabled
[pod/worker-0/spark-worker] 2025-03-21T23:03:22.943132461Z 	at io.netty.resolver.SimpleNameResolver.resolve(SimpleNameResolver.java:53)
[pod/worker-0/spark-worker] 2025-03-21T23:03:22.943140981Z 	at io.netty.resolver.InetSocketAddressResolver.doResolve(InetSocketAddressResolver.java:55)
[pod/worker-0/spark-worker] 2025-03-21T23:03:22.943156021Z 	at io.netty.resolver.InetSocketAddressResolver.doResolve(InetSocketAddressResolver.java:31)
[pod/worker-0/spark-worker] 2025-03-21T23:03:22.943168809Z 	at io.netty.resolver.AbstractAddressResolver.resolve(AbstractAddressResolver.java:106)
[pod/worker-1/spark-worker] 2025-03-21T23:03:13.270133850Z 	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[pod/worker-0/spark-worker] 2025-03-21T23:03:22.943177650Z 	at io.netty.bootstrap.Bootstrap.doResolveAndConnect0(Bootstrap.java:206)
[pod/worker-1/spark-worker] 2025-03-21T23:03:13.270147981Z 	at org.apache.spark.deploy.worker.Worker$$anon$1.run(Worker.scala:313)
[pod/worker-1/spark-worker] 2025-03-21T23:03:13.270157672Z 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:31.122124473Z 2025-03-21 23:03:30,929 INFO blockmanagement.BlockManager: dfs.block.access.token.enable = false
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:31.122154470Z 2025-03-21 23:03:30,937 INFO blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.threshold-pct = 0.999
[pod/worker-0/spark-worker] 2025-03-21T23:03:22.943186863Z 	at io.netty.bootstrap.Bootstrap.access$000(Bootstrap.java:46)
[pod/worker-0/spark-worker] 2025-03-21T23:03:22.943197071Z 	at io.netty.bootstrap.Bootstrap$1.operationComplete(Bootstrap.java:180)
[pod/worker-1/spark-worker] 2025-03-21T23:03:13.270166226Z 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[pod/worker-1/spark-worker] 2025-03-21T23:03:13.270175047Z 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:31.122160507Z 2025-03-21 23:03:30,937 INFO blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.min.datanodes = 0
[pod/worker-0/spark-worker] 2025-03-21T23:03:22.943206337Z 	at io.netty.bootstrap.Bootstrap$1.operationComplete(Bootstrap.java:166)
[pod/worker-0/spark-worker] 2025-03-21T23:03:22.943215288Z 	at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:578)
[pod/worker-1/spark-worker] 2025-03-21T23:03:13.270186281Z 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[pod/worker-0/spark-worker] 2025-03-21T23:03:22.943225272Z 	at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:552)
[pod/worker-1/spark-worker] 2025-03-21T23:03:13.270194905Z 	at java.base/java.lang.Thread.run(Thread.java:829)
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:31.122164950Z 2025-03-21 23:03:30,937 INFO blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.extension = 30000
[pod/worker-0/spark-worker] 2025-03-21T23:03:22.943234892Z 	at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:491)
[pod/worker-0/spark-worker] 2025-03-21T23:03:22.943245004Z 	at io.netty.util.concurrent.DefaultPromise.setValue0(DefaultPromise.java:616)
[pod/worker-1/spark-worker] 2025-03-21T23:03:13.270203653Z Caused by: java.io.IOException: Failed to connect to spark-master.submission-b88ebfea875443329ffa71394f4e85fa.svc.cluster.local:7077
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:31.122169368Z 2025-03-21 23:03:30,938 INFO blockmanagement.BlockManager: defaultReplication         = 3
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:31.122173733Z 2025-03-21 23:03:30,938 INFO blockmanagement.BlockManager: maxReplication             = 512
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:31.122197619Z 2025-03-21 23:03:30,939 INFO blockmanagement.BlockManager: minReplication             = 1
[pod/worker-0/spark-worker] 2025-03-21T23:03:22.943254888Z 	at io.netty.util.concurrent.DefaultPromise.setSuccess0(DefaultPromise.java:605)
[pod/worker-0/spark-worker] 2025-03-21T23:03:22.943264889Z 	at io.netty.util.concurrent.DefaultPromise.trySuccess(DefaultPromise.java:104)
[pod/worker-1/spark-worker] 2025-03-21T23:03:13.270213614Z 	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:298)
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:31.122200923Z 2025-03-21 23:03:30,939 INFO blockmanagement.BlockManager: maxReplicationStreams      = 2
[pod/worker-0/spark-worker] 2025-03-21T23:03:22.943275237Z 	at io.netty.channel.DefaultChannelPromise.trySuccess(DefaultChannelPromise.java:84)
[pod/worker-0/spark-worker] 2025-03-21T23:03:22.943284804Z 	at io.netty.channel.AbstractChannel$AbstractUnsafe.safeSetSuccess(AbstractChannel.java:990)
[pod/worker-0/spark-worker] 2025-03-21T23:03:22.943295543Z 	at io.netty.channel.AbstractChannel$AbstractUnsafe.register0(AbstractChannel.java:516)
[pod/worker-1/spark-worker] 2025-03-21T23:03:13.270227177Z 	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:218)
[pod/worker-1/spark-worker] 2025-03-21T23:03:13.270236199Z 	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:230)
[pod/worker-1/spark-worker] 2025-03-21T23:03:13.270246257Z 	at org.apache.spark.rpc.netty.NettyRpcEnv.createClient(NettyRpcEnv.scala:204)
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:31.122203460Z 2025-03-21 23:03:30,939 INFO blockmanagement.BlockManager: redundancyRecheckInterval  = 3000ms
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:31.122205892Z 2025-03-21 23:03:30,939 INFO blockmanagement.BlockManager: encryptDataTransfer        = false
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:31.122208436Z 2025-03-21 23:03:30,939 INFO blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
[pod/worker-1/spark-worker] 2025-03-21T23:03:13.270254747Z 	at org.apache.spark.rpc.netty.Outbox$$anon$1.call(Outbox.scala:202)
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:31.122210962Z 2025-03-21 23:03:30,980 INFO namenode.FSDirectory: GLOBAL serial map: bits=29 maxEntries=536870911
[pod/worker-0/spark-worker] 2025-03-21T23:03:22.943304224Z 	at io.netty.channel.AbstractChannel$AbstractUnsafe.access$200(AbstractChannel.java:429)
[pod/worker-0/spark-worker] 2025-03-21T23:03:22.943351215Z 	at io.netty.channel.AbstractChannel$AbstractUnsafe$1.run(AbstractChannel.java:486)
[pod/worker-0/spark-worker] 2025-03-21T23:03:22.943366164Z 	at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:164)
[pod/worker-1/spark-worker] 2025-03-21T23:03:13.270263168Z 	at org.apache.spark.rpc.netty.Outbox$$anon$1.call(Outbox.scala:198)
[pod/worker-1/spark-worker] 2025-03-21T23:03:13.270271739Z 	... 4 more
[pod/worker-0/spark-worker] 2025-03-21T23:03:22.943375550Z 	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:469)
[pod/worker-1/spark-worker] 2025-03-21T23:03:13.270283023Z Caused by: java.net.UnknownHostException: spark-master.submission-b88ebfea875443329ffa71394f4e85fa.svc.cluster.local
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:31.122213532Z 2025-03-21 23:03:30,980 INFO namenode.FSDirectory: USER serial map: bits=24 maxEntries=16777215
[pod/worker-0/spark-worker] 2025-03-21T23:03:22.943385107Z 	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:503)
[pod/worker-0/spark-worker] 2025-03-21T23:03:22.943393962Z 	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:986)
[pod/worker-1/spark-worker] 2025-03-21T23:03:13.270291670Z 	at java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:797)
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:31.122216114Z 2025-03-21 23:03:30,980 INFO namenode.FSDirectory: GROUP serial map: bits=24 maxEntries=16777215
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:31.122218578Z 2025-03-21 23:03:30,980 INFO namenode.FSDirectory: XATTR serial map: bits=24 maxEntries=16777215
[pod/worker-0/spark-worker] 2025-03-21T23:03:22.943403067Z 	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:31.122224356Z 2025-03-21 23:03:31,004 INFO util.GSet: Computing capacity for map INodeMap
[pod/worker-0/spark-worker] 2025-03-21T23:03:22.943411815Z 	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
[pod/worker-0/spark-worker] 2025-03-21T23:03:22.943447084Z 	... 1 more
[pod/worker-0/spark-worker] 2025-03-21T23:03:29.919465344Z 25/03/21 23:03:29 INFO Worker: Retrying connection to master (attempt # 3)
[pod/worker-1/spark-worker] 2025-03-21T23:03:13.270299940Z 	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:31.122227575Z 2025-03-21 23:03:31,004 INFO util.GSet: VM type       = 64-bit
[pod/worker-1/spark-worker] 2025-03-21T23:03:13.270346988Z 	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1386)
[pod/worker-1/spark-worker] 2025-03-21T23:03:13.270354860Z 	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1307)
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:31.122230084Z 2025-03-21 23:03:31,004 INFO util.GSet: 1.0% max memory 1 GB = 10.2 MB
[pod/worker-0/spark-worker] 2025-03-21T23:03:29.920165002Z 25/03/21 23:03:29 INFO Worker: Connecting to master spark-master.submission-b88ebfea875443329ffa71394f4e85fa.svc.cluster.local:7077...
[pod/worker-0/spark-worker] 2025-03-21T23:03:29.934610616Z 25/03/21 23:03:29 WARN Worker: Failed to connect to master spark-master.submission-b88ebfea875443329ffa71394f4e85fa.svc.cluster.local:7077
[pod/worker-0/spark-worker] 2025-03-21T23:03:29.934665636Z org.apache.spark.SparkException: Exception thrown in awaitResult: 
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:31.122232564Z 2025-03-21 23:03:31,004 INFO util.GSet: capacity      = 2^20 = 1048576 entries
[pod/worker-0/spark-worker] 2025-03-21T23:03:29.934678831Z 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[pod/worker-1/spark-worker] 2025-03-21T23:03:13.270360865Z 	at java.base/java.net.InetAddress.getByName(InetAddress.java:1257)
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:31.122235064Z 2025-03-21 23:03:31,008 INFO namenode.FSDirectory: ACLs enabled? true
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:31.122237499Z 2025-03-21 23:03:31,008 INFO namenode.FSDirectory: POSIX ACL inheritance enabled? true
[pod/worker-1/spark-worker] 2025-03-21T23:03:13.270368804Z 	at io.netty.util.internal.SocketUtils$8.run(SocketUtils.java:156)
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:31.122240118Z 2025-03-21 23:03:31,008 INFO namenode.FSDirectory: XAttrs enabled? true
[pod/worker-0/spark-worker] 2025-03-21T23:03:29.934687913Z 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[pod/worker-0/spark-worker] 2025-03-21T23:03:29.934696905Z 	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[pod/worker-1/spark-worker] 2025-03-21T23:03:13.270374141Z 	at io.netty.util.internal.SocketUtils$8.run(SocketUtils.java:153)
[pod/worker-1/spark-worker] 2025-03-21T23:03:13.270379647Z 	at java.base/java.security.AccessController.doPrivileged(Native Method)
[pod/worker-1/spark-worker] 2025-03-21T23:03:13.270389231Z 	at io.netty.util.internal.SocketUtils.addressByName(SocketUtils.java:153)
[pod/worker-0/spark-worker] 2025-03-21T23:03:29.934707020Z 	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[pod/worker-0/spark-worker] 2025-03-21T23:03:29.934715791Z 	at org.apache.spark.deploy.worker.Worker$$anon$1.run(Worker.scala:313)
[pod/worker-0/spark-worker] 2025-03-21T23:03:29.934724686Z 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[pod/worker-0/spark-worker] 2025-03-21T23:03:29.934733086Z 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[pod/worker-1/spark-worker] 2025-03-21T23:03:13.270395001Z 	at io.netty.resolver.DefaultNameResolver.doResolve(DefaultNameResolver.java:41)
[pod/worker-1/spark-worker] 2025-03-21T23:03:13.270400491Z 	at io.netty.resolver.SimpleNameResolver.resolve(SimpleNameResolver.java:61)
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:31.122242575Z 2025-03-21 23:03:31,008 INFO namenode.NameNode: Caching file names occurring more than 10 times
[pod/worker-0/spark-worker] 2025-03-21T23:03:29.934741436Z 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[pod/worker-1/spark-worker] 2025-03-21T23:03:13.270406523Z 	at io.netty.resolver.SimpleNameResolver.resolve(SimpleNameResolver.java:53)
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:31.122246180Z 2025-03-21 23:03:31,013 INFO snapshot.SnapshotManager: Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:31.122248948Z 2025-03-21 23:03:31,015 INFO snapshot.SnapshotManager: SkipList is disabled
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:31.122251340Z 2025-03-21 23:03:31,019 INFO util.GSet: Computing capacity for map cachedBlocks
[pod/worker-0/spark-worker] 2025-03-21T23:03:29.934749783Z 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[pod/worker-0/spark-worker] 2025-03-21T23:03:29.934758338Z 	at java.base/java.lang.Thread.run(Thread.java:829)
[pod/worker-1/spark-worker] 2025-03-21T23:03:13.270415147Z 	at io.netty.resolver.InetSocketAddressResolver.doResolve(InetSocketAddressResolver.java:55)
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:31.122253893Z 2025-03-21 23:03:31,019 INFO util.GSet: VM type       = 64-bit
[pod/worker-0/spark-worker] 2025-03-21T23:03:29.934767577Z Caused by: java.io.IOException: Failed to connect to spark-master.submission-b88ebfea875443329ffa71394f4e85fa.svc.cluster.local:7077
[pod/worker-1/spark-worker] 2025-03-21T23:03:13.270420493Z 	at io.netty.resolver.InetSocketAddressResolver.doResolve(InetSocketAddressResolver.java:31)
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:31.122256317Z 2025-03-21 23:03:31,020 INFO util.GSet: 0.25% max memory 1 GB = 2.6 MB
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:31.122258672Z 2025-03-21 23:03:31,020 INFO util.GSet: capacity      = 2^18 = 262144 entries
[pod/worker-0/spark-worker] 2025-03-21T23:03:29.934777146Z 	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:298)
[pod/worker-0/spark-worker] 2025-03-21T23:03:29.934785888Z 	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:218)
[pod/worker-0/spark-worker] 2025-03-21T23:03:29.934794134Z 	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:230)
[pod/worker-1/spark-worker] 2025-03-21T23:03:13.270425819Z 	at io.netty.resolver.AbstractAddressResolver.resolve(AbstractAddressResolver.java:106)
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:31.122261129Z 2025-03-21 23:03:31,028 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
[pod/worker-0/spark-worker] 2025-03-21T23:03:29.934802625Z 	at org.apache.spark.rpc.netty.NettyRpcEnv.createClient(NettyRpcEnv.scala:204)
[pod/worker-0/spark-worker] 2025-03-21T23:03:29.934810999Z 	at org.apache.spark.rpc.netty.Outbox$$anon$1.call(Outbox.scala:202)
[pod/worker-0/spark-worker] 2025-03-21T23:03:29.934819309Z 	at org.apache.spark.rpc.netty.Outbox$$anon$1.call(Outbox.scala:198)
[pod/worker-0/spark-worker] 2025-03-21T23:03:29.934827582Z 	... 4 more
[pod/worker-0/spark-worker] 2025-03-21T23:03:29.934842415Z Caused by: java.net.UnknownHostException: spark-master.submission-b88ebfea875443329ffa71394f4e85fa.svc.cluster.local
[pod/worker-1/spark-worker] 2025-03-21T23:03:13.270431353Z 	at io.netty.bootstrap.Bootstrap.doResolveAndConnect0(Bootstrap.java:206)
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:31.122263521Z 2025-03-21 23:03:31,028 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
[pod/worker-0/spark-worker] 2025-03-21T23:03:29.934851283Z 	at java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:797)
[pod/worker-0/spark-worker] 2025-03-21T23:03:29.934859744Z 	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)
[pod/worker-1/spark-worker] 2025-03-21T23:03:13.270436632Z 	at io.netty.bootstrap.Bootstrap.access$000(Bootstrap.java:46)
[pod/worker-1/spark-worker] 2025-03-21T23:03:13.270441939Z 	at io.netty.bootstrap.Bootstrap$1.operationComplete(Bootstrap.java:180)
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:31.122266099Z 2025-03-21 23:03:31,028 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
[pod/worker-0/spark-worker] 2025-03-21T23:03:29.934868876Z 	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1386)
[pod/worker-1/spark-worker] 2025-03-21T23:03:13.270447178Z 	at io.netty.bootstrap.Bootstrap$1.operationComplete(Bootstrap.java:166)
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:31.122268446Z 2025-03-21 23:03:31,035 INFO namenode.FSNamesystem: Retry cache on namenode is enabled
[pod/worker-0/spark-worker] 2025-03-21T23:03:29.934877032Z 	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1307)
[pod/worker-1/spark-worker] 2025-03-21T23:03:13.270452447Z 	at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:578)
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:31.122271633Z 2025-03-21 23:03:31,035 INFO namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
[pod/worker-1/spark-worker] 2025-03-21T23:03:13.270457857Z 	at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:552)
[pod/worker-0/spark-worker] 2025-03-21T23:03:29.934885286Z 	at java.base/java.net.InetAddress.getByName(InetAddress.java:1257)
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:31.122274037Z 2025-03-21 23:03:31,038 INFO util.GSet: Computing capacity for map NameNodeRetryCache
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:31.122276385Z 2025-03-21 23:03:31,038 INFO util.GSet: VM type       = 64-bit
[pod/worker-1/spark-worker] 2025-03-21T23:03:13.270463591Z 	at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:491)
[pod/worker-1/spark-worker] 2025-03-21T23:03:13.270468851Z 	at io.netty.util.concurrent.DefaultPromise.setValue0(DefaultPromise.java:616)
[pod/worker-1/spark-worker] 2025-03-21T23:03:13.270474147Z 	at io.netty.util.concurrent.DefaultPromise.setSuccess0(DefaultPromise.java:605)
[pod/worker-1/spark-worker] 2025-03-21T23:03:13.270479323Z 	at io.netty.util.concurrent.DefaultPromise.trySuccess(DefaultPromise.java:104)
[pod/worker-0/spark-worker] 2025-03-21T23:03:29.934896590Z 	at io.netty.util.internal.SocketUtils$8.run(SocketUtils.java:156)
[pod/worker-0/spark-worker] 2025-03-21T23:03:29.934904880Z 	at io.netty.util.internal.SocketUtils$8.run(SocketUtils.java:153)
[pod/worker-0/spark-worker] 2025-03-21T23:03:29.934913357Z 	at java.base/java.security.AccessController.doPrivileged(Native Method)
[pod/worker-0/spark-worker] 2025-03-21T23:03:29.934921530Z 	at io.netty.util.internal.SocketUtils.addressByName(SocketUtils.java:153)
[pod/worker-1/spark-worker] 2025-03-21T23:03:13.270485738Z 	at io.netty.channel.DefaultChannelPromise.trySuccess(DefaultChannelPromise.java:84)
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:31.122279192Z 2025-03-21 23:03:31,038 INFO util.GSet: 0.029999999329447746% max memory 1 GB = 314.6 KB
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:31.122281828Z 2025-03-21 23:03:31,038 INFO util.GSet: capacity      = 2^15 = 32768 entries
[pod/worker-0/spark-worker] 2025-03-21T23:03:29.934929901Z 	at io.netty.resolver.DefaultNameResolver.doResolve(DefaultNameResolver.java:41)
[pod/worker-0/spark-worker] 2025-03-21T23:03:29.934973697Z 	at io.netty.resolver.SimpleNameResolver.resolve(SimpleNameResolver.java:61)
[pod/worker-1/spark-worker] 2025-03-21T23:03:13.270491669Z 	at io.netty.channel.AbstractChannel$AbstractUnsafe.safeSetSuccess(AbstractChannel.java:990)
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:31.122295054Z 2025-03-21 23:03:31,103 INFO common.Storage: Lock on /var/local/hadoop/name/in_use.lock acquired by nodename 1@hdfs-namenode-0
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:31.131870892Z 2025-03-21 23:03:31,131 INFO namenode.FileJournalManager: Recovering unfinalized segments in /var/local/hadoop/name/current
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:31.132100999Z 2025-03-21 23:03:31,132 INFO namenode.FSImage: No edit log streams selected.
[pod/worker-1/spark-worker] 2025-03-21T23:03:13.270496859Z 	at io.netty.channel.AbstractChannel$AbstractUnsafe.register0(AbstractChannel.java:516)
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:31.132354933Z 2025-03-21 23:03:31,132 INFO namenode.FSImage: Planning to load image: FSImageFile(file=/var/local/hadoop/name/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
[pod/worker-1/spark-worker] 2025-03-21T23:03:13.270502506Z 	at io.netty.channel.AbstractChannel$AbstractUnsafe.access$200(AbstractChannel.java:429)
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:31.238458435Z 2025-03-21 23:03:31,238 INFO namenode.FSImageFormatPBINode: Loading 1 INodes.
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:31.320434072Z 2025-03-21 23:03:31,253 INFO namenode.FSImageFormatPBINode: Successfully loaded 1 inodes
[pod/worker-1/spark-worker] 2025-03-21T23:03:13.270533474Z 	at io.netty.channel.AbstractChannel$AbstractUnsafe$1.run(AbstractChannel.java:486)
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:31.320462858Z 2025-03-21 23:03:31,268 INFO namenode.FSImageFormatPBINode: Completed update blocks map and name cache, total waiting duration 0ms.
[pod/worker-1/spark-worker] 2025-03-21T23:03:13.270540311Z 	at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:164)
[pod/worker-0/spark-worker] 2025-03-21T23:03:29.934980774Z 	at io.netty.resolver.SimpleNameResolver.resolve(SimpleNameResolver.java:53)
[pod/worker-0/spark-worker] 2025-03-21T23:03:29.934986645Z 	at io.netty.resolver.InetSocketAddressResolver.doResolve(InetSocketAddressResolver.java:55)
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:31.320469487Z 2025-03-21 23:03:31,281 INFO namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
[pod/worker-1/spark-worker] 2025-03-21T23:03:13.270545727Z 	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:469)
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:31.320474989Z 2025-03-21 23:03:31,281 INFO namenode.FSImage: Loaded image for txid 0 from /var/local/hadoop/name/current/fsimage_0000000000000000000
[pod/worker-0/spark-worker] 2025-03-21T23:03:29.934992162Z 	at io.netty.resolver.InetSocketAddressResolver.doResolve(InetSocketAddressResolver.java:31)
[pod/worker-1/spark-worker] 2025-03-21T23:03:13.270550900Z 	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:503)
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:31.320480771Z 2025-03-21 23:03:31,288 INFO namenode.FSNamesystem: Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
[pod/worker-0/spark-worker] 2025-03-21T23:03:29.934997996Z 	at io.netty.resolver.AbstractAddressResolver.resolve(AbstractAddressResolver.java:106)
[pod/worker-1/spark-worker] 2025-03-21T23:03:13.270556199Z 	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:986)
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:31.320486357Z 2025-03-21 23:03:31,288 INFO namenode.FSEditLog: Starting log segment at 1
[pod/worker-0/spark-worker] 2025-03-21T23:03:29.935003596Z 	at io.netty.bootstrap.Bootstrap.doResolveAndConnect0(Bootstrap.java:206)
[pod/worker-0/spark-worker] 2025-03-21T23:03:29.935009220Z 	at io.netty.bootstrap.Bootstrap.access$000(Bootstrap.java:46)
[pod/worker-0/spark-worker] 2025-03-21T23:03:29.935015131Z 	at io.netty.bootstrap.Bootstrap$1.operationComplete(Bootstrap.java:180)
[pod/worker-1/spark-worker] 2025-03-21T23:03:13.270561322Z 	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
[pod/worker-1/spark-worker] 2025-03-21T23:03:13.270567517Z 	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:31.320491365Z Mar 21, 2025 11:03:31 PM com.sun.jersey.api.core.PackagesResourceConfig init
[pod/worker-0/spark-worker] 2025-03-21T23:03:29.935020661Z 	at io.netty.bootstrap.Bootstrap$1.operationComplete(Bootstrap.java:166)
[pod/worker-0/spark-worker] 2025-03-21T23:03:29.935026101Z 	at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:578)
[pod/worker-1/spark-worker] 2025-03-21T23:03:13.270586316Z 	... 1 more
[pod/worker-1/spark-worker] 2025-03-21T23:03:24.251004242Z 25/03/21 23:03:24 INFO Worker: Retrying connection to master (attempt # 3)
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:31.320496401Z INFO: Scanning for root resource and provider classes in the packages:
[pod/worker-0/spark-worker] 2025-03-21T23:03:29.935031711Z 	at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:552)
[pod/worker-0/spark-worker] 2025-03-21T23:03:29.935037124Z 	at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:491)
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:31.320501620Z   org.apache.hadoop.hdfs.server.namenode.web.resources
[pod/worker-0/spark-worker] 2025-03-21T23:03:29.935042621Z 	at io.netty.util.concurrent.DefaultPromise.setValue0(DefaultPromise.java:616)
[pod/worker-1/spark-worker] 2025-03-21T23:03:24.251699420Z 25/03/21 23:03:24 INFO Worker: Connecting to master spark-master.submission-b88ebfea875443329ffa71394f4e85fa.svc.cluster.local:7077...
[pod/worker-1/spark-worker] 2025-03-21T23:03:24.266635687Z 25/03/21 23:03:24 WARN Worker: Failed to connect to master spark-master.submission-b88ebfea875443329ffa71394f4e85fa.svc.cluster.local:7077
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:31.320507271Z   org.apache.hadoop.hdfs.web.resources
[pod/worker-0/spark-worker] 2025-03-21T23:03:29.935048154Z 	at io.netty.util.concurrent.DefaultPromise.setSuccess0(DefaultPromise.java:605)
[pod/worker-1/spark-worker] 2025-03-21T23:03:24.266672794Z org.apache.spark.SparkException: Exception thrown in awaitResult: 
[pod/worker-1/spark-worker] 2025-03-21T23:03:24.266685756Z 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[pod/worker-0/spark-worker] 2025-03-21T23:03:29.935053881Z 	at io.netty.util.concurrent.DefaultPromise.trySuccess(DefaultPromise.java:104)
[pod/worker-0/spark-worker] 2025-03-21T23:03:29.935062933Z 	at io.netty.channel.DefaultChannelPromise.trySuccess(DefaultChannelPromise.java:84)
[pod/worker-1/spark-worker] 2025-03-21T23:03:24.266695192Z 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[pod/worker-0/spark-worker] 2025-03-21T23:03:29.935068590Z 	at io.netty.channel.AbstractChannel$AbstractUnsafe.safeSetSuccess(AbstractChannel.java:990)
[pod/worker-0/spark-worker] 2025-03-21T23:03:29.935074147Z 	at io.netty.channel.AbstractChannel$AbstractUnsafe.register0(AbstractChannel.java:516)
[pod/worker-1/spark-worker] 2025-03-21T23:03:24.266703913Z 	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[pod/worker-1/spark-worker] 2025-03-21T23:03:24.266712460Z 	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[pod/worker-0/spark-worker] 2025-03-21T23:03:29.935079584Z 	at io.netty.channel.AbstractChannel$AbstractUnsafe.access$200(AbstractChannel.java:429)
[pod/worker-0/spark-worker] 2025-03-21T23:03:29.935108467Z 	at io.netty.channel.AbstractChannel$AbstractUnsafe$1.run(AbstractChannel.java:486)
[pod/worker-1/spark-worker] 2025-03-21T23:03:24.266721172Z 	at org.apache.spark.deploy.worker.Worker$$anon$1.run(Worker.scala:313)
[pod/worker-0/spark-worker] 2025-03-21T23:03:29.935115454Z 	at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:164)
[pod/worker-0/spark-worker] 2025-03-21T23:03:29.935120988Z 	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:469)
[pod/worker-1/spark-worker] 2025-03-21T23:03:24.266731894Z 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[pod/worker-1/spark-worker] 2025-03-21T23:03:24.266740726Z 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[pod/worker-0/spark-worker] 2025-03-21T23:03:29.935126494Z 	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:503)
[pod/worker-0/spark-worker] 2025-03-21T23:03:29.935132014Z 	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:986)
[pod/worker-0/spark-worker] 2025-03-21T23:03:29.935137304Z 	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
[pod/worker-0/spark-worker] 2025-03-21T23:03:29.935142590Z 	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
[pod/worker-0/spark-worker] 2025-03-21T23:03:29.935148117Z 	... 1 more
[pod/worker-1/spark-worker] 2025-03-21T23:03:24.266749323Z 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[pod/worker-1/spark-worker] 2025-03-21T23:03:24.266757867Z 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[pod/worker-1/spark-worker] 2025-03-21T23:03:24.266766428Z 	at java.base/java.lang.Thread.run(Thread.java:829)
[pod/worker-1/spark-worker] 2025-03-21T23:03:24.266774962Z Caused by: java.io.IOException: Failed to connect to spark-master.submission-b88ebfea875443329ffa71394f4e85fa.svc.cluster.local:7077
[pod/worker-1/spark-worker] 2025-03-21T23:03:24.266784388Z 	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:298)
[pod/worker-1/spark-worker] 2025-03-21T23:03:24.266792695Z 	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:218)
[pod/worker-1/spark-worker] 2025-03-21T23:03:24.266800895Z 	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:230)
[pod/worker-1/spark-worker] 2025-03-21T23:03:24.266809209Z 	at org.apache.spark.rpc.netty.NettyRpcEnv.createClient(NettyRpcEnv.scala:204)
[pod/worker-1/spark-worker] 2025-03-21T23:03:24.266817790Z 	at org.apache.spark.rpc.netty.Outbox$$anon$1.call(Outbox.scala:202)
[pod/worker-1/spark-worker] 2025-03-21T23:03:24.266826250Z 	at org.apache.spark.rpc.netty.Outbox$$anon$1.call(Outbox.scala:198)
[pod/worker-1/spark-worker] 2025-03-21T23:03:24.266834704Z 	... 4 more
[pod/worker-1/spark-worker] 2025-03-21T23:03:24.266844982Z Caused by: java.net.UnknownHostException: spark-master.submission-b88ebfea875443329ffa71394f4e85fa.svc.cluster.local
[pod/worker-1/spark-worker] 2025-03-21T23:03:24.266853663Z 	at java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:797)
[pod/worker-1/spark-worker] 2025-03-21T23:03:24.266862167Z 	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)
[pod/worker-1/spark-worker] 2025-03-21T23:03:24.266870621Z 	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1386)
[pod/worker-1/spark-worker] 2025-03-21T23:03:24.266878948Z 	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1307)
[pod/worker-1/spark-worker] 2025-03-21T23:03:24.266949329Z 	at java.base/java.net.InetAddress.getByName(InetAddress.java:1257)
[pod/worker-1/spark-worker] 2025-03-21T23:03:24.266965385Z 	at io.netty.util.internal.SocketUtils$8.run(SocketUtils.java:156)
[pod/worker-1/spark-worker] 2025-03-21T23:03:24.266974597Z 	at io.netty.util.internal.SocketUtils$8.run(SocketUtils.java:153)
[pod/worker-1/spark-worker] 2025-03-21T23:03:24.266983789Z 	at java.base/java.security.AccessController.doPrivileged(Native Method)
[pod/worker-1/spark-worker] 2025-03-21T23:03:24.266992631Z 	at io.netty.util.internal.SocketUtils.addressByName(SocketUtils.java:153)
[pod/worker-1/spark-worker] 2025-03-21T23:03:24.267001693Z 	at io.netty.resolver.DefaultNameResolver.doResolve(DefaultNameResolver.java:41)
[pod/worker-1/spark-worker] 2025-03-21T23:03:24.267044089Z 	at io.netty.resolver.SimpleNameResolver.resolve(SimpleNameResolver.java:61)
[pod/worker-1/spark-worker] 2025-03-21T23:03:24.267051200Z 	at io.netty.resolver.SimpleNameResolver.resolve(SimpleNameResolver.java:53)
[pod/worker-1/spark-worker] 2025-03-21T23:03:24.267057161Z 	at io.netty.resolver.InetSocketAddressResolver.doResolve(InetSocketAddressResolver.java:55)
[pod/worker-1/spark-worker] 2025-03-21T23:03:24.267062895Z 	at io.netty.resolver.InetSocketAddressResolver.doResolve(InetSocketAddressResolver.java:31)
[pod/worker-1/spark-worker] 2025-03-21T23:03:24.267068448Z 	at io.netty.resolver.AbstractAddressResolver.resolve(AbstractAddressResolver.java:106)
[pod/worker-1/spark-worker] 2025-03-21T23:03:24.267073878Z 	at io.netty.bootstrap.Bootstrap.doResolveAndConnect0(Bootstrap.java:206)
[pod/worker-1/spark-worker] 2025-03-21T23:03:24.267079699Z 	at io.netty.bootstrap.Bootstrap.access$000(Bootstrap.java:46)
[pod/worker-1/spark-worker] 2025-03-21T23:03:24.267085406Z 	at io.netty.bootstrap.Bootstrap$1.operationComplete(Bootstrap.java:180)
[pod/worker-1/spark-worker] 2025-03-21T23:03:24.267090913Z 	at io.netty.bootstrap.Bootstrap$1.operationComplete(Bootstrap.java:166)
[pod/worker-1/spark-worker] 2025-03-21T23:03:24.267096383Z 	at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:578)
[pod/worker-1/spark-worker] 2025-03-21T23:03:24.267102133Z 	at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:552)
[pod/worker-1/spark-worker] 2025-03-21T23:03:24.267107770Z 	at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:491)
[pod/worker-1/spark-worker] 2025-03-21T23:03:24.267115202Z 	at io.netty.util.concurrent.DefaultPromise.setValue0(DefaultPromise.java:616)
[pod/worker-1/spark-worker] 2025-03-21T23:03:24.267121754Z 	at io.netty.util.concurrent.DefaultPromise.setSuccess0(DefaultPromise.java:605)
[pod/worker-1/spark-worker] 2025-03-21T23:03:24.267127007Z 	at io.netty.util.concurrent.DefaultPromise.trySuccess(DefaultPromise.java:104)
[pod/worker-1/spark-worker] 2025-03-21T23:03:24.267133122Z 	at io.netty.channel.DefaultChannelPromise.trySuccess(DefaultChannelPromise.java:84)
[pod/worker-1/spark-worker] 2025-03-21T23:03:24.267138382Z 	at io.netty.channel.AbstractChannel$AbstractUnsafe.safeSetSuccess(AbstractChannel.java:990)
[pod/worker-1/spark-worker] 2025-03-21T23:03:24.267143594Z 	at io.netty.channel.AbstractChannel$AbstractUnsafe.register0(AbstractChannel.java:516)
[pod/worker-1/spark-worker] 2025-03-21T23:03:24.267148954Z 	at io.netty.channel.AbstractChannel$AbstractUnsafe.access$200(AbstractChannel.java:429)
[pod/worker-1/spark-worker] 2025-03-21T23:03:24.267184958Z 	at io.netty.channel.AbstractChannel$AbstractUnsafe$1.run(AbstractChannel.java:486)
[pod/worker-1/spark-worker] 2025-03-21T23:03:24.267192723Z 	at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:164)
[pod/worker-1/spark-worker] 2025-03-21T23:03:24.267198487Z 	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:469)
[pod/worker-1/spark-worker] 2025-03-21T23:03:24.267203850Z 	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:503)
[pod/worker-1/spark-worker] 2025-03-21T23:03:24.267209244Z 	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:986)
[pod/worker-1/spark-worker] 2025-03-21T23:03:24.267214640Z 	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
[pod/worker-1/spark-worker] 2025-03-21T23:03:24.267220207Z 	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
[pod/worker-1/spark-worker] 2025-03-21T23:03:24.267225707Z 	... 1 more
[pod/spark-master-0/spark-master] 2025-03-21T23:03:31.554261662Z 25/03/21 23:03:31 INFO MasterWebUI: Bound MasterWebUI to 0.0.0.0, and started at http://spark-master-0.spark-master.submission-b88ebfea875443329ffa71394f4e85fa.svc.cluster.local:8080
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:31.609922859Z 2025-03-21 23:03:31,609 INFO namenode.NameCache: initialized with 0 entries 0 lookups
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:31.610097901Z 2025-03-21 23:03:31,609 INFO namenode.FSNamesystem: Finished loading FSImage in 566 msecs
[pod/worker-1/datanode] 2025-03-21T23:03:31.628842478Z 2025-03-21 23:03:31,628 INFO ipc.Client: Retrying connect to server: hdfs-namenode:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[pod/worker-1/datanode] 2025-03-21T23:03:31.631109200Z 2025-03-21 23:03:31,630 WARN ipc.Client: Address change detected. Old: hdfs-namenode:8020 New: hdfs-namenode/192.168.139.246:8020
[pod/spark-master-0/spark-master] 2025-03-21T23:03:31.814633956Z 25/03/21 23:03:31 INFO Master: I have been elected leader! New state: ALIVE
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:31.864801925Z 2025-03-21 23:03:31,864 INFO namenode.NameNode: RPC server is binding to hdfs-namenode:8020
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:31.864869853Z 2025-03-21 23:03:31,864 INFO namenode.NameNode: Enable NameNode state context:false
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:31.874636784Z 2025-03-21 23:03:31,874 INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:31.885063783Z 2025-03-21 23:03:31,884 INFO ipc.Server: Listener at hdfs-namenode:8020
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:31.886424578Z 2025-03-21 23:03:31,886 INFO ipc.Server: Starting Socket Reader #1 for port 8020
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:32.020567933Z 2025-03-21 23:03:32,020 INFO namenode.FSNamesystem: Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:32.041851681Z 2025-03-21 23:03:32,041 INFO namenode.LeaseManager: Number of blocks under construction: 0
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:32.053990647Z 2025-03-21 23:03:32,053 INFO blockmanagement.DatanodeAdminDefaultMonitor: Initialized the Default Decommission and Maintenance monitor
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:32.055565799Z 2025-03-21 23:03:32,055 INFO blockmanagement.BlockManager: Start MarkedDeleteBlockScrubber thread
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:32.057827182Z 2025-03-21 23:03:32,057 INFO blockmanagement.BlockManager: initializing replication queues
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:32.058189405Z 2025-03-21 23:03:32,058 INFO hdfs.StateChange: STATE* Leaving safe mode after 0 secs
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:32.058317007Z 2025-03-21 23:03:32,058 INFO hdfs.StateChange: STATE* Network topology has 0 racks and 0 datanodes
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:32.058380725Z 2025-03-21 23:03:32,058 INFO hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:32.071380901Z 2025-03-21 23:03:32,071 INFO blockmanagement.BlockManager: Total number of blocks            = 0
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:32.071426288Z 2025-03-21 23:03:32,071 INFO blockmanagement.BlockManager: Number of invalid blocks          = 0
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:32.071463184Z 2025-03-21 23:03:32,071 INFO blockmanagement.BlockManager: Number of under-replicated blocks = 0
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:32.071474525Z 2025-03-21 23:03:32,071 INFO blockmanagement.BlockManager: Number of  over-replicated blocks = 0
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:32.071505313Z 2025-03-21 23:03:32,071 INFO blockmanagement.BlockManager: Number of blocks being written    = 0
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:32.071784306Z 2025-03-21 23:03:32,071 INFO hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 13 msec
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:32.111288392Z 2025-03-21 23:03:32,111 INFO ipc.Server: IPC Server Responder: starting
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:32.111850696Z 2025-03-21 23:03:32,111 INFO ipc.Server: IPC Server listener on 8020: starting
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:32.115184355Z 2025-03-21 23:03:32,114 INFO namenode.NameNode: NameNode RPC up at: hdfs-namenode/192.168.139.246:8020
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:32.118318065Z 2025-03-21 23:03:32,118 INFO namenode.FSNamesystem: Starting services required for active state
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:32.118367551Z 2025-03-21 23:03:32,118 INFO namenode.FSDirectory: Initializing quota with 12 thread(s)
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:32.124372822Z 2025-03-21 23:03:32,124 INFO namenode.FSDirectory: Quota initialization completed in 5 milliseconds
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:32.124423518Z name space=1
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:32.124436780Z storage space=0
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:32.124445214Z storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:32.131533853Z 2025-03-21 23:03:32,131 INFO blockmanagement.CacheReplicationMonitor: Starting CacheReplicationMonitor with interval 30000 milliseconds
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:32.402126248Z Mar 21, 2025 11:03:32 PM com.sun.jersey.api.core.ScanningResourceConfig logClasses
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:32.402192345Z INFO: Root resource classes found:
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:32.402206496Z   class org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:32.403032470Z Mar 21, 2025 11:03:32 PM com.sun.jersey.api.core.ScanningResourceConfig logClasses
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:32.403081837Z INFO: Provider classes found:
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:32.403101077Z   class org.apache.hadoop.hdfs.web.resources.UserProvider
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:32.403116320Z   class org.apache.hadoop.hdfs.web.resources.ExceptionHandler
[pod/worker-0/datanode] 2025-03-21T23:03:32.489307756Z 2025-03-21 23:03:32,488 INFO ipc.Client: Retrying connect to server: hdfs-namenode/192.168.139.246:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:32.559683643Z Mar 21, 2025 11:03:32 PM com.sun.jersey.server.impl.application.WebApplicationImpl _initiate
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:32.559769785Z INFO: Initiating Jersey application, version 'Jersey: 1.19.4 05/24/2017 03:20 PM'
[pod/worker-1/datanode] 2025-03-21T23:03:32.631686147Z 2025-03-21 23:03:32,631 INFO ipc.Client: Retrying connect to server: hdfs-namenode/192.168.139.246:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[pod/worker-1/datanode] 2025-03-21T23:03:32.824870185Z 2025-03-21 23:03:32,824 INFO datanode.DataNode: Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to hdfs-namenode:8020
[pod/worker-0/datanode] 2025-03-21T23:03:32.828883267Z 2025-03-21 23:03:32,828 INFO datanode.DataNode: Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to hdfs-namenode:8020
[pod/worker-1/datanode] 2025-03-21T23:03:32.831418241Z 2025-03-21 23:03:32,831 INFO common.Storage: Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
[pod/worker-0/datanode] 2025-03-21T23:03:32.835418236Z 2025-03-21 23:03:32,835 INFO common.Storage: Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
[pod/worker-1/datanode] 2025-03-21T23:03:32.854502573Z 2025-03-21 23:03:32,854 INFO common.Storage: Lock on /var/local/hadoop/data/in_use.lock acquired by nodename 1@worker-1
[pod/worker-1/datanode] 2025-03-21T23:03:32.856915566Z 2025-03-21 23:03:32,856 INFO common.Storage: Storage directory with location [DISK]file:/var/local/hadoop/data is not formatted for namespace 1770004461. Formatting...
[pod/worker-1/datanode] 2025-03-21T23:03:32.858588543Z 2025-03-21 23:03:32,858 INFO common.Storage: Generated new storageID DS-8b00f068-a8a5-4069-b4f2-e0fa1801a8ba for directory /var/local/hadoop/data 
[pod/worker-0/datanode] 2025-03-21T23:03:32.895832008Z 2025-03-21 23:03:32,895 INFO common.Storage: Lock on /var/local/hadoop/data/in_use.lock acquired by nodename 1@worker-0
[pod/worker-0/datanode] 2025-03-21T23:03:32.898316458Z 2025-03-21 23:03:32,898 INFO common.Storage: Storage directory with location [DISK]file:/var/local/hadoop/data is not formatted for namespace 1770004461. Formatting...
[pod/worker-0/datanode] 2025-03-21T23:03:32.899999081Z 2025-03-21 23:03:32,899 INFO common.Storage: Generated new storageID DS-3ed5f14f-07a4-475b-bc10-b9afbfdde2f1 for directory /var/local/hadoop/data 
[pod/worker-1/datanode] 2025-03-21T23:03:32.945719510Z 2025-03-21 23:03:32,945 INFO common.Storage: Analyzing storage directories for bpid BP-1789806720-192.168.139.246-1742598207255
[pod/worker-1/datanode] 2025-03-21T23:03:32.946190534Z 2025-03-21 23:03:32,945 INFO common.Storage: Locking is disabled for /var/local/hadoop/data/current/BP-1789806720-192.168.139.246-1742598207255
[pod/worker-1/datanode] 2025-03-21T23:03:32.947545347Z 2025-03-21 23:03:32,947 INFO common.Storage: Block pool storage directory for location [DISK]file:/var/local/hadoop/data and block pool id BP-1789806720-192.168.139.246-1742598207255 is not formatted. Formatting ...
[pod/worker-1/datanode] 2025-03-21T23:03:32.947616113Z 2025-03-21 23:03:32,947 INFO common.Storage: Formatting block pool BP-1789806720-192.168.139.246-1742598207255 directory /var/local/hadoop/data/current/BP-1789806720-192.168.139.246-1742598207255/current
[pod/worker-1/datanode] 2025-03-21T23:03:32.951481149Z 2025-03-21 23:03:32,951 INFO datanode.DataNode: Setting up storage: nsid=1770004461;bpid=BP-1789806720-192.168.139.246-1742598207255;lv=-57;nsInfo=lv=-66;cid=CID-d9b6df04-7661-475c-aa98-a572511d8eb0;nsid=1770004461;c=1742598207255;bpid=BP-1789806720-192.168.139.246-1742598207255;dnuuid=null
[pod/worker-1/datanode] 2025-03-21T23:03:32.953112314Z 2025-03-21 23:03:32,952 INFO datanode.DataNode: Generated and persisted new Datanode UUID 893341a4-96f9-462c-a469-c66baaf544c4
[pod/worker-1/datanode] 2025-03-21T23:03:32.982999801Z 2025-03-21 23:03:32,982 INFO impl.FsDatasetImpl: The datanode lock is a read write lock
[pod/worker-0/datanode] 2025-03-21T23:03:33.006918379Z 2025-03-21 23:03:33,006 INFO common.Storage: Analyzing storage directories for bpid BP-1789806720-192.168.139.246-1742598207255
[pod/worker-0/datanode] 2025-03-21T23:03:33.007226169Z 2025-03-21 23:03:33,007 INFO common.Storage: Locking is disabled for /var/local/hadoop/data/current/BP-1789806720-192.168.139.246-1742598207255
[pod/worker-0/datanode] 2025-03-21T23:03:33.008407600Z 2025-03-21 23:03:33,008 INFO common.Storage: Block pool storage directory for location [DISK]file:/var/local/hadoop/data and block pool id BP-1789806720-192.168.139.246-1742598207255 is not formatted. Formatting ...
[pod/worker-0/datanode] 2025-03-21T23:03:33.008546844Z 2025-03-21 23:03:33,008 INFO common.Storage: Formatting block pool BP-1789806720-192.168.139.246-1742598207255 directory /var/local/hadoop/data/current/BP-1789806720-192.168.139.246-1742598207255/current
[pod/worker-0/datanode] 2025-03-21T23:03:33.054961664Z 2025-03-21 23:03:33,054 INFO datanode.DataNode: Setting up storage: nsid=1770004461;bpid=BP-1789806720-192.168.139.246-1742598207255;lv=-57;nsInfo=lv=-66;cid=CID-d9b6df04-7661-475c-aa98-a572511d8eb0;nsid=1770004461;c=1742598207255;bpid=BP-1789806720-192.168.139.246-1742598207255;dnuuid=null
[pod/worker-0/datanode] 2025-03-21T23:03:33.071191641Z 2025-03-21 23:03:33,070 INFO datanode.DataNode: Generated and persisted new Datanode UUID 4c73769c-fe12-440f-bd45-0ff9788f8e79
[pod/worker-0/datanode] 2025-03-21T23:03:33.103075871Z 2025-03-21 23:03:33,102 INFO impl.FsDatasetImpl: The datanode lock is a read write lock
[pod/worker-1/datanode] 2025-03-21T23:03:33.191814396Z 2025-03-21 23:03:33,191 INFO impl.FsDatasetImpl: Added new volume: DS-8b00f068-a8a5-4069-b4f2-e0fa1801a8ba
[pod/worker-1/datanode] 2025-03-21T23:03:33.192368001Z 2025-03-21 23:03:33,191 INFO impl.FsDatasetImpl: Added volume - [DISK]file:/var/local/hadoop/data, StorageType: DISK
[pod/worker-1/datanode] 2025-03-21T23:03:33.201982293Z 2025-03-21 23:03:33,201 INFO impl.MemoryMappableBlockLoader: Initializing cache loader: MemoryMappableBlockLoader.
[pod/worker-1/datanode] 2025-03-21T23:03:33.210088413Z 2025-03-21 23:03:33,209 INFO impl.FsDatasetImpl: Registered FSDatasetState MBean
[pod/worker-1/datanode] 2025-03-21T23:03:33.223467328Z 2025-03-21 23:03:33,223 INFO impl.FsDatasetImpl: Adding block pool BP-1789806720-192.168.139.246-1742598207255
[pod/worker-1/datanode] 2025-03-21T23:03:33.225284825Z 2025-03-21 23:03:33,224 INFO impl.FsDatasetImpl: Scanning block pool BP-1789806720-192.168.139.246-1742598207255 on volume /var/local/hadoop/data...
[pod/worker-1/datanode] 2025-03-21T23:03:33.244334422Z 2025-03-21 23:03:33,244 WARN impl.FsDatasetImpl: dfsUsed file missing in /var/local/hadoop/data/current/BP-1789806720-192.168.139.246-1742598207255/current, will proceed with Du for space computation calculation, 
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:33.257340002Z WARNING: An illegal reflective access operation has occurred
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:33.257401388Z WARNING: Illegal reflective access by com.sun.xml.bind.v2.runtime.reflect.opt.Injector$1 (file:/opt/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar) to method java.lang.ClassLoader.defineClass(java.lang.String,byte[],int,int)
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:33.257414590Z WARNING: Please consider reporting this to the maintainers of com.sun.xml.bind.v2.runtime.reflect.opt.Injector$1
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:33.257423532Z WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:33.257432069Z WARNING: All illegal access operations will be denied in a future release
[pod/worker-1/datanode] 2025-03-21T23:03:33.308850413Z 2025-03-21 23:03:33,308 INFO impl.FsDatasetImpl: Time taken to scan block pool BP-1789806720-192.168.139.246-1742598207255 on /var/local/hadoop/data: 83ms
[pod/worker-1/datanode] 2025-03-21T23:03:33.309408064Z 2025-03-21 23:03:33,309 INFO impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-1789806720-192.168.139.246-1742598207255: 86ms
[pod/worker-1/datanode] 2025-03-21T23:03:33.322916995Z 2025-03-21 23:03:33,322 INFO impl.FsDatasetImpl: Adding replicas to map for block pool BP-1789806720-192.168.139.246-1742598207255 on volume /var/local/hadoop/data...
[pod/worker-1/datanode] 2025-03-21T23:03:33.325640987Z 2025-03-21 23:03:33,325 INFO impl.BlockPoolSlice: Replica Cache file: /var/local/hadoop/data/current/BP-1789806720-192.168.139.246-1742598207255/current/replicas doesn't exist 
[pod/worker-1/datanode] 2025-03-21T23:03:33.330571702Z 2025-03-21 23:03:33,330 INFO impl.FsDatasetImpl: Time to add replicas to map for block pool BP-1789806720-192.168.139.246-1742598207255 on volume /var/local/hadoop/data: 8ms
[pod/worker-1/datanode] 2025-03-21T23:03:33.330866935Z 2025-03-21 23:03:33,330 INFO impl.FsDatasetImpl: Total time to add all replicas to map for block pool BP-1789806720-192.168.139.246-1742598207255: 20ms
[pod/worker-1/datanode] 2025-03-21T23:03:33.332391735Z 2025-03-21 23:03:33,331 INFO checker.ThrottledAsyncChecker: Scheduling a check for /var/local/hadoop/data
[pod/worker-0/datanode] 2025-03-21T23:03:33.332314841Z 2025-03-21 23:03:33,331 INFO impl.FsDatasetImpl: Added new volume: DS-3ed5f14f-07a4-475b-bc10-b9afbfdde2f1
[pod/worker-0/datanode] 2025-03-21T23:03:33.332737028Z 2025-03-21 23:03:33,332 INFO impl.FsDatasetImpl: Added volume - [DISK]file:/var/local/hadoop/data, StorageType: DISK
[pod/worker-0/datanode] 2025-03-21T23:03:33.343587761Z 2025-03-21 23:03:33,343 INFO impl.MemoryMappableBlockLoader: Initializing cache loader: MemoryMappableBlockLoader.
[pod/worker-0/datanode] 2025-03-21T23:03:33.352410629Z 2025-03-21 23:03:33,352 INFO impl.FsDatasetImpl: Registered FSDatasetState MBean
[pod/worker-1/datanode] 2025-03-21T23:03:33.357934945Z 2025-03-21 23:03:33,357 INFO checker.DatasetVolumeChecker: Scheduled health check for volume /var/local/hadoop/data
[pod/worker-1/datanode] 2025-03-21T23:03:33.365840879Z 2025-03-21 23:03:33,365 INFO datanode.VolumeScanner: Now scanning bpid BP-1789806720-192.168.139.246-1742598207255 on volume /var/local/hadoop/data
[pod/worker-0/datanode] 2025-03-21T23:03:33.367335255Z 2025-03-21 23:03:33,367 INFO impl.FsDatasetImpl: Adding block pool BP-1789806720-192.168.139.246-1742598207255
[pod/worker-1/datanode] 2025-03-21T23:03:33.368525499Z 2025-03-21 23:03:33,368 INFO datanode.VolumeScanner: VolumeScanner(/var/local/hadoop/data, DS-8b00f068-a8a5-4069-b4f2-e0fa1801a8ba): finished scanning block pool BP-1789806720-192.168.139.246-1742598207255
[pod/worker-0/datanode] 2025-03-21T23:03:33.369064799Z 2025-03-21 23:03:33,368 INFO impl.FsDatasetImpl: Scanning block pool BP-1789806720-192.168.139.246-1742598207255 on volume /var/local/hadoop/data...
[pod/worker-1/datanode] 2025-03-21T23:03:33.373551171Z 2025-03-21 23:03:33,373 WARN datanode.DirectoryScanner: dfs.datanode.directoryscan.throttle.limit.ms.per.sec set to value above 1000 ms/sec. Assuming default value of -1
[pod/worker-1/datanode] 2025-03-21T23:03:33.374432137Z 2025-03-21 23:03:33,374 INFO datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting in 589661ms with interval of 21600000ms and throttle limit of -1ms/s
[pod/worker-1/datanode] 2025-03-21T23:03:33.387912548Z 2025-03-21 23:03:33,387 INFO datanode.DataNode: Block pool BP-1789806720-192.168.139.246-1742598207255 (Datanode Uuid 893341a4-96f9-462c-a469-c66baaf544c4) service to hdfs-namenode:8020 beginning handshake with NN
[pod/worker-0/datanode] 2025-03-21T23:03:33.389902364Z 2025-03-21 23:03:33,389 WARN impl.FsDatasetImpl: dfsUsed file missing in /var/local/hadoop/data/current/BP-1789806720-192.168.139.246-1742598207255/current, will proceed with Du for space computation calculation, 
[pod/worker-1/datanode] 2025-03-21T23:03:33.393719949Z 2025-03-21 23:03:33,393 INFO datanode.VolumeScanner: VolumeScanner(/var/local/hadoop/data, DS-8b00f068-a8a5-4069-b4f2-e0fa1801a8ba): no suitable block pools found to scan.  Waiting 1814399972 ms.
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:33.422444980Z Mar 21, 2025 11:03:33 PM com.sun.jersey.spi.inject.Errors processErrorMessages
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:33.422549881Z WARNING: The following warnings have been detected with resource and/or provider classes:
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:33.422581615Z   WARNING: A sub-resource method, public javax.ws.rs.core.Response org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.getRoot(org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.hdfs.web.resources.DelegationParam,org.apache.hadoop.hdfs.web.resources.UserParam,org.apache.hadoop.hdfs.web.resources.DoAsParam,org.apache.hadoop.hdfs.web.resources.GetOpParam,org.apache.hadoop.hdfs.web.resources.OffsetParam,org.apache.hadoop.hdfs.web.resources.LengthParam,org.apache.hadoop.hdfs.web.resources.RenewerParam,org.apache.hadoop.hdfs.web.resources.BufferSizeParam,java.util.List,org.apache.hadoop.hdfs.web.resources.XAttrEncodingParam,org.apache.hadoop.hdfs.web.resources.ExcludeDatanodesParam,org.apache.hadoop.hdfs.web.resources.FsActionParam,org.apache.hadoop.hdfs.web.resources.SnapshotNameParam,org.apache.hadoop.hdfs.web.resources.OldSnapshotNameParam,org.apache.hadoop.hdfs.web.resources.TokenKindParam,org.apache.hadoop.hdfs.web.resources.TokenServiceParam,org.apache.hadoop.hdfs.web.resources.NoRedirectParam,org.apache.hadoop.hdfs.web.resources.StartAfterParam) throws java.io.IOException,java.lang.InterruptedException, with URI template, "/", is treated as a resource method
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:33.422609820Z   WARNING: A sub-resource method, public javax.ws.rs.core.Response org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.putRoot(org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.hdfs.web.resources.DelegationParam,org.apache.hadoop.hdfs.web.resources.UserParam,org.apache.hadoop.hdfs.web.resources.DoAsParam,org.apache.hadoop.hdfs.web.resources.PutOpParam,org.apache.hadoop.hdfs.web.resources.DestinationParam,org.apache.hadoop.hdfs.web.resources.OwnerParam,org.apache.hadoop.hdfs.web.resources.GroupParam,org.apache.hadoop.hdfs.web.resources.PermissionParam,org.apache.hadoop.hdfs.web.resources.UnmaskedPermissionParam,org.apache.hadoop.hdfs.web.resources.OverwriteParam,org.apache.hadoop.hdfs.web.resources.BufferSizeParam,org.apache.hadoop.hdfs.web.resources.ReplicationParam,org.apache.hadoop.hdfs.web.resources.BlockSizeParam,org.apache.hadoop.hdfs.web.resources.ModificationTimeParam,org.apache.hadoop.hdfs.web.resources.AccessTimeParam,org.apache.hadoop.hdfs.web.resources.RenameOptionSetParam,org.apache.hadoop.hdfs.web.resources.CreateParentParam,org.apache.hadoop.hdfs.web.resources.TokenArgumentParam,org.apache.hadoop.hdfs.web.resources.AclPermissionParam,org.apache.hadoop.hdfs.web.resources.XAttrNameParam,org.apache.hadoop.hdfs.web.resources.XAttrValueParam,org.apache.hadoop.hdfs.web.resources.XAttrSetFlagParam,org.apache.hadoop.hdfs.web.resources.SnapshotNameParam,org.apache.hadoop.hdfs.web.resources.OldSnapshotNameParam,org.apache.hadoop.hdfs.web.resources.ExcludeDatanodesParam,org.apache.hadoop.hdfs.web.resources.CreateFlagParam,org.apache.hadoop.hdfs.web.resources.NoRedirectParam,org.apache.hadoop.hdfs.web.resources.StoragePolicyParam,org.apache.hadoop.hdfs.web.resources.ECPolicyParam,org.apache.hadoop.hdfs.web.resources.NameSpaceQuotaParam,org.apache.hadoop.hdfs.web.resources.StorageSpaceQuotaParam,org.apache.hadoop.hdfs.web.resources.StorageTypeParam) throws java.io.IOException,java.lang.InterruptedException, with URI template, "/", is treated as a resource method
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:33.422655046Z   WARNING: A sub-resource method, public javax.ws.rs.core.Response org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.postRoot(org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.hdfs.web.resources.DelegationParam,org.apache.hadoop.hdfs.web.resources.UserParam,org.apache.hadoop.hdfs.web.resources.DoAsParam,org.apache.hadoop.hdfs.web.resources.PostOpParam,org.apache.hadoop.hdfs.web.resources.ConcatSourcesParam,org.apache.hadoop.hdfs.web.resources.BufferSizeParam,org.apache.hadoop.hdfs.web.resources.ExcludeDatanodesParam,org.apache.hadoop.hdfs.web.resources.NewLengthParam,org.apache.hadoop.hdfs.web.resources.NoRedirectParam) throws java.io.IOException,java.lang.InterruptedException, with URI template, "/", is treated as a resource method
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:33.422687903Z   WARNING: A sub-resource method, public javax.ws.rs.core.Response org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.deleteRoot(org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.hdfs.web.resources.DelegationParam,org.apache.hadoop.hdfs.web.resources.UserParam,org.apache.hadoop.hdfs.web.resources.DoAsParam,org.apache.hadoop.hdfs.web.resources.DeleteOpParam,org.apache.hadoop.hdfs.web.resources.RecursiveParam,org.apache.hadoop.hdfs.web.resources.SnapshotNameParam) throws java.io.IOException,java.lang.InterruptedException, with URI template, "/", is treated as a resource method
[pod/worker-0/datanode] 2025-03-21T23:03:33.450997162Z 2025-03-21 23:03:33,450 INFO impl.FsDatasetImpl: Time taken to scan block pool BP-1789806720-192.168.139.246-1742598207255 on /var/local/hadoop/data: 82ms
[pod/worker-0/datanode] 2025-03-21T23:03:33.451492728Z 2025-03-21 23:03:33,451 INFO impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-1789806720-192.168.139.246-1742598207255: 84ms
[pod/worker-0/datanode] 2025-03-21T23:03:33.453656770Z 2025-03-21 23:03:33,453 INFO impl.FsDatasetImpl: Adding replicas to map for block pool BP-1789806720-192.168.139.246-1742598207255 on volume /var/local/hadoop/data...
[pod/worker-0/datanode] 2025-03-21T23:03:33.454106157Z 2025-03-21 23:03:33,453 INFO impl.BlockPoolSlice: Replica Cache file: /var/local/hadoop/data/current/BP-1789806720-192.168.139.246-1742598207255/current/replicas doesn't exist 
[pod/worker-0/datanode] 2025-03-21T23:03:33.458474004Z 2025-03-21 23:03:33,458 INFO impl.FsDatasetImpl: Time to add replicas to map for block pool BP-1789806720-192.168.139.246-1742598207255 on volume /var/local/hadoop/data: 4ms
[pod/worker-0/datanode] 2025-03-21T23:03:33.458636899Z 2025-03-21 23:03:33,458 INFO impl.FsDatasetImpl: Total time to add all replicas to map for block pool BP-1789806720-192.168.139.246-1742598207255: 6ms
[pod/worker-0/datanode] 2025-03-21T23:03:33.459617539Z 2025-03-21 23:03:33,459 INFO checker.ThrottledAsyncChecker: Scheduling a check for /var/local/hadoop/data
[pod/worker-0/datanode] 2025-03-21T23:03:33.480340586Z 2025-03-21 23:03:33,480 INFO checker.DatasetVolumeChecker: Scheduled health check for volume /var/local/hadoop/data
[pod/worker-0/datanode] 2025-03-21T23:03:33.487356943Z 2025-03-21 23:03:33,487 INFO datanode.VolumeScanner: Now scanning bpid BP-1789806720-192.168.139.246-1742598207255 on volume /var/local/hadoop/data
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:33.499739359Z 2025-03-21 23:03:33,499 INFO hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(192.168.172.208:9866, datanodeUuid=893341a4-96f9-462c-a469-c66baaf544c4, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-d9b6df04-7661-475c-aa98-a572511d8eb0;nsid=1770004461;c=1742598207255) storage 893341a4-96f9-462c-a469-c66baaf544c4
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:33.502036974Z 2025-03-21 23:03:33,501 INFO net.NetworkTopology: Adding a new node: /default-rack/192.168.172.208:9866
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:33.502279208Z 2025-03-21 23:03:33,502 INFO blockmanagement.BlockReportLeaseManager: Registered DN 893341a4-96f9-462c-a469-c66baaf544c4 (192.168.172.208:9866).
[pod/worker-0/datanode] 2025-03-21T23:03:33.506970668Z 2025-03-21 23:03:33,506 INFO datanode.VolumeScanner: VolumeScanner(/var/local/hadoop/data, DS-3ed5f14f-07a4-475b-bc10-b9afbfdde2f1): finished scanning block pool BP-1789806720-192.168.139.246-1742598207255
[pod/worker-0/datanode] 2025-03-21T23:03:33.512182199Z 2025-03-21 23:03:33,511 WARN datanode.DirectoryScanner: dfs.datanode.directoryscan.throttle.limit.ms.per.sec set to value above 1000 ms/sec. Assuming default value of -1
[pod/worker-0/datanode] 2025-03-21T23:03:33.512953030Z 2025-03-21 23:03:33,512 INFO datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting in 9506578ms with interval of 21600000ms and throttle limit of -1ms/s
[pod/worker-1/datanode] 2025-03-21T23:03:33.526475669Z 2025-03-21 23:03:33,526 INFO datanode.DataNode: Block pool BP-1789806720-192.168.139.246-1742598207255 (Datanode Uuid 893341a4-96f9-462c-a469-c66baaf544c4) service to hdfs-namenode:8020 successfully registered with NN
[pod/worker-1/datanode] 2025-03-21T23:03:33.528931293Z 2025-03-21 23:03:33,528 INFO datanode.DataNode: For namenode hdfs-namenode:8020 using BLOCKREPORT_INTERVAL of 21600000msecs CACHEREPORT_INTERVAL of 10000msecs Initial delay: 0msecs; heartBeatInterval=3000
[pod/worker-1/datanode] 2025-03-21T23:03:33.529001667Z 2025-03-21 23:03:33,528 INFO datanode.DataNode: Starting IBR Task Handler.
[pod/worker-0/datanode] 2025-03-21T23:03:33.528577601Z 2025-03-21 23:03:33,528 INFO datanode.DataNode: Block pool BP-1789806720-192.168.139.246-1742598207255 (Datanode Uuid 4c73769c-fe12-440f-bd45-0ff9788f8e79) service to hdfs-namenode:8020 beginning handshake with NN
[pod/worker-0/datanode] 2025-03-21T23:03:33.532890096Z 2025-03-21 23:03:33,532 INFO datanode.VolumeScanner: VolumeScanner(/var/local/hadoop/data, DS-3ed5f14f-07a4-475b-bc10-b9afbfdde2f1): no suitable block pools found to scan.  Waiting 1814399954 ms.
2025-03-21T23:03:33: Could not find META-INF/MANIFEST.MF in app archive
2025-03-21T23:03:33: Could not find Main.class in app archive
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:33.605024974Z 2025-03-21 23:03:33,604 INFO hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(192.168.84.177:9866, datanodeUuid=4c73769c-fe12-440f-bd45-0ff9788f8e79, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-d9b6df04-7661-475c-aa98-a572511d8eb0;nsid=1770004461;c=1742598207255) storage 4c73769c-fe12-440f-bd45-0ff9788f8e79
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:33.605477468Z 2025-03-21 23:03:33,605 INFO net.NetworkTopology: Adding a new node: /default-rack/192.168.84.177:9866
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:33.605840863Z 2025-03-21 23:03:33,605 INFO blockmanagement.BlockReportLeaseManager: Registered DN 4c73769c-fe12-440f-bd45-0ff9788f8e79 (192.168.84.177:9866).
2025-03-21T23:03:33: Extracting and uploading main.py ...
2025-03-21T23:03:33: Could not find main.py in app archive
[pod/worker-0/datanode] 2025-03-21T23:03:33.612199270Z 2025-03-21 23:03:33,611 INFO datanode.DataNode: Block pool BP-1789806720-192.168.139.246-1742598207255 (Datanode Uuid 4c73769c-fe12-440f-bd45-0ff9788f8e79) service to hdfs-namenode:8020 successfully registered with NN
[pod/worker-0/datanode] 2025-03-21T23:03:33.614564357Z 2025-03-21 23:03:33,614 INFO datanode.DataNode: For namenode hdfs-namenode:8020 using BLOCKREPORT_INTERVAL of 21600000msecs CACHEREPORT_INTERVAL of 10000msecs Initial delay: 0msecs; heartBeatInterval=3000
[pod/worker-0/datanode] 2025-03-21T23:03:33.614659056Z 2025-03-21 23:03:33,614 INFO datanode.DataNode: Starting IBR Task Handler.
2025-03-21T23:03:33: Uploading app app.zip ...
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:33.647779559Z 2025-03-21 23:03:33,647 INFO blockmanagement.DatanodeDescriptor: Adding new storage ID DS-8b00f068-a8a5-4069-b4f2-e0fa1801a8ba for DN 192.168.172.208:9866
[pod/worker-1/datanode] 2025-03-21T23:03:33.682079565Z 2025-03-21 23:03:33,681 INFO datanode.DataNode: After receiving heartbeat response, updating state of namenode hdfs-namenode:8020 to active
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:33.699828579Z 2025-03-21 23:03:33,699 INFO blockmanagement.DatanodeDescriptor: Adding new storage ID DS-3ed5f14f-07a4-475b-bc10-b9afbfdde2f1 for DN 192.168.84.177:9866
[pod/worker-0/datanode] 2025-03-21T23:03:33.719088222Z 2025-03-21 23:03:33,718 INFO datanode.DataNode: After receiving heartbeat response, updating state of namenode hdfs-namenode:8020 to active
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:33.734389160Z 2025-03-21 23:03:33,734 INFO BlockStateChange: BLOCK* processReport 0x254c79e0ec19572b with lease ID 0x5349378d71d5ee3: Processing first storage report for DS-8b00f068-a8a5-4069-b4f2-e0fa1801a8ba from datanode DatanodeRegistration(192.168.172.208:9866, datanodeUuid=893341a4-96f9-462c-a469-c66baaf544c4, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-d9b6df04-7661-475c-aa98-a572511d8eb0;nsid=1770004461;c=1742598207255)
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:33.737109103Z 2025-03-21 23:03:33,736 INFO BlockStateChange: BLOCK* processReport 0x254c79e0ec19572b with lease ID 0x5349378d71d5ee3: from storage DS-8b00f068-a8a5-4069-b4f2-e0fa1801a8ba node DatanodeRegistration(192.168.172.208:9866, datanodeUuid=893341a4-96f9-462c-a469-c66baaf544c4, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-d9b6df04-7661-475c-aa98-a572511d8eb0;nsid=1770004461;c=1742598207255), blocks: 0, hasStaleStorage: false, processing time: 3 msecs, invalidatedBlocks: 0
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:33.767417246Z 2025-03-21 23:03:33,767 INFO BlockStateChange: BLOCK* processReport 0x45db825e6db2188 with lease ID 0x5349378d71d5ee4: Processing first storage report for DS-3ed5f14f-07a4-475b-bc10-b9afbfdde2f1 from datanode DatanodeRegistration(192.168.84.177:9866, datanodeUuid=4c73769c-fe12-440f-bd45-0ff9788f8e79, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-d9b6df04-7661-475c-aa98-a572511d8eb0;nsid=1770004461;c=1742598207255)
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:33.767554138Z 2025-03-21 23:03:33,767 INFO BlockStateChange: BLOCK* processReport 0x45db825e6db2188 with lease ID 0x5349378d71d5ee4: from storage DS-3ed5f14f-07a4-475b-bc10-b9afbfdde2f1 node DatanodeRegistration(192.168.84.177:9866, datanodeUuid=4c73769c-fe12-440f-bd45-0ff9788f8e79, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-d9b6df04-7661-475c-aa98-a572511d8eb0;nsid=1770004461;c=1742598207255), blocks: 0, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
[pod/worker-1/datanode] 2025-03-21T23:03:33.785632240Z 2025-03-21 23:03:33,785 INFO datanode.DataNode: Successfully sent block report 0x254c79e0ec19572b with lease ID 0x5349378d71d5ee3 to namenode: hdfs-namenode:8020,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 10 msecs to generate and 90 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
[pod/worker-1/datanode] 2025-03-21T23:03:33.787560346Z 2025-03-21 23:03:33,787 INFO datanode.DataNode: Got finalize command for block pool BP-1789806720-192.168.139.246-1742598207255
[pod/worker-0/datanode] 2025-03-21T23:03:33.790329603Z 2025-03-21 23:03:33,789 INFO datanode.DataNode: Successfully sent block report 0x45db825e6db2188 with lease ID 0x5349378d71d5ee4 to namenode: hdfs-namenode:8020,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 11 msecs to generate and 56 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
[pod/worker-0/datanode] 2025-03-21T23:03:33.792030935Z 2025-03-21 23:03:33,791 INFO datanode.DataNode: Got finalize command for block pool BP-1789806720-192.168.139.246-1742598207255
[pod/worker-1/datanode] 2025-03-21T23:03:35.056668206Z 2025-03-21 23:03:35,056 INFO datanode.webhdfs: 192.168.139.229 PUT /webhdfs/v1/app.zip?op=CREATE&user.name=hadoop&namenoderpcaddress=hdfs-namenode:8020&createflag=&createparent=true&overwrite=false&user.name=hadoop 201
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:35.118393685Z 2025-03-21 23:03:35,117 INFO blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:35.125153203Z 2025-03-21 23:03:35,124 INFO hdfs.StateChange: BLOCK* allocate blk_1073741825_1001, replicas=192.168.172.208:9866, 192.168.84.177:9866 for /app.zip
[pod/worker-1/spark-worker] 2025-03-21T23:03:35.250963707Z 25/03/21 23:03:35 INFO Worker: Retrying connection to master (attempt # 4)
[pod/worker-1/spark-worker] 2025-03-21T23:03:35.251715486Z 25/03/21 23:03:35 INFO Worker: Connecting to master spark-master.submission-b88ebfea875443329ffa71394f4e85fa.svc.cluster.local:7077...
[pod/worker-1/spark-worker] 2025-03-21T23:03:35.281490745Z 25/03/21 23:03:35 INFO TransportClientFactory: Successfully created connection to spark-master.submission-b88ebfea875443329ffa71394f4e85fa.svc.cluster.local/192.168.139.224:7077 after 12 ms (0 ms spent in bootstraps)
[pod/worker-1/datanode] 2025-03-21T23:03:35.393114859Z 2025-03-21 23:03:35,392 INFO datanode.DataNode: Receiving BP-1789806720-192.168.139.246-1742598207255:blk_1073741825_1001 src: /192.168.172.208:55910 dest: /192.168.172.208:9866
[pod/worker-0/datanode] 2025-03-21T23:03:35.587163686Z 2025-03-21 23:03:35,586 INFO datanode.DataNode: Receiving BP-1789806720-192.168.139.246-1742598207255:blk_1073741825_1001 src: /192.168.172.208:37902 dest: /192.168.84.177:9866
[pod/spark-master-0/spark-master] 2025-03-21T23:03:35.613076484Z 25/03/21 23:03:35 INFO Master: Registering worker worker-1.worker.submission-b88ebfea875443329ffa71394f4e85fa.svc.cluster.local:7078 with 40 cores, 300.0 GiB RAM
[pod/worker-1/spark-worker] 2025-03-21T23:03:35.658357361Z 25/03/21 23:03:35 INFO Worker: Successfully registered with master spark://spark-master-0.spark-master.submission-b88ebfea875443329ffa71394f4e85fa.svc.cluster.local:7077
[pod/worker-0/spark-worker] 2025-03-21T23:03:36.919619587Z 25/03/21 23:03:36 INFO Worker: Retrying connection to master (attempt # 4)
[pod/worker-0/spark-worker] 2025-03-21T23:03:36.920219553Z 25/03/21 23:03:36 INFO Worker: Connecting to master spark-master.submission-b88ebfea875443329ffa71394f4e85fa.svc.cluster.local:7077...
[pod/worker-0/spark-worker] 2025-03-21T23:03:36.950950491Z 25/03/21 23:03:36 INFO TransportClientFactory: Successfully created connection to spark-master.submission-b88ebfea875443329ffa71394f4e85fa.svc.cluster.local/192.168.139.224:7077 after 12 ms (0 ms spent in bootstraps)
[pod/spark-master-0/spark-master] 2025-03-21T23:03:37.126049255Z 25/03/21 23:03:37 INFO Master: Registering worker worker-0.worker.submission-b88ebfea875443329ffa71394f4e85fa.svc.cluster.local:7078 with 40 cores, 300.0 GiB RAM
[pod/worker-0/spark-worker] 2025-03-21T23:03:37.138647781Z 25/03/21 23:03:37 INFO Worker: Successfully registered with master spark://spark-master-0.spark-master.submission-b88ebfea875443329ffa71394f4e85fa.svc.cluster.local:7077
[pod/worker-0/datanode] 2025-03-21T23:03:37.805109325Z 2025-03-21 23:03:37,803 INFO DataNode.clienttrace: src: /192.168.172.208:37902, dest: /192.168.84.177:9866, bytes: 134217728, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-821086404_84, offset: 0, srvID: 4c73769c-fe12-440f-bd45-0ff9788f8e79, blockid: BP-1789806720-192.168.139.246-1742598207255:blk_1073741825_1001, duration(ns): 2149989844
[pod/worker-0/datanode] 2025-03-21T23:03:37.805377493Z 2025-03-21 23:03:37,805 INFO datanode.DataNode: PacketResponder: BP-1789806720-192.168.139.246-1742598207255:blk_1073741825_1001, type=LAST_IN_PIPELINE terminating
[pod/worker-1/datanode] 2025-03-21T23:03:37.832219551Z 2025-03-21 23:03:37,830 INFO DataNode.clienttrace: src: /192.168.172.208:55910, dest: /192.168.172.208:9866, bytes: 134217728, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-821086404_84, offset: 0, srvID: 893341a4-96f9-462c-a469-c66baaf544c4, blockid: BP-1789806720-192.168.139.246-1742598207255:blk_1073741825_1001, duration(ns): 2161643092
[pod/worker-1/datanode] 2025-03-21T23:03:37.832828439Z 2025-03-21 23:03:37,832 INFO datanode.DataNode: PacketResponder: BP-1789806720-192.168.139.246-1742598207255:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[192.168.84.177:9866] terminating
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:37.844285685Z 2025-03-21 23:03:37,843 INFO blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:37.847238219Z 2025-03-21 23:03:37,846 INFO hdfs.StateChange: BLOCK* allocate blk_1073741826_1002, replicas=192.168.172.208:9866, 192.168.84.177:9866 for /app.zip
[pod/worker-1/datanode] 2025-03-21T23:03:37.872838320Z 2025-03-21 23:03:37,872 INFO datanode.DataNode: Receiving BP-1789806720-192.168.139.246-1742598207255:blk_1073741826_1002 src: /192.168.172.208:53962 dest: /192.168.172.208:9866
[pod/worker-0/datanode] 2025-03-21T23:03:37.879740620Z 2025-03-21 23:03:37,879 INFO datanode.DataNode: Receiving BP-1789806720-192.168.139.246-1742598207255:blk_1073741826_1002 src: /192.168.172.208:54338 dest: /192.168.84.177:9866
[pod/worker-0/datanode] 2025-03-21T23:03:40.441895097Z 2025-03-21 23:03:40,440 INFO DataNode.clienttrace: src: /192.168.172.208:54338, dest: /192.168.84.177:9866, bytes: 134217728, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-821086404_84, offset: 0, srvID: 4c73769c-fe12-440f-bd45-0ff9788f8e79, blockid: BP-1789806720-192.168.139.246-1742598207255:blk_1073741826_1002, duration(ns): 2556208454
[pod/worker-0/datanode] 2025-03-21T23:03:40.442682408Z 2025-03-21 23:03:40,442 INFO datanode.DataNode: PacketResponder: BP-1789806720-192.168.139.246-1742598207255:blk_1073741826_1002, type=LAST_IN_PIPELINE terminating
[pod/worker-1/datanode] 2025-03-21T23:03:40.447953717Z 2025-03-21 23:03:40,446 INFO DataNode.clienttrace: src: /192.168.172.208:53962, dest: /192.168.172.208:9866, bytes: 134217728, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-821086404_84, offset: 0, srvID: 893341a4-96f9-462c-a469-c66baaf544c4, blockid: BP-1789806720-192.168.139.246-1742598207255:blk_1073741826_1002, duration(ns): 2560625291
[pod/worker-1/datanode] 2025-03-21T23:03:40.448196156Z 2025-03-21 23:03:40,447 INFO datanode.DataNode: PacketResponder: BP-1789806720-192.168.139.246-1742598207255:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[192.168.84.177:9866] terminating
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:40.451636786Z 2025-03-21 23:03:40,451 INFO blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:40.453009717Z 2025-03-21 23:03:40,452 INFO hdfs.StateChange: BLOCK* allocate blk_1073741827_1003, replicas=192.168.172.208:9866, 192.168.84.177:9866 for /app.zip
[pod/worker-1/datanode] 2025-03-21T23:03:40.470528753Z 2025-03-21 23:03:40,470 INFO datanode.DataNode: Receiving BP-1789806720-192.168.139.246-1742598207255:blk_1073741827_1003 src: /192.168.172.208:53964 dest: /192.168.172.208:9866
[pod/worker-0/datanode] 2025-03-21T23:03:40.475526210Z 2025-03-21 23:03:40,475 INFO datanode.DataNode: Receiving BP-1789806720-192.168.139.246-1742598207255:blk_1073741827_1003 src: /192.168.172.208:54348 dest: /192.168.84.177:9866
[pod/worker-0/datanode] 2025-03-21T23:03:42.235769855Z 2025-03-21 23:03:42,235 INFO DataNode.clienttrace: src: /192.168.172.208:54348, dest: /192.168.84.177:9866, bytes: 91558201, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-821086404_84, offset: 0, srvID: 4c73769c-fe12-440f-bd45-0ff9788f8e79, blockid: BP-1789806720-192.168.139.246-1742598207255:blk_1073741827_1003, duration(ns): 1755241753
[pod/worker-0/datanode] 2025-03-21T23:03:42.235918388Z 2025-03-21 23:03:42,235 INFO datanode.DataNode: PacketResponder: BP-1789806720-192.168.139.246-1742598207255:blk_1073741827_1003, type=LAST_IN_PIPELINE terminating
[pod/worker-1/datanode] 2025-03-21T23:03:42.240592599Z 2025-03-21 23:03:42,239 INFO DataNode.clienttrace: src: /192.168.172.208:53964, dest: /192.168.172.208:9866, bytes: 91558201, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-821086404_84, offset: 0, srvID: 893341a4-96f9-462c-a469-c66baaf544c4, blockid: BP-1789806720-192.168.139.246-1742598207255:blk_1073741827_1003, duration(ns): 1758865110
[pod/worker-1/datanode] 2025-03-21T23:03:42.241201334Z 2025-03-21 23:03:42,240 INFO datanode.DataNode: PacketResponder: BP-1789806720-192.168.139.246-1742598207255:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[192.168.84.177:9866] terminating
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:42.264570432Z 2025-03-21 23:03:42,264 INFO hdfs.StateChange: DIR* completeFile: /app.zip is closed by DFSClient_NONMAPREDUCE_-821086404_84
2025-03-21T23:03:42: App status: {'accessTime': 1742598214954, 'blockSize': 134217728, 'childrenNum': 0, 'fileId': 16387, 'group': 'supergroup', 'length': 359993657, 'modificationTime': 1742598222254, 'owner': 'hadoop', 'pathSuffix': '', 'permission': '644', 'replication': 3, 'storagePolicy': 0, 'type': 'FILE'}
2025-03-21T23:03:42: No data provided
2025-03-21T23:03:42: Uploading /diagnoses.csv
[pod/worker-1/datanode] 2025-03-21T23:03:42.427358098Z 2025-03-21 23:03:42,426 INFO datanode.webhdfs: 192.168.139.229 PUT /webhdfs/v1/diagnoses.csv?op=CREATE&user.name=hadoop&namenoderpcaddress=hdfs-namenode:8020&createflag=&createparent=true&overwrite=false&user.name=hadoop 201
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:42.440396118Z 2025-03-21 23:03:42,440 INFO blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:42.442107169Z 2025-03-21 23:03:42,441 INFO hdfs.StateChange: BLOCK* allocate blk_1073741828_1004, replicas=192.168.172.208:9866, 192.168.84.177:9866 for /diagnoses.csv
[pod/worker-1/datanode] 2025-03-21T23:03:42.456955608Z 2025-03-21 23:03:42,456 INFO datanode.DataNode: Receiving BP-1789806720-192.168.139.246-1742598207255:blk_1073741828_1004 src: /192.168.172.208:53976 dest: /192.168.172.208:9866
[pod/worker-0/datanode] 2025-03-21T23:03:42.461998840Z 2025-03-21 23:03:42,461 INFO datanode.DataNode: Receiving BP-1789806720-192.168.139.246-1742598207255:blk_1073741828_1004 src: /192.168.172.208:54362 dest: /192.168.84.177:9866
[pod/worker-0/datanode] 2025-03-21T23:03:45.040868624Z 2025-03-21 23:03:45,039 INFO DataNode.clienttrace: src: /192.168.172.208:54362, dest: /192.168.84.177:9866, bytes: 134217728, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-693970008_100, offset: 0, srvID: 4c73769c-fe12-440f-bd45-0ff9788f8e79, blockid: BP-1789806720-192.168.139.246-1742598207255:blk_1073741828_1004, duration(ns): 2571483607
[pod/worker-0/datanode] 2025-03-21T23:03:45.041007698Z 2025-03-21 23:03:45,040 INFO datanode.DataNode: PacketResponder: BP-1789806720-192.168.139.246-1742598207255:blk_1073741828_1004, type=LAST_IN_PIPELINE terminating
[pod/worker-1/datanode] 2025-03-21T23:03:45.045183935Z 2025-03-21 23:03:45,044 INFO DataNode.clienttrace: src: /192.168.172.208:53976, dest: /192.168.172.208:9866, bytes: 134217728, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-693970008_100, offset: 0, srvID: 893341a4-96f9-462c-a469-c66baaf544c4, blockid: BP-1789806720-192.168.139.246-1742598207255:blk_1073741828_1004, duration(ns): 2576160228
[pod/worker-1/datanode] 2025-03-21T23:03:45.045284041Z 2025-03-21 23:03:45,045 INFO datanode.DataNode: PacketResponder: BP-1789806720-192.168.139.246-1742598207255:blk_1073741828_1004, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[192.168.84.177:9866] terminating
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:45.049525108Z 2025-03-21 23:03:45,049 INFO blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:45.051171265Z 2025-03-21 23:03:45,050 INFO hdfs.StateChange: BLOCK* allocate blk_1073741829_1005, replicas=192.168.172.208:9866, 192.168.84.177:9866 for /diagnoses.csv
[pod/worker-1/datanode] 2025-03-21T23:03:45.069586281Z 2025-03-21 23:03:45,069 INFO datanode.DataNode: Receiving BP-1789806720-192.168.139.246-1742598207255:blk_1073741829_1005 src: /192.168.172.208:53978 dest: /192.168.172.208:9866
[pod/worker-0/datanode] 2025-03-21T23:03:45.075926178Z 2025-03-21 23:03:45,075 INFO datanode.DataNode: Receiving BP-1789806720-192.168.139.246-1742598207255:blk_1073741829_1005 src: /192.168.172.208:54374 dest: /192.168.84.177:9866
[pod/worker-0/datanode] 2025-03-21T23:03:47.593638064Z 2025-03-21 23:03:47,593 INFO DataNode.clienttrace: src: /192.168.172.208:54374, dest: /192.168.84.177:9866, bytes: 134217728, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-693970008_100, offset: 0, srvID: 4c73769c-fe12-440f-bd45-0ff9788f8e79, blockid: BP-1789806720-192.168.139.246-1742598207255:blk_1073741829_1005, duration(ns): 2512681402
[pod/worker-0/datanode] 2025-03-21T23:03:47.593797892Z 2025-03-21 23:03:47,593 INFO datanode.DataNode: PacketResponder: BP-1789806720-192.168.139.246-1742598207255:blk_1073741829_1005, type=LAST_IN_PIPELINE terminating
[pod/worker-1/datanode] 2025-03-21T23:03:47.598214110Z 2025-03-21 23:03:47,597 INFO DataNode.clienttrace: src: /192.168.172.208:53978, dest: /192.168.172.208:9866, bytes: 134217728, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-693970008_100, offset: 0, srvID: 893341a4-96f9-462c-a469-c66baaf544c4, blockid: BP-1789806720-192.168.139.246-1742598207255:blk_1073741829_1005, duration(ns): 2515927769
[pod/worker-1/datanode] 2025-03-21T23:03:47.598319480Z 2025-03-21 23:03:47,598 INFO datanode.DataNode: PacketResponder: BP-1789806720-192.168.139.246-1742598207255:blk_1073741829_1005, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[192.168.84.177:9866] terminating
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:47.602574306Z 2025-03-21 23:03:47,602 INFO blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:47.603985320Z 2025-03-21 23:03:47,603 INFO hdfs.StateChange: BLOCK* allocate blk_1073741830_1006, replicas=192.168.172.208:9866, 192.168.84.177:9866 for /diagnoses.csv
[pod/worker-1/datanode] 2025-03-21T23:03:47.644701907Z 2025-03-21 23:03:47,644 INFO datanode.DataNode: Receiving BP-1789806720-192.168.139.246-1742598207255:blk_1073741830_1006 src: /192.168.172.208:49670 dest: /192.168.172.208:9866
[pod/worker-0/datanode] 2025-03-21T23:03:47.649091870Z 2025-03-21 23:03:47,648 INFO datanode.DataNode: Receiving BP-1789806720-192.168.139.246-1742598207255:blk_1073741830_1006 src: /192.168.172.208:39198 dest: /192.168.84.177:9866
[pod/worker-0/datanode] 2025-03-21T23:03:50.330434855Z 2025-03-21 23:03:50,329 INFO DataNode.clienttrace: src: /192.168.172.208:39198, dest: /192.168.84.177:9866, bytes: 134217728, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-693970008_100, offset: 0, srvID: 4c73769c-fe12-440f-bd45-0ff9788f8e79, blockid: BP-1789806720-192.168.139.246-1742598207255:blk_1073741830_1006, duration(ns): 2676645001
[pod/worker-0/datanode] 2025-03-21T23:03:50.330577010Z 2025-03-21 23:03:50,330 INFO datanode.DataNode: PacketResponder: BP-1789806720-192.168.139.246-1742598207255:blk_1073741830_1006, type=LAST_IN_PIPELINE terminating
[pod/worker-1/datanode] 2025-03-21T23:03:50.339847183Z 2025-03-21 23:03:50,338 INFO DataNode.clienttrace: src: /192.168.172.208:49670, dest: /192.168.172.208:9866, bytes: 134217728, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-693970008_100, offset: 0, srvID: 893341a4-96f9-462c-a469-c66baaf544c4, blockid: BP-1789806720-192.168.139.246-1742598207255:blk_1073741830_1006, duration(ns): 2680905617
[pod/worker-1/datanode] 2025-03-21T23:03:50.339989378Z 2025-03-21 23:03:50,339 INFO datanode.DataNode: PacketResponder: BP-1789806720-192.168.139.246-1742598207255:blk_1073741830_1006, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[192.168.84.177:9866] terminating
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:50.344692346Z 2025-03-21 23:03:50,344 INFO blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:50.345533523Z 2025-03-21 23:03:50,345 INFO hdfs.StateChange: BLOCK* allocate blk_1073741831_1007, replicas=192.168.172.208:9866, 192.168.84.177:9866 for /diagnoses.csv
[pod/worker-1/datanode] 2025-03-21T23:03:50.364133057Z 2025-03-21 23:03:50,363 INFO datanode.DataNode: Receiving BP-1789806720-192.168.139.246-1742598207255:blk_1073741831_1007 src: /192.168.172.208:49680 dest: /192.168.172.208:9866
[pod/worker-0/datanode] 2025-03-21T23:03:50.369097404Z 2025-03-21 23:03:50,368 INFO datanode.DataNode: Receiving BP-1789806720-192.168.139.246-1742598207255:blk_1073741831_1007 src: /192.168.172.208:39206 dest: /192.168.84.177:9866
[pod/worker-0/datanode] 2025-03-21T23:03:52.856191877Z 2025-03-21 23:03:52,855 INFO DataNode.clienttrace: src: /192.168.172.208:39206, dest: /192.168.84.177:9866, bytes: 134217728, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-693970008_100, offset: 0, srvID: 4c73769c-fe12-440f-bd45-0ff9788f8e79, blockid: BP-1789806720-192.168.139.246-1742598207255:blk_1073741831_1007, duration(ns): 2481948544
[pod/worker-0/datanode] 2025-03-21T23:03:52.856307187Z 2025-03-21 23:03:52,856 INFO datanode.DataNode: PacketResponder: BP-1789806720-192.168.139.246-1742598207255:blk_1073741831_1007, type=LAST_IN_PIPELINE terminating
[pod/worker-1/datanode] 2025-03-21T23:03:52.860329414Z 2025-03-21 23:03:52,859 INFO DataNode.clienttrace: src: /192.168.172.208:49680, dest: /192.168.172.208:9866, bytes: 134217728, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-693970008_100, offset: 0, srvID: 893341a4-96f9-462c-a469-c66baaf544c4, blockid: BP-1789806720-192.168.139.246-1742598207255:blk_1073741831_1007, duration(ns): 2485767824
[pod/worker-1/datanode] 2025-03-21T23:03:52.860467319Z 2025-03-21 23:03:52,860 INFO datanode.DataNode: PacketResponder: BP-1789806720-192.168.139.246-1742598207255:blk_1073741831_1007, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[192.168.84.177:9866] terminating
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:52.864540355Z 2025-03-21 23:03:52,864 INFO blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:52.865903636Z 2025-03-21 23:03:52,865 INFO hdfs.StateChange: BLOCK* allocate blk_1073741832_1008, replicas=192.168.172.208:9866, 192.168.84.177:9866 for /diagnoses.csv
[pod/worker-1/datanode] 2025-03-21T23:03:52.894698242Z 2025-03-21 23:03:52,894 INFO datanode.DataNode: Receiving BP-1789806720-192.168.139.246-1742598207255:blk_1073741832_1008 src: /192.168.172.208:49694 dest: /192.168.172.208:9866
[pod/worker-0/datanode] 2025-03-21T23:03:52.899676168Z 2025-03-21 23:03:52,899 INFO datanode.DataNode: Receiving BP-1789806720-192.168.139.246-1742598207255:blk_1073741832_1008 src: /192.168.172.208:39214 dest: /192.168.84.177:9866
[pod/worker-0/datanode] 2025-03-21T23:03:53.698490715Z 2025-03-21 23:03:53,698 INFO DataNode.clienttrace: src: /192.168.172.208:39214, dest: /192.168.84.177:9866, bytes: 40774475, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-693970008_100, offset: 0, srvID: 4c73769c-fe12-440f-bd45-0ff9788f8e79, blockid: BP-1789806720-192.168.139.246-1742598207255:blk_1073741832_1008, duration(ns): 793799835
[pod/worker-0/datanode] 2025-03-21T23:03:53.698704909Z 2025-03-21 23:03:53,698 INFO datanode.DataNode: PacketResponder: BP-1789806720-192.168.139.246-1742598207255:blk_1073741832_1008, type=LAST_IN_PIPELINE terminating
[pod/worker-1/datanode] 2025-03-21T23:03:53.702661602Z 2025-03-21 23:03:53,702 INFO DataNode.clienttrace: src: /192.168.172.208:49694, dest: /192.168.172.208:9866, bytes: 40774475, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-693970008_100, offset: 0, srvID: 893341a4-96f9-462c-a469-c66baaf544c4, blockid: BP-1789806720-192.168.139.246-1742598207255:blk_1073741832_1008, duration(ns): 796961274
[pod/worker-1/datanode] 2025-03-21T23:03:53.702767416Z 2025-03-21 23:03:53,702 INFO datanode.DataNode: PacketResponder: BP-1789806720-192.168.139.246-1742598207255:blk_1073741832_1008, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[192.168.84.177:9866] terminating
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:53.714511198Z 2025-03-21 23:03:53,714 INFO hdfs.StateChange: DIR* completeFile: /diagnoses.csv is closed by DFSClient_NONMAPREDUCE_-693970008_100
2025-03-21T23:03:53: Done uploading /diagnoses.csv
2025-03-21T23:03:53: Uploading /patients.csv
[pod/worker-1/datanode] 2025-03-21T23:03:53.784327766Z 2025-03-21 23:03:53,784 INFO datanode.webhdfs: 192.168.139.229 PUT /webhdfs/v1/patients.csv?op=CREATE&user.name=hadoop&namenoderpcaddress=hdfs-namenode:8020&createflag=&createparent=true&overwrite=false&user.name=hadoop 201
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:53.797553537Z 2025-03-21 23:03:53,797 INFO blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:53.798598810Z 2025-03-21 23:03:53,798 INFO hdfs.StateChange: BLOCK* allocate blk_1073741833_1009, replicas=192.168.172.208:9866, 192.168.84.177:9866 for /patients.csv
[pod/worker-1/datanode] 2025-03-21T23:03:53.814404467Z 2025-03-21 23:03:53,814 INFO datanode.DataNode: Receiving BP-1789806720-192.168.139.246-1742598207255:blk_1073741833_1009 src: /192.168.172.208:49710 dest: /192.168.172.208:9866
[pod/worker-0/datanode] 2025-03-21T23:03:53.818707045Z 2025-03-21 23:03:53,818 INFO datanode.DataNode: Receiving BP-1789806720-192.168.139.246-1742598207255:blk_1073741833_1009 src: /192.168.172.208:39226 dest: /192.168.84.177:9866
[pod/worker-0/datanode] 2025-03-21T23:03:55.683894223Z 2025-03-21 23:03:55,683 INFO DataNode.clienttrace: src: /192.168.172.208:39226, dest: /192.168.84.177:9866, bytes: 100814568, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1451430770_117, offset: 0, srvID: 4c73769c-fe12-440f-bd45-0ff9788f8e79, blockid: BP-1789806720-192.168.139.246-1742598207255:blk_1073741833_1009, duration(ns): 1861411036
[pod/worker-0/datanode] 2025-03-21T23:03:55.684004036Z 2025-03-21 23:03:55,683 INFO datanode.DataNode: PacketResponder: BP-1789806720-192.168.139.246-1742598207255:blk_1073741833_1009, type=LAST_IN_PIPELINE terminating
[pod/worker-1/datanode] 2025-03-21T23:03:55.690754075Z 2025-03-21 23:03:55,690 INFO DataNode.clienttrace: src: /192.168.172.208:49710, dest: /192.168.172.208:9866, bytes: 100814568, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1451430770_117, offset: 0, srvID: 893341a4-96f9-462c-a469-c66baaf544c4, blockid: BP-1789806720-192.168.139.246-1742598207255:blk_1073741833_1009, duration(ns): 1866627835
[pod/worker-1/datanode] 2025-03-21T23:03:55.690865432Z 2025-03-21 23:03:55,690 INFO datanode.DataNode: PacketResponder: BP-1789806720-192.168.139.246-1742598207255:blk_1073741833_1009, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[192.168.84.177:9866] terminating
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:55.706273136Z 2025-03-21 23:03:55,705 INFO hdfs.StateChange: DIR* completeFile: /patients.csv is closed by DFSClient_NONMAPREDUCE_-1451430770_117
2025-03-21T23:03:55: Done uploading /patients.csv
2025-03-21T23:03:55: Uploading /prescriptions.csv
[pod/worker-1/datanode] 2025-03-21T23:03:55.767631316Z 2025-03-21 23:03:55,767 INFO datanode.webhdfs: 192.168.139.229 PUT /webhdfs/v1/prescriptions.csv?op=CREATE&user.name=hadoop&namenoderpcaddress=hdfs-namenode:8020&createflag=&createparent=true&overwrite=false&user.name=hadoop 201
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:55.779708082Z 2025-03-21 23:03:55,779 INFO blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:55.781397344Z 2025-03-21 23:03:55,781 INFO hdfs.StateChange: BLOCK* allocate blk_1073741834_1010, replicas=192.168.172.208:9866, 192.168.84.177:9866 for /prescriptions.csv
[pod/worker-1/datanode] 2025-03-21T23:03:55.797203190Z 2025-03-21 23:03:55,796 INFO datanode.DataNode: Receiving BP-1789806720-192.168.139.246-1742598207255:blk_1073741834_1010 src: /192.168.172.208:49712 dest: /192.168.172.208:9866
[pod/worker-0/datanode] 2025-03-21T23:03:55.801877671Z 2025-03-21 23:03:55,801 INFO datanode.DataNode: Receiving BP-1789806720-192.168.139.246-1742598207255:blk_1073741834_1010 src: /192.168.172.208:39234 dest: /192.168.84.177:9866
[pod/worker-0/datanode] 2025-03-21T23:03:58.298158183Z 2025-03-21 23:03:58,297 INFO DataNode.clienttrace: src: /192.168.172.208:39234, dest: /192.168.84.177:9866, bytes: 134217728, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1917840387_122, offset: 0, srvID: 4c73769c-fe12-440f-bd45-0ff9788f8e79, blockid: BP-1789806720-192.168.139.246-1742598207255:blk_1073741834_1010, duration(ns): 2492071037
[pod/worker-0/datanode] 2025-03-21T23:03:58.298250514Z 2025-03-21 23:03:58,298 INFO datanode.DataNode: PacketResponder: BP-1789806720-192.168.139.246-1742598207255:blk_1073741834_1010, type=LAST_IN_PIPELINE terminating
[pod/worker-1/datanode] 2025-03-21T23:03:58.302948847Z 2025-03-21 23:03:58,302 INFO DataNode.clienttrace: src: /192.168.172.208:49712, dest: /192.168.172.208:9866, bytes: 134217728, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1917840387_122, offset: 0, srvID: 893341a4-96f9-462c-a469-c66baaf544c4, blockid: BP-1789806720-192.168.139.246-1742598207255:blk_1073741834_1010, duration(ns): 2495609073
[pod/worker-1/datanode] 2025-03-21T23:03:58.303052132Z 2025-03-21 23:03:58,302 INFO datanode.DataNode: PacketResponder: BP-1789806720-192.168.139.246-1742598207255:blk_1073741834_1010, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[192.168.84.177:9866] terminating
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:58.306819899Z 2025-03-21 23:03:58,306 INFO blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:03:58.307756835Z 2025-03-21 23:03:58,307 INFO hdfs.StateChange: BLOCK* allocate blk_1073741835_1011, replicas=192.168.172.208:9866, 192.168.84.177:9866 for /prescriptions.csv
[pod/worker-1/datanode] 2025-03-21T23:03:58.335235328Z 2025-03-21 23:03:58,334 INFO datanode.DataNode: Receiving BP-1789806720-192.168.139.246-1742598207255:blk_1073741835_1011 src: /192.168.172.208:41888 dest: /192.168.172.208:9866
[pod/worker-0/datanode] 2025-03-21T23:03:58.339834509Z 2025-03-21 23:03:58,339 INFO datanode.DataNode: Receiving BP-1789806720-192.168.139.246-1742598207255:blk_1073741835_1011 src: /192.168.172.208:42126 dest: /192.168.84.177:9866
[pod/worker-0/datanode] 2025-03-21T23:04:00.862661651Z 2025-03-21 23:04:00,862 INFO DataNode.clienttrace: src: /192.168.172.208:42126, dest: /192.168.84.177:9866, bytes: 134217728, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1917840387_122, offset: 0, srvID: 4c73769c-fe12-440f-bd45-0ff9788f8e79, blockid: BP-1789806720-192.168.139.246-1742598207255:blk_1073741835_1011, duration(ns): 2519079607
[pod/worker-0/datanode] 2025-03-21T23:04:00.863072254Z 2025-03-21 23:04:00,862 INFO datanode.DataNode: PacketResponder: BP-1789806720-192.168.139.246-1742598207255:blk_1073741835_1011, type=LAST_IN_PIPELINE terminating
[pod/worker-1/datanode] 2025-03-21T23:04:00.866696105Z 2025-03-21 23:04:00,866 INFO DataNode.clienttrace: src: /192.168.172.208:41888, dest: /192.168.172.208:9866, bytes: 134217728, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1917840387_122, offset: 0, srvID: 893341a4-96f9-462c-a469-c66baaf544c4, blockid: BP-1789806720-192.168.139.246-1742598207255:blk_1073741835_1011, duration(ns): 2522171489
[pod/worker-1/datanode] 2025-03-21T23:04:00.866842430Z 2025-03-21 23:04:00,866 INFO datanode.DataNode: PacketResponder: BP-1789806720-192.168.139.246-1742598207255:blk_1073741835_1011, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[192.168.84.177:9866] terminating
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:04:00.869470821Z 2025-03-21 23:04:00,869 INFO blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:04:00.870422541Z 2025-03-21 23:04:00,870 INFO hdfs.StateChange: BLOCK* allocate blk_1073741836_1012, replicas=192.168.172.208:9866, 192.168.84.177:9866 for /prescriptions.csv
[pod/worker-1/datanode] 2025-03-21T23:04:00.894391011Z 2025-03-21 23:04:00,894 INFO datanode.DataNode: Receiving BP-1789806720-192.168.139.246-1742598207255:blk_1073741836_1012 src: /192.168.172.208:41892 dest: /192.168.172.208:9866
[pod/worker-0/datanode] 2025-03-21T23:04:00.898551805Z 2025-03-21 23:04:00,898 INFO datanode.DataNode: Receiving BP-1789806720-192.168.139.246-1742598207255:blk_1073741836_1012 src: /192.168.172.208:42136 dest: /192.168.84.177:9866
[pod/worker-0/datanode] 2025-03-21T23:04:03.327811948Z 2025-03-21 23:04:03,327 INFO DataNode.clienttrace: src: /192.168.172.208:42136, dest: /192.168.84.177:9866, bytes: 134217728, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1917840387_122, offset: 0, srvID: 4c73769c-fe12-440f-bd45-0ff9788f8e79, blockid: BP-1789806720-192.168.139.246-1742598207255:blk_1073741836_1012, duration(ns): 2425554443
[pod/worker-0/datanode] 2025-03-21T23:04:03.327918006Z 2025-03-21 23:04:03,327 INFO datanode.DataNode: PacketResponder: BP-1789806720-192.168.139.246-1742598207255:blk_1073741836_1012, type=LAST_IN_PIPELINE terminating
[pod/worker-1/datanode] 2025-03-21T23:04:03.331758462Z 2025-03-21 23:04:03,331 INFO DataNode.clienttrace: src: /192.168.172.208:41892, dest: /192.168.172.208:9866, bytes: 134217728, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1917840387_122, offset: 0, srvID: 893341a4-96f9-462c-a469-c66baaf544c4, blockid: BP-1789806720-192.168.139.246-1742598207255:blk_1073741836_1012, duration(ns): 2428794658
[pod/worker-1/datanode] 2025-03-21T23:04:03.331824191Z 2025-03-21 23:04:03,331 INFO datanode.DataNode: PacketResponder: BP-1789806720-192.168.139.246-1742598207255:blk_1073741836_1012, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[192.168.84.177:9866] terminating
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:04:03.333576730Z 2025-03-21 23:04:03,333 INFO blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:04:03.334051363Z 2025-03-21 23:04:03,333 INFO hdfs.StateChange: BLOCK* allocate blk_1073741837_1013, replicas=192.168.172.208:9866, 192.168.84.177:9866 for /prescriptions.csv
[pod/worker-1/datanode] 2025-03-21T23:04:03.368960224Z 2025-03-21 23:04:03,368 INFO datanode.DataNode: Receiving BP-1789806720-192.168.139.246-1742598207255:blk_1073741837_1013 src: /192.168.172.208:41900 dest: /192.168.172.208:9866
[pod/worker-0/datanode] 2025-03-21T23:04:03.373301328Z 2025-03-21 23:04:03,373 INFO datanode.DataNode: Receiving BP-1789806720-192.168.139.246-1742598207255:blk_1073741837_1013 src: /192.168.172.208:42148 dest: /192.168.84.177:9866
[pod/worker-1/datanode] 2025-03-21T23:04:05.903068587Z 2025-03-21 23:04:05,902 INFO DataNode.clienttrace: src: /192.168.172.208:41900, dest: /192.168.172.208:9866, bytes: 134217728, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1917840387_122, offset: 0, srvID: 893341a4-96f9-462c-a469-c66baaf544c4, blockid: BP-1789806720-192.168.139.246-1742598207255:blk_1073741837_1013, duration(ns): 2524891692
[pod/worker-1/datanode] 2025-03-21T23:04:05.903141337Z 2025-03-21 23:04:05,902 INFO datanode.DataNode: PacketResponder: BP-1789806720-192.168.139.246-1742598207255:blk_1073741837_1013, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[192.168.84.177:9866] terminating
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:04:05.906011463Z 2025-03-21 23:04:05,905 INFO blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:04:05.907300888Z 2025-03-21 23:04:05,907 INFO hdfs.StateChange: BLOCK* allocate blk_1073741838_1014, replicas=192.168.172.208:9866, 192.168.84.177:9866 for /prescriptions.csv
[pod/worker-0/datanode] 2025-03-21T23:04:05.898914497Z 2025-03-21 23:04:05,898 INFO DataNode.clienttrace: src: /192.168.172.208:42148, dest: /192.168.84.177:9866, bytes: 134217728, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1917840387_122, offset: 0, srvID: 4c73769c-fe12-440f-bd45-0ff9788f8e79, blockid: BP-1789806720-192.168.139.246-1742598207255:blk_1073741837_1013, duration(ns): 2521699237
[pod/worker-0/datanode] 2025-03-21T23:04:05.899050741Z 2025-03-21 23:04:05,898 INFO datanode.DataNode: PacketResponder: BP-1789806720-192.168.139.246-1742598207255:blk_1073741837_1013, type=LAST_IN_PIPELINE terminating
[pod/worker-1/datanode] 2025-03-21T23:04:05.927980762Z 2025-03-21 23:04:05,927 INFO datanode.DataNode: Receiving BP-1789806720-192.168.139.246-1742598207255:blk_1073741838_1014 src: /192.168.172.208:41916 dest: /192.168.172.208:9866
[pod/worker-0/datanode] 2025-03-21T23:04:05.932440477Z 2025-03-21 23:04:05,932 INFO datanode.DataNode: Receiving BP-1789806720-192.168.139.246-1742598207255:blk_1073741838_1014 src: /192.168.172.208:42164 dest: /192.168.84.177:9866
[pod/worker-0/datanode] 2025-03-21T23:04:07.889105230Z 2025-03-21 23:04:07,888 INFO DataNode.clienttrace: src: /192.168.172.208:42164, dest: /192.168.84.177:9866, bytes: 104787623, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1917840387_122, offset: 0, srvID: 4c73769c-fe12-440f-bd45-0ff9788f8e79, blockid: BP-1789806720-192.168.139.246-1742598207255:blk_1073741838_1014, duration(ns): 1953030500
[pod/worker-0/datanode] 2025-03-21T23:04:07.889327403Z 2025-03-21 23:04:07,889 INFO datanode.DataNode: PacketResponder: BP-1789806720-192.168.139.246-1742598207255:blk_1073741838_1014, type=LAST_IN_PIPELINE terminating
[pod/worker-1/datanode] 2025-03-21T23:04:07.893414679Z 2025-03-21 23:04:07,892 INFO DataNode.clienttrace: src: /192.168.172.208:41916, dest: /192.168.172.208:9866, bytes: 104787623, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1917840387_122, offset: 0, srvID: 893341a4-96f9-462c-a469-c66baaf544c4, blockid: BP-1789806720-192.168.139.246-1742598207255:blk_1073741838_1014, duration(ns): 1956223361
[pod/worker-1/datanode] 2025-03-21T23:04:07.893518882Z 2025-03-21 23:04:07,893 INFO datanode.DataNode: PacketResponder: BP-1789806720-192.168.139.246-1742598207255:blk_1073741838_1014, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[192.168.84.177:9866] terminating
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:04:07.914508984Z 2025-03-21 23:04:07,914 INFO hdfs.StateChange: DIR* completeFile: /prescriptions.csv is closed by DFSClient_NONMAPREDUCE_-1917840387_122
2025-03-21T23:04:07: Done uploading /prescriptions.csv
2025-03-21T23:04:07: Time limit: 1800 Seconds
2025-03-21T23:04:07: Creating runner environment ...
2025-03-21T23:04:14: Status: Pending
2025-03-21T23:04:20: Status: Pending
2025-03-21T23:04:25: Status: Pending
2025-03-21T23:04:30: Status: Pending
2025-03-21T23:04:35: Status: Pending
2025-03-21T23:04:41: Attaching logs
2025-03-21T23:04:41: Attaching logger to infra: app.kubernetes.io/name=spark-submit
[pod/spark-submit/spark-submit] 2025-03-21T23:04:41.619040907Z Using properties file: null
[pod/spark-submit/spark-submit] 2025-03-21T23:04:41.796222077Z Parsed arguments:
[pod/spark-submit/spark-submit] 2025-03-21T23:04:41.796274781Z   master                  spark://spark-master.submission-b88ebfea875443329ffa71394f4e85fa.svc.cluster.local:7077
[pod/spark-submit/spark-submit] 2025-03-21T23:04:41.796283348Z   deployMode              null
[pod/spark-submit/spark-submit] 2025-03-21T23:04:41.796287113Z   executorMemory          300g
[pod/spark-submit/spark-submit] 2025-03-21T23:04:41.796291176Z   executorCores           null
[pod/spark-submit/spark-submit] 2025-03-21T23:04:41.796294855Z   totalExecutorCores      null
[pod/spark-submit/spark-submit] 2025-03-21T23:04:41.796298386Z   propertiesFile          null
[pod/spark-submit/spark-submit] 2025-03-21T23:04:41.796301788Z   driverMemory            30g
[pod/spark-submit/spark-submit] 2025-03-21T23:04:41.796305281Z   driverCores             null
[pod/spark-submit/spark-submit] 2025-03-21T23:04:41.796308602Z   driverExtraClassPath    null
[pod/spark-submit/spark-submit] 2025-03-21T23:04:41.796312007Z   driverExtraLibraryPath  null
[pod/spark-submit/spark-submit] 2025-03-21T23:04:41.796315913Z   driverExtraJavaOptions  -Dlog4j.configuration="file:/etc/spark/spark-log4j.properties"
[pod/spark-submit/spark-submit] 2025-03-21T23:04:41.796319829Z   supervise               false
[pod/spark-submit/spark-submit] 2025-03-21T23:04:41.796323656Z   queue                   null
[pod/spark-submit/spark-submit] 2025-03-21T23:04:41.796327018Z   numExecutors            null
[pod/spark-submit/spark-submit] 2025-03-21T23:04:41.796330386Z   files                   null
[pod/spark-submit/spark-submit] 2025-03-21T23:04:41.796333802Z   pyFiles                 hdfs://hdfs-namenode.submission-b88ebfea875443329ffa71394f4e85fa.svc.cluster.local/app.zip
[pod/spark-submit/spark-submit] 2025-03-21T23:04:41.796337163Z   archives                null
[pod/spark-submit/spark-submit] 2025-03-21T23:04:41.796340503Z   mainClass               null
[pod/spark-submit/spark-submit] 2025-03-21T23:04:41.796343912Z   primaryResource         hdfs://hdfs-namenode.submission-b88ebfea875443329ffa71394f4e85fa.svc.cluster.local/main.py
[pod/spark-submit/spark-submit] 2025-03-21T23:04:41.796347647Z   name                    main.py
[pod/spark-submit/spark-submit] 2025-03-21T23:04:41.796351074Z   childArgs               []
[pod/spark-submit/spark-submit] 2025-03-21T23:04:41.796354403Z   jars                    null
[pod/spark-submit/spark-submit] 2025-03-21T23:04:41.796357715Z   packages                null
[pod/spark-submit/spark-submit] 2025-03-21T23:04:41.796361026Z   packagesExclusions      null
[pod/spark-submit/spark-submit] 2025-03-21T23:04:41.796364583Z   repositories            null
[pod/spark-submit/spark-submit] 2025-03-21T23:04:41.796367977Z   verbose                 true
[pod/spark-submit/spark-submit] 2025-03-21T23:04:41.796371052Z 
[pod/spark-submit/spark-submit] 2025-03-21T23:04:41.796374858Z Spark properties used, including those specified through
[pod/spark-submit/spark-submit] 2025-03-21T23:04:41.796378339Z  --conf and those from the properties file null:
[pod/spark-submit/spark-submit] 2025-03-21T23:04:41.796381705Z   (spark.blockManager.port,4041)
[pod/spark-submit/spark-submit] 2025-03-21T23:04:41.796385025Z   (spark.driver.extraJavaOptions,-Dlog4j.configuration="file:/etc/spark/spark-log4j.properties")
[pod/spark-submit/spark-submit] 2025-03-21T23:04:41.796388518Z   (spark.driver.host,spark-submit.submission-b88ebfea875443329ffa71394f4e85fa.svc.cluster.local)
[pod/spark-submit/spark-submit] 2025-03-21T23:04:41.796391851Z   (spark.driver.memory,30g)
[pod/spark-submit/spark-submit] 2025-03-21T23:04:41.796395219Z   (spark.driver.port,4042)
[pod/spark-submit/spark-submit] 2025-03-21T23:04:41.796398603Z   (spark.eventLog.compress,true)
[pod/spark-submit/spark-submit] 2025-03-21T23:04:41.796401922Z   (spark.eventLog.dir,hdfs://hdfs-namenode.submission-b88ebfea875443329ffa71394f4e85fa.svc.cluster.local/spark-logs)
[pod/spark-submit/spark-submit] 2025-03-21T23:04:41.796405518Z   (spark.eventLog.enabled,true)
[pod/spark-submit/spark-submit] 2025-03-21T23:04:41.796408818Z   (spark.executor.memory,300g)
[pod/spark-submit/spark-submit] 2025-03-21T23:04:41.796412156Z   (spark.hadoop.fs.defaultFS,hdfs://hdfs-namenode:8020)
[pod/spark-submit/spark-submit] 2025-03-21T23:04:41.796415465Z   (spark.ui.enabled,false)
[pod/spark-submit/spark-submit] 2025-03-21T23:04:41.796418552Z 
[pod/spark-submit/spark-submit] 2025-03-21T23:04:41.796421882Z     
[pod/spark-submit/spark-submit] 2025-03-21T23:04:42.440621049Z 25/03/21 23:04:42 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[pod/spark-submit/spark-submit] 2025-03-21T23:04:43.606786639Z Exception in thread "main" java.io.FileNotFoundException: File hdfs://hdfs-namenode.submission-b88ebfea875443329ffa71394f4e85fa.svc.cluster.local/main.py does not exist.
[pod/spark-submit/spark-submit] 2025-03-21T23:04:43.606918625Z 	at org.apache.hadoop.hdfs.DistributedFileSystem.listStatusInternal(DistributedFileSystem.java:1104)
[pod/spark-submit/spark-submit] 2025-03-21T23:04:43.606991152Z 	at org.apache.hadoop.hdfs.DistributedFileSystem.access$600(DistributedFileSystem.java:147)
[pod/spark-submit/spark-submit] 2025-03-21T23:04:43.607068209Z 	at org.apache.hadoop.hdfs.DistributedFileSystem$24.doCall(DistributedFileSystem.java:1175)
[pod/spark-submit/spark-submit] 2025-03-21T23:04:43.607081762Z 	at org.apache.hadoop.hdfs.DistributedFileSystem$24.doCall(DistributedFileSystem.java:1172)
[pod/spark-submit/spark-submit] 2025-03-21T23:04:43.607105516Z 	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
[pod/spark-submit/spark-submit] 2025-03-21T23:04:43.607124817Z 	at org.apache.hadoop.hdfs.DistributedFileSystem.listStatus(DistributedFileSystem.java:1182)
[pod/spark-submit/spark-submit] 2025-03-21T23:04:43.607157897Z 	at org.apache.spark.util.Utils$.fetchHcfsFile(Utils.scala:851)
[pod/spark-submit/spark-submit] 2025-03-21T23:04:43.607183937Z 	at org.apache.spark.util.Utils$.doFetchFile(Utils.scala:820)
[pod/spark-submit/spark-submit] 2025-03-21T23:04:43.607245846Z 	at org.apache.spark.util.DependencyUtils$.downloadFile(DependencyUtils.scala:264)
[pod/spark-submit/spark-submit] 2025-03-21T23:04:43.607269425Z 	at org.apache.spark.deploy.SparkSubmit.$anonfun$prepareSubmitEnvironment$8(SparkSubmit.scala:391)
[pod/spark-submit/spark-submit] 2025-03-21T23:04:43.607315228Z 	at scala.Option.map(Option.scala:230)
[pod/spark-submit/spark-submit] 2025-03-21T23:04:43.607356297Z 	at org.apache.spark.deploy.SparkSubmit.prepareSubmitEnvironment(SparkSubmit.scala:391)
[pod/spark-submit/spark-submit] 2025-03-21T23:04:43.607392650Z 	at org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:923)
[pod/spark-submit/spark-submit] 2025-03-21T23:04:43.607434485Z 	at org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:191)
[pod/spark-submit/spark-submit] 2025-03-21T23:04:43.607467702Z 	at org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:214)
[pod/spark-submit/spark-submit] 2025-03-21T23:04:43.607504135Z 	at org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:90)
[pod/spark-submit/spark-submit] 2025-03-21T23:04:43.607542597Z 	at org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1072)
[pod/spark-submit/spark-submit] 2025-03-21T23:04:43.607580731Z 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1081)
[pod/spark-submit/spark-submit] 2025-03-21T23:04:43.607618979Z 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
2025-03-21T23:04:51: Status: Failed
2025-03-21T23:04:51: Begin downloading spark logs
2025-03-21T23:04:51: Collecting stats
2025-03-21T23:04:53: Performing cleanup
2025-03-21T23:04:54: Awaiting attached log termination
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:05:01.478527665Z 2025-03-21 23:05:01,477 ERROR namenode.NameNode: RECEIVED SIGNAL 15: SIGTERM
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:05:01.483247958Z 2025-03-21 23:05:01,482 INFO namenode.NameNode: SHUTDOWN_MSG: 
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:05:01.483298932Z /************************************************************
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:05:01.483314904Z SHUTDOWN_MSG: Shutting down NameNode at hdfs-namenode-0/192.168.139.246
[pod/hdfs-namenode-0/hdfs-namenode] 2025-03-21T23:05:01.483327113Z ************************************************************/
[pod/worker-0/datanode] 2025-03-21T23:05:01.744186615Z 2025-03-21 23:05:01,743 ERROR datanode.DataNode: RECEIVED SIGNAL 15: SIGTERM
[pod/worker-0/datanode] 2025-03-21T23:05:01.758735583Z 2025-03-21 23:05:01,758 INFO datanode.DataNode: SHUTDOWN_MSG: 
[pod/worker-0/datanode] 2025-03-21T23:05:01.758763870Z /************************************************************
[pod/worker-0/datanode] 2025-03-21T23:05:01.758772304Z SHUTDOWN_MSG: Shutting down DataNode at worker-0/192.168.84.177
[pod/worker-0/datanode] 2025-03-21T23:05:01.758778431Z ************************************************************/
[pod/worker-1/datanode] 2025-03-21T23:05:01.802530380Z 2025-03-21 23:05:01,802 ERROR datanode.DataNode: RECEIVED SIGNAL 15: SIGTERM
[pod/worker-1/datanode] 2025-03-21T23:05:01.813742691Z 2025-03-21 23:05:01,813 INFO datanode.DataNode: SHUTDOWN_MSG: 
[pod/worker-1/datanode] 2025-03-21T23:05:01.813806429Z /************************************************************
[pod/worker-1/datanode] 2025-03-21T23:05:01.813825512Z SHUTDOWN_MSG: Shutting down DataNode at worker-1/192.168.172.208
[pod/worker-1/datanode] 2025-03-21T23:05:01.813837922Z ************************************************************/
[pod/worker-1/spark-worker] 2025-03-21T23:05:31.552288826Z 25/03/21 23:05:31 INFO Worker: spark-master.submission-b88ebfea875443329ffa71394f4e85fa.svc.cluster.local:7077 Disassociated !
[pod/worker-0/spark-worker] 2025-03-21T23:05:31.551863453Z 25/03/21 23:05:31 INFO Worker: spark-master.submission-b88ebfea875443329ffa71394f4e85fa.svc.cluster.local:7077 Disassociated !
[pod/worker-1/spark-worker] 2025-03-21T23:05:31.553455199Z 25/03/21 23:05:31 ERROR Worker: Connection to master failed! Waiting for master to reconnect...
[pod/worker-1/spark-worker] 2025-03-21T23:05:31.554877631Z 25/03/21 23:05:31 INFO Worker: spark-master-0.spark-master.submission-b88ebfea875443329ffa71394f4e85fa.svc.cluster.local:7077 Disassociated !
[pod/worker-1/spark-worker] 2025-03-21T23:05:31.555110630Z 25/03/21 23:05:31 INFO Worker: Connecting to master spark-master.submission-b88ebfea875443329ffa71394f4e85fa.svc.cluster.local:7077...
[pod/worker-1/spark-worker] 2025-03-21T23:05:31.555165216Z 25/03/21 23:05:31 ERROR Worker: Connection to master failed! Waiting for master to reconnect...
[pod/worker-1/spark-worker] 2025-03-21T23:05:31.556779854Z 25/03/21 23:05:31 INFO Worker: Not spawning another attempt to register with the master, since there is an attempt scheduled already.
[pod/worker-0/spark-worker] 2025-03-21T23:05:31.552915125Z 25/03/21 23:05:31 ERROR Worker: Connection to master failed! Waiting for master to reconnect...
[pod/worker-0/spark-worker] 2025-03-21T23:05:31.554063322Z 25/03/21 23:05:31 INFO Worker: spark-master-0.spark-master.submission-b88ebfea875443329ffa71394f4e85fa.svc.cluster.local:7077 Disassociated !
[pod/worker-0/spark-worker] 2025-03-21T23:05:31.554257637Z 25/03/21 23:05:31 ERROR Worker: Connection to master failed! Waiting for master to reconnect...
[pod/worker-0/spark-worker] 2025-03-21T23:05:31.554334403Z 25/03/21 23:05:31 INFO Worker: Connecting to master spark-master.submission-b88ebfea875443329ffa71394f4e85fa.svc.cluster.local:7077...
[pod/worker-0/spark-worker] 2025-03-21T23:05:31.555320142Z 25/03/21 23:05:31 INFO Worker: Not spawning another attempt to register with the master, since there is an attempt scheduled already.
[pod/worker-1/spark-worker] 2025-03-21T23:05:31.563172737Z 25/03/21 23:05:31 INFO TransportClientFactory: Found inactive connection to spark-master.submission-b88ebfea875443329ffa71394f4e85fa.svc.cluster.local:7077, creating a new one.
[pod/worker-0/spark-worker] 2025-03-21T23:05:31.562950974Z 25/03/21 23:05:31 INFO TransportClientFactory: Found inactive connection to spark-master.submission-b88ebfea875443329ffa71394f4e85fa.svc.cluster.local:7077, creating a new one.
[pod/worker-1/spark-worker] 2025-03-21T23:05:31.574301729Z 25/03/21 23:05:31 WARN Worker: Failed to connect to master spark-master.submission-b88ebfea875443329ffa71394f4e85fa.svc.cluster.local:7077
[pod/worker-1/spark-worker] 2025-03-21T23:05:31.574351416Z org.apache.spark.SparkException: Exception thrown in awaitResult: 
[pod/worker-1/spark-worker] 2025-03-21T23:05:31.574365340Z 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[pod/worker-1/spark-worker] 2025-03-21T23:05:31.574373583Z 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[pod/worker-1/spark-worker] 2025-03-21T23:05:31.574382194Z 	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[pod/worker-1/spark-worker] 2025-03-21T23:05:31.574390378Z 	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[pod/worker-1/spark-worker] 2025-03-21T23:05:31.574398240Z 	at org.apache.spark.deploy.worker.Worker$$anon$1.run(Worker.scala:313)
[pod/worker-1/spark-worker] 2025-03-21T23:05:31.574408608Z 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[pod/worker-1/spark-worker] 2025-03-21T23:05:31.574417256Z 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[pod/worker-0/spark-worker] 2025-03-21T23:05:31.574397916Z 25/03/21 23:05:31 WARN Worker: Failed to connect to master spark-master.submission-b88ebfea875443329ffa71394f4e85fa.svc.cluster.local:7077
[pod/worker-0/spark-worker] 2025-03-21T23:05:31.574446598Z org.apache.spark.SparkException: Exception thrown in awaitResult: 
[pod/worker-1/spark-worker] 2025-03-21T23:05:31.574425119Z 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[pod/worker-0/spark-worker] 2025-03-21T23:05:31.574459225Z 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[pod/worker-1/spark-worker] 2025-03-21T23:05:31.574435427Z 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[pod/worker-0/spark-worker] 2025-03-21T23:05:31.574467646Z 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[pod/worker-0/spark-worker] 2025-03-21T23:05:31.574475866Z 	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[pod/worker-1/spark-worker] 2025-03-21T23:05:31.574444148Z 	at java.base/java.lang.Thread.run(Thread.java:829)
[pod/worker-0/spark-worker] 2025-03-21T23:05:31.574484440Z 	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[pod/worker-1/spark-worker] 2025-03-21T23:05:31.574452275Z Caused by: java.io.IOException: Failed to connect to spark-master.submission-b88ebfea875443329ffa71394f4e85fa.svc.cluster.local:7077
[pod/worker-0/spark-worker] 2025-03-21T23:05:31.574492803Z 	at org.apache.spark.deploy.worker.Worker$$anon$1.run(Worker.scala:313)
[pod/worker-0/spark-worker] 2025-03-21T23:05:31.574527812Z 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[pod/worker-1/spark-worker] 2025-03-21T23:05:31.574461590Z 	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:298)
[pod/worker-0/spark-worker] 2025-03-21T23:05:31.574545969Z 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[pod/worker-0/spark-worker] 2025-03-21T23:05:31.574554988Z 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[pod/worker-1/spark-worker] 2025-03-21T23:05:31.574470071Z 	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:218)
[pod/worker-1/spark-worker] 2025-03-21T23:05:31.574478973Z 	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:230)
[pod/worker-0/spark-worker] 2025-03-21T23:05:31.574565075Z 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[pod/worker-1/spark-worker] 2025-03-21T23:05:31.574487523Z 	at org.apache.spark.rpc.netty.NettyRpcEnv.createClient(NettyRpcEnv.scala:204)
[pod/worker-1/spark-worker] 2025-03-21T23:05:31.574496525Z 	at org.apache.spark.rpc.netty.Outbox$$anon$1.call(Outbox.scala:202)
[pod/worker-0/spark-worker] 2025-03-21T23:05:31.574574244Z 	at java.base/java.lang.Thread.run(Thread.java:829)
[pod/worker-0/spark-worker] 2025-03-21T23:05:31.574583206Z Caused by: java.io.IOException: Failed to connect to spark-master.submission-b88ebfea875443329ffa71394f4e85fa.svc.cluster.local:7077
[pod/worker-0/spark-worker] 2025-03-21T23:05:31.574596208Z 	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:298)
[pod/worker-1/spark-worker] 2025-03-21T23:05:31.574504575Z 	at org.apache.spark.rpc.netty.Outbox$$anon$1.call(Outbox.scala:198)
[pod/worker-0/spark-worker] 2025-03-21T23:05:31.574606917Z 	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:218)
[pod/worker-0/spark-worker] 2025-03-21T23:05:31.574615324Z 	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:230)
[pod/worker-0/spark-worker] 2025-03-21T23:05:31.574629826Z 	at org.apache.spark.rpc.netty.NettyRpcEnv.createClient(NettyRpcEnv.scala:204)
[pod/worker-1/spark-worker] 2025-03-21T23:05:31.574512367Z 	... 4 more
[pod/worker-0/spark-worker] 2025-03-21T23:05:31.574638290Z 	at org.apache.spark.rpc.netty.Outbox$$anon$1.call(Outbox.scala:202)
[pod/worker-0/spark-worker] 2025-03-21T23:05:31.574646727Z 	at org.apache.spark.rpc.netty.Outbox$$anon$1.call(Outbox.scala:198)
[pod/worker-1/spark-worker] 2025-03-21T23:05:31.574520423Z Caused by: java.net.UnknownHostException: spark-master.submission-b88ebfea875443329ffa71394f4e85fa.svc.cluster.local
[pod/worker-0/spark-worker] 2025-03-21T23:05:31.574654750Z 	... 4 more
[pod/worker-1/spark-worker] 2025-03-21T23:05:31.574527982Z 	at java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:797)
[pod/worker-1/spark-worker] 2025-03-21T23:05:31.574535557Z 	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)
[pod/worker-1/spark-worker] 2025-03-21T23:05:31.574543429Z 	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1386)
[pod/worker-1/spark-worker] 2025-03-21T23:05:31.574551088Z 	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1307)
[pod/worker-1/spark-worker] 2025-03-21T23:05:31.574586337Z 	at java.base/java.net.InetAddress.getByName(InetAddress.java:1257)
[pod/worker-0/spark-worker] 2025-03-21T23:05:31.574665977Z Caused by: java.net.UnknownHostException: spark-master.submission-b88ebfea875443329ffa71394f4e85fa.svc.cluster.local
[pod/worker-0/spark-worker] 2025-03-21T23:05:31.574674290Z 	at java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:797)
[pod/worker-0/spark-worker] 2025-03-21T23:05:31.574682123Z 	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)
[pod/worker-0/spark-worker] 2025-03-21T23:05:31.574689965Z 	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1386)
[pod/worker-1/spark-worker] 2025-03-21T23:05:31.574596461Z 	at io.netty.util.internal.SocketUtils$8.run(SocketUtils.java:156)
[pod/worker-0/spark-worker] 2025-03-21T23:05:31.574697670Z 	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1307)
[pod/worker-1/spark-worker] 2025-03-21T23:05:31.574604267Z 	at io.netty.util.internal.SocketUtils$8.run(SocketUtils.java:153)
[pod/worker-1/spark-worker] 2025-03-21T23:05:31.574612554Z 	at java.base/java.security.AccessController.doPrivileged(Native Method)
[pod/worker-0/spark-worker] 2025-03-21T23:05:31.574732178Z 	at java.base/java.net.InetAddress.getByName(InetAddress.java:1257)
[pod/worker-1/spark-worker] 2025-03-21T23:05:31.574620293Z 	at io.netty.util.internal.SocketUtils.addressByName(SocketUtils.java:153)
[pod/worker-0/spark-worker] 2025-03-21T23:05:31.574741387Z 	at io.netty.util.internal.SocketUtils$8.run(SocketUtils.java:156)
[pod/worker-0/spark-worker] 2025-03-21T23:05:31.574749449Z 	at io.netty.util.internal.SocketUtils$8.run(SocketUtils.java:153)
[pod/worker-0/spark-worker] 2025-03-21T23:05:31.574757679Z 	at java.base/java.security.AccessController.doPrivileged(Native Method)
[pod/worker-1/spark-worker] 2025-03-21T23:05:31.574629020Z 	at io.netty.resolver.DefaultNameResolver.doResolve(DefaultNameResolver.java:41)
[pod/worker-0/spark-worker] 2025-03-21T23:05:31.574765542Z 	at io.netty.util.internal.SocketUtils.addressByName(SocketUtils.java:153)
[pod/worker-1/spark-worker] 2025-03-21T23:05:31.574636953Z 	at io.netty.resolver.SimpleNameResolver.resolve(SimpleNameResolver.java:61)
[pod/worker-0/spark-worker] 2025-03-21T23:05:31.574773307Z 	at io.netty.resolver.DefaultNameResolver.doResolve(DefaultNameResolver.java:41)
[pod/worker-1/spark-worker] 2025-03-21T23:05:31.574661750Z 	at io.netty.resolver.SimpleNameResolver.resolve(SimpleNameResolver.java:53)
[pod/worker-1/spark-worker] 2025-03-21T23:05:31.574672155Z 	at io.netty.resolver.InetSocketAddressResolver.doResolve(InetSocketAddressResolver.java:55)
[pod/worker-0/spark-worker] 2025-03-21T23:05:31.574780933Z 	at io.netty.resolver.SimpleNameResolver.resolve(SimpleNameResolver.java:61)
[pod/worker-0/spark-worker] 2025-03-21T23:05:31.574788618Z 	at io.netty.resolver.SimpleNameResolver.resolve(SimpleNameResolver.java:53)
[pod/worker-1/spark-worker] 2025-03-21T23:05:31.574689581Z 	at io.netty.resolver.InetSocketAddressResolver.doResolve(InetSocketAddressResolver.java:31)
[pod/worker-1/spark-worker] 2025-03-21T23:05:31.574698650Z 	at io.netty.resolver.AbstractAddressResolver.resolve(AbstractAddressResolver.java:106)
[pod/worker-0/spark-worker] 2025-03-21T23:05:31.574796544Z 	at io.netty.resolver.InetSocketAddressResolver.doResolve(InetSocketAddressResolver.java:55)
[pod/worker-1/spark-worker] 2025-03-21T23:05:31.574706816Z 	at io.netty.bootstrap.Bootstrap.doResolveAndConnect0(Bootstrap.java:206)
[pod/worker-1/spark-worker] 2025-03-21T23:05:31.574714572Z 	at io.netty.bootstrap.Bootstrap.access$000(Bootstrap.java:46)
[pod/worker-0/spark-worker] 2025-03-21T23:05:31.574804192Z 	at io.netty.resolver.InetSocketAddressResolver.doResolve(InetSocketAddressResolver.java:31)
[pod/worker-1/spark-worker] 2025-03-21T23:05:31.574722397Z 	at io.netty.bootstrap.Bootstrap$1.operationComplete(Bootstrap.java:180)
[pod/worker-1/spark-worker] 2025-03-21T23:05:31.574730200Z 	at io.netty.bootstrap.Bootstrap$1.operationComplete(Bootstrap.java:166)
[pod/worker-0/spark-worker] 2025-03-21T23:05:31.574817040Z 	at io.netty.resolver.AbstractAddressResolver.resolve(AbstractAddressResolver.java:106)
[pod/worker-0/spark-worker] 2025-03-21T23:05:31.574825497Z 	at io.netty.bootstrap.Bootstrap.doResolveAndConnect0(Bootstrap.java:206)
[pod/worker-1/spark-worker] 2025-03-21T23:05:31.574737845Z 	at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:578)
[pod/worker-1/spark-worker] 2025-03-21T23:05:31.574745784Z 	at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:552)
[pod/worker-0/spark-worker] 2025-03-21T23:05:31.574833270Z 	at io.netty.bootstrap.Bootstrap.access$000(Bootstrap.java:46)
[pod/worker-0/spark-worker] 2025-03-21T23:05:31.574841112Z 	at io.netty.bootstrap.Bootstrap$1.operationComplete(Bootstrap.java:180)
[pod/worker-0/spark-worker] 2025-03-21T23:05:31.574849449Z 	at io.netty.bootstrap.Bootstrap$1.operationComplete(Bootstrap.java:166)
[pod/worker-1/spark-worker] 2025-03-21T23:05:31.574753309Z 	at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:491)
[pod/worker-0/spark-worker] 2025-03-21T23:05:31.574856934Z 	at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:578)
[pod/worker-1/spark-worker] 2025-03-21T23:05:31.574762902Z 	at io.netty.util.concurrent.DefaultPromise.setValue0(DefaultPromise.java:616)
[pod/worker-1/spark-worker] 2025-03-21T23:05:31.574771246Z 	at io.netty.util.concurrent.DefaultPromise.setSuccess0(DefaultPromise.java:605)
[pod/worker-1/spark-worker] 2025-03-21T23:05:31.574778781Z 	at io.netty.util.concurrent.DefaultPromise.trySuccess(DefaultPromise.java:104)
[pod/worker-0/spark-worker] 2025-03-21T23:05:31.574864519Z 	at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:552)
[pod/worker-0/spark-worker] 2025-03-21T23:05:31.574872114Z 	at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:491)
[pod/worker-0/spark-worker] 2025-03-21T23:05:31.574879632Z 	at io.netty.util.concurrent.DefaultPromise.setValue0(DefaultPromise.java:616)
[pod/worker-1/spark-worker] 2025-03-21T23:05:31.574787044Z 	at io.netty.channel.DefaultChannelPromise.trySuccess(DefaultChannelPromise.java:84)
[pod/worker-1/spark-worker] 2025-03-21T23:05:31.574794763Z 	at io.netty.channel.AbstractChannel$AbstractUnsafe.safeSetSuccess(AbstractChannel.java:990)
[pod/worker-1/spark-worker] 2025-03-21T23:05:31.574802201Z 	at io.netty.channel.AbstractChannel$AbstractUnsafe.register0(AbstractChannel.java:516)
[pod/worker-0/spark-worker] 2025-03-21T23:05:31.574887515Z 	at io.netty.util.concurrent.DefaultPromise.setSuccess0(DefaultPromise.java:605)
[pod/worker-0/spark-worker] 2025-03-21T23:05:31.574895029Z 	at io.netty.util.concurrent.DefaultPromise.trySuccess(DefaultPromise.java:104)
[pod/worker-1/spark-worker] 2025-03-21T23:05:31.574809649Z 	at io.netty.channel.AbstractChannel$AbstractUnsafe.access$200(AbstractChannel.java:429)
[pod/worker-1/spark-worker] 2025-03-21T23:05:31.574840344Z 	at io.netty.channel.AbstractChannel$AbstractUnsafe$1.run(AbstractChannel.java:486)
[pod/worker-1/spark-worker] 2025-03-21T23:05:31.574850348Z 	at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:164)
[pod/worker-0/spark-worker] 2025-03-21T23:05:31.574902812Z 	at io.netty.channel.DefaultChannelPromise.trySuccess(DefaultChannelPromise.java:84)
[pod/worker-0/spark-worker] 2025-03-21T23:05:31.574910694Z 	at io.netty.channel.AbstractChannel$AbstractUnsafe.safeSetSuccess(AbstractChannel.java:990)
[pod/worker-0/spark-worker] 2025-03-21T23:05:31.574918146Z 	at io.netty.channel.AbstractChannel$AbstractUnsafe.register0(AbstractChannel.java:516)
[pod/worker-0/spark-worker] 2025-03-21T23:05:31.574925824Z 	at io.netty.channel.AbstractChannel$AbstractUnsafe.access$200(AbstractChannel.java:429)
[pod/worker-1/spark-worker] 2025-03-21T23:05:31.574858491Z 	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:469)
[pod/worker-1/spark-worker] 2025-03-21T23:05:31.574866223Z 	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:503)
[pod/worker-1/spark-worker] 2025-03-21T23:05:31.574873922Z 	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:986)
[pod/worker-1/spark-worker] 2025-03-21T23:05:31.574881544Z 	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
[pod/worker-0/spark-worker] 2025-03-21T23:05:31.574955145Z 	at io.netty.channel.AbstractChannel$AbstractUnsafe$1.run(AbstractChannel.java:486)
[pod/worker-1/spark-worker] 2025-03-21T23:05:31.574928631Z 	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
[pod/worker-1/spark-worker] 2025-03-21T23:05:31.574938599Z 	... 1 more
[pod/worker-0/spark-worker] 2025-03-21T23:05:31.574964993Z 	at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:164)
[pod/worker-0/spark-worker] 2025-03-21T23:05:31.574973844Z 	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:469)
[pod/worker-0/spark-worker] 2025-03-21T23:05:31.574981573Z 	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:503)
[pod/worker-0/spark-worker] 2025-03-21T23:05:31.574989422Z 	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:986)
[pod/worker-0/spark-worker] 2025-03-21T23:05:31.574997097Z 	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
[pod/worker-0/spark-worker] 2025-03-21T23:05:31.575007713Z 	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
[pod/worker-0/spark-worker] 2025-03-21T23:05:31.575015645Z 	... 1 more
2025-03-21T23:05:33: Done
2025-03-21T23:05:33: Bye
